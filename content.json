{"meta":{"title":"徐乔伟","subtitle":"","description":"徐乔伟的个人博客","author":"徐乔伟","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2022-09-25T08:04:37.346Z","updated":"2022-09-25T08:04:37.346Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"所有标签","date":"2022-09-25T08:17:53.053Z","updated":"2022-09-25T08:17:53.053Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-09-25T08:06:39.390Z","updated":"2022-09-25T08:06:39.390Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"layout: friends # 必须title: 我的朋友们 # 可选，这是友链页的标题 这里写友链上方的内容。","text":"layout: friends # 必须title: 我的朋友们 # 可选，这是友链页的标题 这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有分类","date":"2022-09-25T08:07:13.457Z","updated":"2022-09-25T08:07:13.457Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"自己总结的go网络模型知识点（仅供自己复习使用，难免有不严谨处）","slug":"自己总结的go网络模型知识点（仅供自己复习使用，难免有不严谨处）","date":"2023-02-02T00:20:00.000Z","updated":"2023-02-27T13:18:54.555Z","comments":true,"path":"/post/自己总结的go网络模型知识点（仅供自己复习使用，难免有不严谨处）.html","link":"","permalink":"http://example.com/post/%E8%87%AA%E5%B7%B1%E6%80%BB%E7%BB%93%E7%9A%84go%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E4%BB%85%E4%BE%9B%E8%87%AA%E5%B7%B1%E5%A4%8D%E4%B9%A0%E4%BD%BF%E7%94%A8%EF%BC%8C%E9%9A%BE%E5%85%8D%E6%9C%89%E4%B8%8D%E4%B8%A5%E8%B0%A8%E5%A4%84%EF%BC%89.html","excerpt":"","text":"常见网络IO模型及其优缺点1.阻塞阻塞IO的方案是建立几个线程，这几个线程都遵循如下逻辑：业务方会调用read这个系统调用读socket，如果此时内核没有准备好数据，那么这个线程会阻塞住，一直陷入内核态。一旦内核准备好数据，经过业务处理后，再将处理好后的数据写会到socket。阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。阻塞IO特点：同步读写socket时，线程陷入内核态；当读写成功后，切换会用户态，继续执行。其优点为：开发难度小，代码简单。其缺点为：内核态切换开销大。 2.非阻塞非阻塞IO会不断的去询问各个socket是否有新数据可读，如果数据未准备好，则立即返回往下执行，去问下一个socket，而不是像阻塞IO一样没数据可读就阻塞住。应用程序通过一个线程不断的轮询访问内核（问各个socket），直至数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。非阻塞IO特点：如果暂时无法收发数据，会返回错误；应用会不断轮询，直至可以读写数据。其优点为：不会陷入内核态，自由度高。其缺点为：需要自旋轮询。 3.多路复用IO 多路复用技术为了解决上述问题采用了复用一个线程来监听多路连接的方案。一个线程持有多个连接并阻塞等待，当其中某个连接可读写时线程被唤醒进行处理。因为多个连接复用了一个线程所以 IO 多路复用需要的线程数少很多。它是通过 I&#x2F;O 事件分发，当内核数据准备好时，内核再以事件通知应用程序进行操作。这个做法大大改善了 CPU 的利用率，因为当调用了 I&#x2F;O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I&#x2F;O 多路复用接口的线程，然后用户可以进行后续的事件处理。epoll 等技术提供的接口面向 IO 事件而非面向连接，所以需要编写复杂的异步代码，开发难度很大。 go的网络模型操作系统提供了socket作为TCP连接的抽象，IO模型是指操作多个socket的方案，阻塞模型利于编写，但性能差，多路复用模型好，但业务编写复杂。 有没有能结合阻塞、非阻塞模型和多路复用的方法？通过go的网络层实现每一个协程操作一个socket，并且能够隐藏epoll的实现 将线程的阻塞模型换成了协程的休眠模型，休眠后不会被调度，也就不会占用资源 每一个goroutine管理一个socket！ Golang 的 netpoller 基于非阻塞的IO多路复用和 gmp调度模式构建了一个简洁高性能的网络模型，并给开发者提供了 goroutine-per-connection 风格的极简接口。 epoll简单介绍以epoll为例，他会有一个事件池，所有的socket都会在事件池里面注册，然后应用程序会非阻塞的访问这个事件池，问这个事件池中哪几个socket是可读的？事件池会自动返回可读的socket。应用程序知道了哪个socket可读后，直接去读取对应socket。 epoll具体原理epoll 内部使用红黑树来保存所有监听的 socket，红黑树是一种平衡二叉树，添加和查找元素的时间复杂度为 O（log n）。epoll 通过 socket 句柄来作为 key，把 socket 保存在红黑树中。把监听的 socket 保存在红黑树中的目的是，为了在 socket 发生可读可写事件时，能够通过 socket 句柄快速找到对应的 socket 对象。另外，epoll 还维护着一个就绪队列，当 epoll 监听的 socket 状态发生改变（变为可读或可写）时，就会把就绪的 socket 添加到就绪队列中。当 socket 从网络中获取到数据后，会发生通知给 epoll，epoll 会将当前 socket 添加到就绪队列中，并且唤醒等待中的进程（也就是调用 epoll_wait 的进程）。通知的方法为：当 socket 状态发生变化时，会调用 ep_poll_callback 函数来通知 epoll，ep_poll_callback 函数的意图很清晰，主要完成两个工作：1.把就绪的 socket 添加到就绪队列中。2.唤醒调用 epoll_wait 函数而被阻塞的进程。当进程被唤醒后，就会从就绪队列中，把就绪的 socket 复制到用户提供的数组中。当 epoll_wait 返回后，用户就可以从数组中获取到就绪的 socket，并可对其进行读写操作。 多路复用将监听多个socket的这个任务从业务转移给了操作系统自己，也就是应用程序方无需自己询问哪个socket可读，只需要去问事件池即可。多路复用特点：需要注册多个socket事件；调用事件池，当有事件发生时，返回。其优点为：提供了事件列表，不需要查询各个socket。其缺点为：开发难度大，逻辑复杂。 go 对epoll的封装epoll抽象层是为了统一各个操作系统对多路复用器的实现。新建多路复用器：epoll_create()往多路复用器里插入需要监听的事件：epoll_ctl()查询当前有哪些事件发生：epoll_wait() go对epoll做了一层封装，主要是封装了epoll的三个主要方法，这三个方法分别是：新建多路复用器，往多路复用器里面插入一个等待监听的新事件，查询此时有哪些事件发生并返回所有发生的事件。 第一个方法没有变动，主要就是新建多路复用器实例。 第二个方法原epoll中是维护了一个红黑树，用于记录各个待检测的socket的信息，如果当前需要监听一个新的socket，就在红黑树中插入一个节点保存新的socket信息。而go对于其的封装改动为：底层也是利用epoll的红黑树结构，但是记录的是一个socket和关心该socket的协程goroutine信息，即不仅记录了待检测的socket，还记录了正在休眠等待读取或者休眠等待写入该socket的协程信息，新增待检测socket同样是往红黑树中插入一个节点。 第三个方法原epoll中返回的是当前发生的socket本身的事件列表，即当前有哪些socket可读或者可写了，就将该socket加入到一个就绪链表中，这个链表中保存的就是就绪的socket，返回就绪的事件个数。而go对此的封装改动为：首先也是维护了一个就绪链表，但不是立即返回这些就绪事件，而是通过遍历就绪链表，若发现某个就绪socket有相应的想要进行读写的休眠协程，将这个socket对应的可读或者可写的休眠协程返回，若多个就绪socket有可读可写协程，则组成一个协程列表返回，这些休眠协程返回后会被唤醒。若某个就绪socket暂时还没有协程可读可写，就先记录一下状态暂时不管他。 netpoller运行机理 netpoller底层通过多路复用抽象层实现，多路复用抽象层负责监听不同的socket，在多路复用层之上有着polldesc结构体，这个polldesc结构体用于记录每个就绪scoket的信息，以及有哪些休眠协程goroutine在关注这些就绪的socket。（休眠协程被放置在一个等待队列中休眠等待）runtime（垃圾回收）会不断的调用netpoller，使其通过多路复用抽象层不断的监听不同的socket，检查当前有没有socket可读写。如果发现某个socket可读写，先将socket加入到就绪链表中去。再检查有没有对应的休眠协程goroutine正在关心这个socket。如果当前没有休眠协程在关心这个socket，会在polldesc里面记录一下相应的描述；如果当前有休眠协程在关心这个socket，则让上层唤醒对应的协程工作。 整个godis的网络模型处理逻辑 首先，client 连接 server 的时候，listener 通过 accept 调用接收新 connection，每一个新 connection 都启动一个 goroutine 处理，accept 调用会把该 connection 的 socket信息连带所在的 goroutine 上下文信息封装注册到 epoll 的监听列表里去（红黑树）。当在新开启的goroutine里面调用 conn.Read 或者 conn.Write 等需要阻塞等待的函数时，goroutine会被 gopark 给封存起来并使之休眠,休眠的goroutine 会被放置在某个等待队列中，这个等待队列中存放的都是当前想要读写socket但当前又无法立即读写只能休眠等待的g。 什么时候被唤醒呢？只有当多路复用器监听到该socket可读写了，才会去唤醒socket的协程（这里的逻辑是，goroutine里面代码执行到read或write，这里是goroutine本身自己想要读写，但是此时socket无法读写所以协程休眠，当socket可读写时，协程g再被放到p上唤醒）但是也有可能这个socket此时没有正在关心他的协程，因为go程被开启后，不会立即执行，而是由gmp调度决定什么时候执行，所以go程不一定能立即走到read，此时在链表中记录一下状态即可。 获取逻辑是： Go scheduler 会在循环调度的 runtime.schedule() 函数以及 sysmon 监控线程中调用go封装的第三个方法netpoll 以获取等待队列中当前可以运行并唤醒的协程列表，并通过底层 netpoll 中的 epoll_wait系统调用返回将就绪的g列表放置到全局调度队列或者当前 P 本地调度队列去重新执行（协程一旦被放入P的队列或全局队列就代表这个协程被唤醒了，要运行了）。 得到可运行的协程列表后，剩下的就交给了GMP调度。P会有一个当前协程，如果由于P当前的goroutine休眠，就让 P 去执行本地调度队列里的下一个可执行的就绪的 goroutine。而后面的处理就是gmp调度的逻辑了。 Go netpoller 通过在底层对 epoll&#x2F;kqueue&#x2F;iocp 的封装，从而实现了使用同步编程模式达到异步执行的效果。 因为多个连接的话，我们的逻辑只需要为每个连接开启一个goroutine处理就好了。剩下的就是goroutine里面的处理逻辑，处理逻辑就是从连接里面读数据，并且往连接里面写数据。而读数据、写数据在无数据可读或无数据可写时协程是会阻塞的，所以是会休眠，而我们这里封装了epoll，会在合适的时机再唤醒去读写，这里的逻辑我们使用者无需关注，编程的时候只需要把读的代码写出来，处理读的内容，再把写回的代码写出来就行，这完全是一个同步编程的写法，但是实际执行的时候可能读完先休眠，去干其他事处理其他协程去，时机到了再回来写这个协程，也就是执行的时候是异步执行的。综上，Go 借助于 epoll&#x2F;kqueue&#x2F;iocp 和 runtime scheduler 等的帮助，设计出了自己的 I&#x2F;O 多路复用 netpoller，成功地让 Listener.Accept &#x2F; conn.Read &#x2F; conn.Write 等方法从开发者的角度看来是同步模式。 go借助非阻塞io和多路复用实现了自己的网络模型netpoller，非阻塞io体现在哪？ netpoller是结合了多路复用和非阻塞io。 多路复用体现在netpoller封装了epoll的三个核心函数。 非阻塞io体现在goroutine在无法立即读写时不会陷入到系统调用阻塞住从而进入内核态，而是会发生协程休眠等待，等到socket可读写后通过epoll的机制再唤醒协程放入p上运行，从而形成了非阻塞io。当goroutine不陷入内核态的话，就可以利用go scheduler的gmp调度模式来灵活调度g。使用非阻塞io就是为了要利用go的gpm调度。因为一旦进入内核态，整个程序的控制权就会发生转移(到内核)，不再属于用户进程了，那么也就无法借助于 Go 强大的 runtime scheduler 来调度业务程序的并发了。","categories":[{"name":"网络模型 golang","slug":"网络模型-golang","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B-golang/"}],"tags":[{"name":"netpoller epoll","slug":"netpoller-epoll","permalink":"http://example.com/tags/netpoller-epoll/"}]},{"title":"(自己的理解，仅供参考)简易单机版godis逻辑结构图","slug":"简易单机版godis逻辑结构图","date":"2023-02-01T00:20:00.000Z","updated":"2023-02-27T13:42:41.460Z","comments":true,"path":"/post/简易单机版godis逻辑结构图.html","link":"","permalink":"http://example.com/post/%E7%AE%80%E6%98%93%E5%8D%95%E6%9C%BA%E7%89%88godis%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84%E5%9B%BE.html","excerpt":"","text":"单机版godis项目架构 单机版goids执行逻辑结合上面的项目架构图来看更好理解！ server监听每个客户端的TCP连接，并且获取连接交给handler进行处理。handler为每一个客户端连接单独开启一个goroutine处理。在每个goroutine里面，先将该客户端的连接交给解析器parser进行解析，获取了一个管道。业务层handler会持有每个客户端的管道，然后从管道内读取解析完成后的指令，并将指令交给内核，也就是handler调用了内核来执行命令。 内核的执行逻辑是将用户发过来的指令转交给对应的db，让db去执行db的exec方法。如果指令是select，单独处理，调用execselect方法切换db。如果是正常指令，我们就先取出当前连接所操作的那个db编号，有了这个db编号我们就可以从内核Database结构体的属性切片中找到那个db本身。再调用该db的exec方法,db的exec方法通过指令与操作的映射来实现根据指令找到该指令对应的操作方法并调用它。","categories":[{"name":"godis","slug":"godis","permalink":"http://example.com/categories/godis/"}],"tags":[{"name":"godis","slug":"godis","permalink":"http://example.com/tags/godis/"}]},{"title":"(自己的理解，仅供参考)redis和go网络模型对比","slug":"redis和go网络模型对比","date":"2023-01-10T00:20:00.000Z","updated":"2023-02-27T13:40:33.006Z","comments":true,"path":"/post/redis和go网络模型对比.html","link":"","permalink":"http://example.com/post/redis%E5%92%8Cgo%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.html","excerpt":"","text":"redis和go的网络模型的对比：查阅了一些资料，结合自己的理解，总结了redis和go的网络模型的特点如下，仅供自己复习参考，难免有不严谨之处。 Redis 6.0 版本之前的单线模式： 当多个客户端连接过来后，统一进入io多路复用器里面注册，然后调用epoll_wait函数将可读可写的事件取出来，进入事件分发器，分发到各个事件处理器。（多个事件处理器是在一个单线程上运行的，这也是redis被称为单线程的原因）。然后利用一个线程循环处理多个连接的注册、读、写，也就是说线程循环处理的都是已经可读可写的socket。 go的网络模型： 当有多个客户端连接过来后，先不管这个连接是否可读可写，我们都为每个连接单独开启一个goroutine协程去处理（类似于第一种方案），如果当goroutine想要对这个连接读写时，发现没数据可读，此时按照第一种方案这个goroutine应该像方案一种的线程一样会陷入内核态而阻塞，但是由于go这里内部采用了非阻塞io的形式，所以这个goroutine并不会陷入内核态，而是会发生休眠，所有休眠的go程会被放到一个等待队列中，然后由于go封装了epoll，所以调用netpoll方法可以知道有哪些连接又可以读写了，所以会从等待队列中取出相应的休眠的go程唤醒它们，并将他们放到p的本地队列或者全局队列上利用go的gmp调度模式来处理连接。 共同之处 redis的reactor网络模型和go的网络模型的共同之处在于都是采用的io多路复用结合非阻塞io的方法。 多路复用很好理解。 非阻塞io在redis上体现在：针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。redis 调用 read() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。 非阻塞io在godis上体现在：当轮到某个goroutine想要对自己负责的连接读写时，发现此时没数据可读时，此时go程并不会陷入内核态而阻塞，若阻塞了就无法运行下一个go程了，故这里是会让这个go程休眠，记录一下信息然后直接返回，这样调度器就可以顺利运行本地队列中的下一个g了。也就是说go程无法读写时，并不会陷入内核态阻塞其他go程的运行，而是休眠了，并且休眠的go程后续会由netpoll机制唤醒，唤醒也不是立即运行，而是加入队列由gpm调度。这里要知道虽然go程之间是独立的，但是多个go程也是需要统一调度来轮流运行而不是同时运行的，所以go程不允许陷入内核而阻塞其他go程。 除了非阻塞IO的实现不同，还有其他不同之处 redis里面是利用epoll统一注册所有连接，若有连接可读，将可读的连接分配给一个线程处理，然后这个线程利用循环的方式处理多个当前可读的连接。 而go是将每个连接开启多个go协程，不能处理的连接对应的go协程就休眠，可以处理的连接对应的go协程利用gpm调度的模式而非循环模式去处理（gpm调度模式能高并发）。 go网络模型的缺点 go的网络模式由于会为每个连接创建一个goroutine，当有大量连接过来时，此时 goroutine 数量以及消耗的资源就会呈线性趋势暴涨。大量的 goroutines 会被不断创建出来，从而对 Go runtime scheduler 造成极大的调度压力和侵占系统资源，然后资源被侵占又反过来影响 Go scheduler 的调度，进而导致性能下降。 而单reactor&#x2F;单线程模式（redis）只会让可读的连接给线程处理，不会有多余线程。即使是单reactor&#x2F;多线程模式，也只会采用有限的线程来处理连接，并且这些线程处理的连接都是可读可写的，也即处理的都是当前活跃的连接。而在现实网络中，大部分连接虽然存活但并非活跃，go的网络模型会为所有连接开启一个go程从而消耗大量资源，而reactor模式只关注于当前活跃的连接。 另外提一点，虽然redis是单reactor&#x2F;单线程模式，只有一个线程处理多个连接，但是由于redis是在内存中操作，处理速度非常快，所以一个线程足够。","categories":[{"name":"网络模型","slug":"网络模型","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"netpoller redis","slug":"netpoller-redis","permalink":"http://example.com/tags/netpoller-redis/"}]},{"title":"(自己的理解，仅供参考)报文的并发解析，业务异步逻辑的实现原理","slug":"(自己的理解)报文的并发解析，业务异步逻辑的实现原理","date":"2023-01-05T00:20:00.000Z","updated":"2023-02-27T13:29:39.138Z","comments":true,"path":"/post/(自己的理解)报文的并发解析，业务异步逻辑的实现原理.html","link":"","permalink":"http://example.com/post/(%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3)%E6%8A%A5%E6%96%87%E7%9A%84%E5%B9%B6%E5%8F%91%E8%A7%A3%E6%9E%90%EF%BC%8C%E4%B8%9A%E5%8A%A1%E5%BC%82%E6%AD%A5%E9%80%BB%E8%BE%91%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html","excerpt":"","text":"resp报文的并发解析怎么实现的？ 这里通过两个函数ParseStream和parse0，这两个函数什么意思呢？ 就是上层通过io.reader来读取TCP字节流，并且将这个io.reader交给ParseStream去做一个解析，但是ParseStream不会自己直接去做解析，因为解析是需要时间的，如果上层调用ParseStream自己去做解析，需要完整得到解析出一条指令，指令才能返回给上层，此时上层才能去做业务处理，这种方式的话在解析期间业务层就会阻塞在这里，一直阻塞等待到命令的解析完成，才能解析下一个命令，如果客户端想要发很多个命令，短时间就要解析很多命令，只能一个一个的解析，那么同步阻塞等待的时间会很长。 有点HTTP请求的队头阻塞的意思，HTTP是利用了长连接+管道实现请求的并行传输来解决。 为了解决这种情况。于是ParseStream专门开启一个go协程parse0，这个parse0会拿到ParseStream读取的reader去做核心的解析，而不在ParseStream中解析。 这样设计有什么用呢？ 就是ParseStream的任务是读取客户端发送过来的内容，并分发给核心解析器parse0。每当客户端发送过来一次内容，我就读取并开启一个go程，相当于客户端的多个请求发过来会被多个协程并发的解析，客户端不需要等待上一个请求被解析完才能向服务端发送下一个请求，这里首先实现了一个客户端多个请求的并发解析，利用gmp调度来实现并发。 报文解析与业务处理之间的一步逻辑怎么实现的？利用管道！！ 异步指的是报文解析和业务处理之间是异步的，这里异步是利用一个管道来实现的。 每个parse0协程做核心解析的时候，ParseStream会先把一个空管道和io.reader一起传给parse0，由parse0完成解析工作并将解析后的内容填入管道，然后再由ParseStream来向上层返回这个管道。管道的类型为payload，这个类型的含义是客户端向服务端发出的经过解析以后的内容。也即这个管道里装的是客户端向服务端发出的经过解析以后的内容。 这样的话，业务层调用了ParseStream方法后，就会直接得到返回值拿到一个管道，而不会阻塞等待命令的解析，也就是解决了阻塞等待问题。虽然可能管道内一开始没东西，但是一定会获取到一个管道，然后直接从管道内读解析完成的指令就可以了，每解析完成一个指令，管道内就有了该指令，拿到指令就可以先去做业务的处理了，后续的指令可以再从管道内读取，这样就做到了业务的处理与报文的解析实现了异步。 管道的作用 这里管道的作用是：当调用parseStream时，该parseStream方法里面会创建一个管道，然后该方法为parse0开启一个go程后并把管道作为参数传入parse0，在这个parse0里面会将解析后的数据传进该管道，这里因为是开启go程，所以并不需要等parse0解析完，parseStream会直接将这个管道返回。后续只需要一直监听这个管道，没数据就是代表这个客户端没发命令，有数据就是代表这个客户端发数据了。这里一个管道其实就代表一个连接，管道里的数据就是属于该连接上的数据。parseStream方法是在handle方法里面被调用的，而handle方法是写在一个for循环里面的，也就是每过来一个新的连接，都会调用handle方法去处理，那么每个连接就会有一个属于自己的管道了。 总结因为每个连接会持有一个管道，所以业务层其实是会有多个管道的，他只需要从各个管道内读取命令去执行就可以了。至于先读取哪个，由gmp调度来决定。以前的缺点在于如果使用同步阻塞等待某个客户端命令的解析，那么业务层一定会卡死阻塞等待，什么事都做不了，只能等。而现在业务层根本不会阻塞，哪个有命令我就执行哪个，执行完了再去读命令，充分提高了业务处理的效率。","categories":[{"name":"godis","slug":"godis","permalink":"http://example.com/categories/godis/"}],"tags":[{"name":"godis","slug":"godis","permalink":"http://example.com/tags/godis/"}]},{"title":"手动实现一个跳表","slug":"跳表代码","date":"2023-01-01T00:20:00.000Z","updated":"2023-02-27T13:28:25.867Z","comments":true,"path":"/post/跳表代码.html","link":"","permalink":"http://example.com/post/%E8%B7%B3%E8%A1%A8%E4%BB%A3%E7%A0%81.html","excerpt":"","text":"设计跳表不使用任何库函数，设计一个 跳表 。 跳表 是在 O(log(n)) 时间内完成增加、删除、搜索操作的数据结构。跳表相比于树堆与红黑树，其功能与性能相当，并且跳表的代码长度相较下更短，其设计思想与链表相似。 例如，一个跳表包含 [30, 40, 50, 60, 70, 90] ，然后增加 80、45 到跳表中，以下图的方式操作： 跳表中有很多层，每一层是一个短的链表。在第一层的作用下，增加、删除和搜索操作的时间复杂度不超过 O(n)。跳表的每一个操作的平均时间复杂度是 O(log(n))，空间复杂度是 O(n)。 在本题中，你的设计应该要包含这些函数： bool search(int target) : 返回target是否存在于跳表中。 void add(int num): 插入一个元素到跳表。 bool erase(int num): 在跳表中删除一个值，如果 num 不存在，直接返回false. 如果存在多个 num ，删除其中任意一个即可。 示例 1: 输入[“Skiplist”, “add”, “add”, “add”, “search”, “add”, “search”, “erase”, “erase”, “search”][[], [1], [2], [3], [0], [4], [1], [0], [1], [1]]输出[null, null, null, null, false, null, true, false, true, false] 解释Skiplist skiplist &#x3D; new Skiplist();skiplist.add(1);skiplist.add(2);skiplist.add(3);skiplist.search(0); &#x2F;&#x2F; 返回 falseskiplist.add(4);skiplist.search(1); &#x2F;&#x2F; 返回 trueskiplist.erase(0); &#x2F;&#x2F; 返回 false，0 不在跳表中skiplist.erase(1); &#x2F;&#x2F; 返回 trueskiplist.search(1); &#x2F;&#x2F; 返回 false，1 已被擦除 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126class Skiplist &#123; //p.forwards[i]表示节点p的第i层的下一个节点 //1.每次插入数据的时候随机产生的level:决定了新节点的层数； //2.数组update的作用：用以存储新节点所有层数上，各自的前一个节点的信息； //3.节点内的forwards数组：用以存储该节点所有层的下一个节点的信息； //4.当所有节点的最大层级变量maxlevel=1的时候，跳表退化成一个普通链表 private static final float SKIPLIST_P = 0.5f; private static final int MAX_LEVEL = 16; private int levelCount = 1; private Node head = new Node(); // 带头链表 public Skiplist() &#123; &#125; public boolean search(int target) &#123; Node p = head; //从最高层开始找,外层循环，遍历向下的指针 for (int i = levelCount - 1; i &gt;= 0; --i) &#123; //内层循环，遍历向右的指针,找到每一层最后一个小于value的位置 while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; target) &#123; p = p.forwards[i]; &#125; &#125; //判断原始链表对于的值是否等于 value，如果找到了，返回这个Node if (p.forwards[0] != null &amp;&amp; p.forwards[0].data == target) &#123; return true; &#125; else &#123; return false; &#125; &#125; public void add(int num) &#123; //获取索引级别 int level = randomLevel(); Node newNode = new Node(); newNode.data = num; newNode.maxLevel = level; //这里是level Node[] update = new Node[level]; /* for (int i = 0; i &lt; level; ++i) &#123; update[i] = head; &#125; */ // 记录每一层级中update[i]该在的位置，a &lt; value &lt;= b Node p = head; //外层循环，遍历向下的指针 //这里是level for (int i = level - 1; i &gt;= 0; --i) &#123; //内层循环，遍历向右的指针，找到每一层最后一个小于value的位置 while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; num) &#123; p = p.forwards[i]; &#125; update[i] = p;// update[i]就是i层级下newNode应该插入的位置，即a的位置 &#125; // 开始在每层对应的位置插入newNode ，原本指针指向 a -&gt; b //这里是level for (int i = 0; i &lt; level; ++i) &#123; //修改该层链表指向为 newNode.next -&gt; a.next newNode.forwards[i] = update[i].forwards[i]; //修改该层链表指向为 a.next -&gt; newNode update[i].forwards[i] = newNode; &#125; //修改完以后，每层的链表指向变为了 a -&gt; newNode -&gt; b // 更新最大层高 if (levelCount &lt; level) levelCount = level; &#125; public boolean erase(int num) &#123; //这里是levelcount，删除要从最顶层找 Node[] update = new Node[levelCount]; Node p = head; //和添加一样，找到每层要删除的索引的对应的位置 for (int i = levelCount - 1; i &gt;= 0; --i) &#123; //内层循环退出的条件是p的下一个节点的值大于等于value，即找到每一层最后一个小于value的位置 while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; num) &#123; p = p.forwards[i]; &#125; //把p赋值给update[i] update[i] = p; &#125; //if条件确保最下层原始链表存在要删除的该值 if (p.forwards[0] != null &amp;&amp; p.forwards[0].data == num) &#123; //从最上层开始删,一直删到原始链表 for (int i = levelCount - 1; i &gt;= 0; --i) &#123; //如果update[i]的下一个节点等于value，即 b == value ，则删除该节点 if (update[i].forwards[i] != null &amp;&amp; update[i].forwards[i].data == num) &#123; //直接让a.next指向要删除节点的下一个节点，此时要删除的节点就不在链表中了 update[i].forwards[i] = update[i].forwards[i].forwards[i]; &#125; &#125; &#125;else&#123; return false; &#125; //修改该跳表的层高，因为删除了一些索引节点，有可能层高变小 //这里如果不-1的话，有时能过有时过不了 while (levelCount &gt; 1 &amp;&amp; head.forwards[levelCount-1] == null)&#123; levelCount--; &#125; return true; &#125; private int randomLevel() &#123; int level = 1; //Math.random()会生成一个0到1之间的Double类型的数,SKIPLIST_P越大，那么晋升的概率越大，Redis里概率为0.25。 // 当 level &lt; MAX_LEVEL，且随机数小于设定的晋升概率时，level + 1 while (Math.random() &lt; SKIPLIST_P &amp;&amp; level &lt; MAX_LEVEL) level += 1; return level; &#125; class Node &#123; private int data = -1; //这里是max_level private Node[] forwards = new Node[MAX_LEVEL]; private int maxLevel = 0; &#125;&#125;","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"跳表","slug":"跳表","permalink":"http://example.com/tags/%E8%B7%B3%E8%A1%A8/"}]},{"title":"跳表实现原理","slug":"跳表","date":"2022-12-31T00:20:00.000Z","updated":"2023-02-27T12:49:01.586Z","comments":true,"path":"/post/跳表.html","link":"","permalink":"http://example.com/post/%E8%B7%B3%E8%A1%A8.html","excerpt":"","text":"本文转载自： https://www.jianshu.com/p/9d8296562806 理解跳表，从单链表开始说起下图是一个简单的有序单链表，单链表的特性就是每个元素存放下一个元素的引用。即：通过第一个元素可以找到第二个元素，通过第二个元素可以找到第三个元素，依次类推，直到找到最后一个元素。 现在我们有个场景，想快速找到上图链表中的 10 这个元素，只能从头开始遍历链表，直到找到我们需要找的元素。查找路径：1、3、4、5、7、8、9、10。这样的查找效率很低，平均时间复杂度很高O(n)。那有没有办法提高链表的查找速度呢？如下图所示，我们从链表中每两个元素抽出来，加一级索引，一级索引指向了原始链表，即：通过一级索引 7 的down指针可以找到原始链表的 7 。那现在怎么查找 10 这个元素呢？ 先在索引找 1、4、7、9，遍历到一级索引的 9 时，发现 9 的后继节点是 13，比 10 大，于是不往后找了，而是通过 9 找到原始链表的 9，然后再往后遍历找到了我们要找的 10，遍历结束。有没有发现，加了一级索引后，查找路径：1、4、7、9、10，查找节点需要遍历的元素相对少了，我们不需要对 10 之前的所有数据都遍历，查找的效率提升了。 那如果加二级索引呢？如下图所示，查找路径：1、7、9、10。是不是找 10 的效率更高了？这就是跳表的思想，用“空间换时间”，通过给链表建立索引，提高了查找的效率。 可能同学们会想，从上面案例来看，提升的效率并不明显，本来需要遍历8个元素，优化了半天，还需要遍历 4 个元素，其实是因为我们的数据量太少了，当数据量足够大时，效率提升会很大。如下图所示，假如有序单链表现在有1万个元素，分别是 0~9999。现在我们建了很多级索引，最高级的索引，就两个元素 0、5000，次高级索引四个元素 0、2500、5000、7500，依次类推，当我们查找 7890 这个元素时，查找路径为 0、5000、7500 … 7890，通过最高级索引直接跳过了5000个元素，次高层索引直接跳过了2500个元素，从而使得链表能够实现二分查找。由此可以看出，当元素数量较多时，索引提高的效率比较大，近似于二分查找。 到这里大家应该已经明白了什么是跳表。跳表是可以实现二分查找的有序链表。 查找的时间复杂度既然跳表可以提升链表查找元素的效率，那查找一个元素的时间复杂度到底是多少呢？查找元素的过程是从最高级索引开始，一层一层遍历最后下沉到原始链表。所以，时间复杂度 &#x3D; 索引的高度 * 每层索引遍历元素的个数。 先来求跳表的索引高度。如下图所示，假设每两个结点会抽出一个结点作为上一级索引的结点，原始的链表有n个元素，则一级索引有n&#x2F;2 个元素、二级索引有 n&#x2F;4 个元素、k级索引就有 n&#x2F;2k个元素。最高级索引一般有2个元素，即：最高级索引 h 满足 2 &#x3D; n&#x2F;2h，即 h &#x3D; log2n - 1，最高级索引 h 为索引层的高度加上原始数据一层，跳表的总高度 h &#x3D; log2n。 我们看上图中加粗的箭头，表示查找元素 x 的路径，那查找过程中每一层索引最多遍历几个元素呢？ 图中所示，现在到达第 k 级索引，我们发现要查找的元素 x 比 y 大比 z 小，所以，我们需要从 y 处下降到 k-1 级索引继续查找，k-1级索引中比 y 大比 z 小的只有一个 w，所以在 k-1 级索引中，我们遍历的元素最多就是 y、w、z，发现 x 比 w大比 z 小之后，再下降到 k-2 级索引。所以，k-2 级索引最多遍历的元素为 w、u、z。其实每级索引都是类似的道理，每级索引中都是两个结点抽出一个结点作为上一级索引的结点。 现在我们得出结论：当每级索引都是两个结点抽出一个结点作为上一级索引的结点时，每一层最多遍历3个结点。 跳表的索引高度 h &#x3D; log2n，且每层索引最多遍历 3 个元素。所以跳表中查找一个元素的时间复杂度为 O(3*logn)，省略常数即：O(logn)。 空间复杂度跳表通过建立索引，来提高查找元素的效率，就是典型的“空间换时间”的思想，所以在空间上做了一些牺牲，那空间复杂度到底是多少呢？ 假如原始链表包含 n 个元素，则一级索引元素个数为 n&#x2F;2、二级索引元素个数为 n&#x2F;4、三级索引元素个数为 n&#x2F;8 以此类推。所以，索引节点的总和是：n&#x2F;2 + n&#x2F;4 + n&#x2F;8 + … + 8 + 4 + 2 &#x3D; n-2，空间复杂度是 O(n)。 如下图所示：如果每三个结点抽一个结点做为索引，索引总和数就是 n&#x2F;3 + n&#x2F;9 + n&#x2F;27 + … + 9 + 3 + 1&#x3D; n&#x2F;2，减少了一半。所以我们可以通过较少索引数来减少空间复杂度，但是相应的肯定会造成查找效率有一定下降，我们可以根据我们的应用场景来控制这个阈值，看我们更注重时间还是空间。 But，索引结点往往只需要存储 key 和几个指针，并不需要存储完整的对象，所以当对象比索引结点大很多时，索引占用的额外空间就可以忽略了。举个例子：我们现在需要用跳表来给所有学生建索引，学生有很多属性：学号、姓名、性别、身份证号、年龄、家庭住址、身高、体重等。学生的各种属性只需要在原始链表中存储一份即可，我们只需要用学生的学号（int 类型的数据）建立索引，所以索引相对原始数据而言，占用的空间可以忽略。 插入数据插入数据看起来也很简单，跳表的原始链表需要保持有序，所以我们会向查找元素一样，找到元素应该插入的位置。如下图所示，要插入数据6，整个过程类似于查找6，整个的查找路径为 1、1、1、4、4、5。查找到第底层原始链表的元素 5 时，发现 5 小于 6 但是后继节点 7 大于 6，所以应该把 6 插入到 5 之后 7 之前。整个时间复杂度为查找元素的时间复杂度 O(logn)。 如下图所示，假如一直往原始列表中添加数据，但是不更新索引，就可能出现两个索引节点之间数据非常多的情况，极端情况，跳表退化为单链表，从而使得查找效率从 O(logn) 退化为 O(n)。那这种问题该怎么解决呢？我们需要在插入数据的时候，索引节点也需要相应的增加、或者重建索引，来避免查找效率的退化。那我们该如何去维护这个索引呢？ 比较容易理解的做法就是完全重建索引，我们每次插入数据后，都把这个跳表的索引删掉全部重建，重建索引的时间复杂度是多少呢？因为索引的空间复杂度是 O(n)，即：索引节点的个数是 O(n) 级别，每次完全重新建一个 O(n) 级别的索引，时间复杂度也是 O(n) 。造成的后果是：为了维护索引，导致每次插入数据的时间复杂度变成了 O(n)。 那有没有其他效率比较高的方式来维护索引呢？假如跳表每一层的晋升概率是 1&#x2F;2，最理想的索引就是在原始链表中每隔一个元素抽取一个元素做为一级索引。换种说法，我们在原始链表中随机的选 n&#x2F;2 个元素做为一级索引是不是也能通过索引提高查找的效率呢？ 当然可以了，因为一般随机选的元素相对来说都是比较均匀的。如下图所示，随机选择了n&#x2F;2 个元素做为一级索引，虽然不是每隔一个元素抽取一个，但是对于查找效率来讲，影响不大，比如我们想找元素 16，仍然可以通过一级索引，使得遍历路径较少了将近一半。如果抽取的一级索引的元素恰好是前一半的元素 1、3、4、5、7、8，那么查找效率确实没有提升，但是这样的概率太小了。我们可以认为：当原始链表中元素数量足够大，且抽取足够随机的话，我们得到的索引是均匀的。我们要清楚设计良好的数据结构都是为了应对大数据量的场景，如果原始链表只有 5 个元素，那么依次遍历 5 个元素也没有关系，因为数据量太少了。所以，我们可以维护一个这样的索引：随机选 n&#x2F;2 个元素做为一级索引、随机选 n&#x2F;4 个元素做为二级索引、随机选 n&#x2F;8 个元素做为三级索引，依次类推，一直到最顶层索引。这里每层索引的元素个数已经确定，且每层索引元素选取的足够随机，所以可以通过索引来提升跳表的查找效率。 那代码该如何实现，才能使跳表满足上述这个样子呢？可以在每次新插入元素的时候，尽量让该元素有 1&#x2F;2 的几率建立一级索引、1&#x2F;4 的几率建立二级索引、1&#x2F;8 的几率建立三级索引，以此类推，就能满足我们上面的条件。现在我们就需要一个概率算法帮我们把控这个 1&#x2F;2、1&#x2F;4、1&#x2F;8 … ，当每次有数据要插入时，先通过概率算法告诉我们这个元素需要插入到几级索引中，然后开始维护索引并把数据插入到原始链表中。下面开始讲解这个概率算法代码如何实现。 我们可以实现一个 randomLevel() 方法，该方法会随机生成 1~MAX_LEVEL 之间的数（MAX_LEVEL表示索引的最高层数），且该方法有 1&#x2F;2 的概率返回 1、1&#x2F;4 的概率返回 2、1&#x2F;8的概率返回 3，以此类推。 randomLevel() 方法返回 1 表示当前插入的该元素不需要建索引，只需要存储数据到原始链表即可（概率 1/2） randomLevel() 方法返回 2 表示当前插入的该元素需要建一级索引（概率 1/4） randomLevel() 方法返回 3 表示当前插入的该元素需要建二级索引（概率 1/8） randomLevel() 方法返回 4 表示当前插入的该元素需要建三级索引（概率 1/16） 。。。以此类推 所以，通过 randomLevel() 方法，我们可以控制整个跳表各级索引中元素的个数。重点来了：randomLevel() 方法返回 2 的时候会建立一级索引，我们想要一级索引中元素个数占原始数据的 1&#x2F;2，但是 randomLevel() 方法返回 2 的概率为 1&#x2F;4，那是不是有矛盾呢？明明说好的 1&#x2F;2，结果一级索引元素个数怎么变成了原始链表的 1&#x2F;4？我们先看下图，应该就明白了。 假设我们在插入元素 6 的时候，randomLevel() 方法返回 1，则我们不会为 6 建立索引。插入 7 的时候，randomLevel() 方法返回3 ，所以我们需要为元素 7 建立二级索引。这里我们发现了一个特点：当建立二级索引的时候，同时也会建立一级索引；当建立三级索引时，同时也会建立一级、二级索引。所以，一级索引中元素的个数等于 [ 原始链表元素个数 ] * [ randomLevel() 方法返回值 &gt; 1 的概率 ]。因为 randomLevel() 方法返回值 &gt; 1就会建索引，凡是建索引，无论几级索引必然有一级索引，所以一级索引中元素个数占原始数据个数的比率为 randomLevel() 方法返回值 &gt; 1 的概率。那 randomLevel() 方法返回值 &gt; 1 的概率是多少呢？因为 randomLevel() 方法随机生成 1~MAX_LEVEL 的数字，且 randomLevel() 方法返回值 1 的概率为 1&#x2F;2，则 randomLevel() 方法返回值 &gt; 1 的概率为 1 - 1&#x2F;2 &#x3D; 1&#x2F;2。即通过上述流程实现了一级索引中元素个数占原始数据个数的 1&#x2F;2。 同理，当 randomLevel() 方法返回值 &gt; 2 时，会建立二级或二级以上索引，都会在二级索引中增加元素，因此二级索引中元素个数占原始数据的比率为 randomLevel() 方法返回值 &gt; 2 的概率。 randomLevel() 方法返回值 &gt; 2 的概率为 1 减去 randomLevel() &#x3D; 1 或 &#x3D;2 的概率，即 1 - 1&#x2F;2 - 1&#x2F;4 &#x3D; 1&#x2F;4。OK，达到了我们设计的目标：二级索引中元素个数占原始数据的 1&#x2F;4。 以此类推，可以得出，遵守以下两个条件： randomLevel() 方法，随机生成 1~MAX_LEVEL 之间的数（MAX_LEVEL表示索引的最高层数），且有 1/2的概率返回 1、1/4的概率返回 2、1/8的概率返回 3 ... randomLevel() 方法返回 1 不建索引、返回2建一级索引、返回 3 建二级索引、返回 4 建三级索引 ... 就可以满足我们想要的结果，即：一级索引中元素个数应该占原始数据的 1&#x2F;2，二级索引中元素个数占原始数据的 1&#x2F;4，三级索引中元素个数占原始数据的 1&#x2F;8 ，依次类推，一直到最顶层索引。 但是问题又来了，怎么设计这么一个 randomLevel() 方法呢？直接撸代码： 1234567891011// 该 randomLevel 方法会随机生成 1~MAX_LEVEL 之间的数，且 ：// 1/2 的概率返回 1// 1/4 的概率返回 2// 1/8 的概率返回 3 以此类推private int randomLevel() &#123; int level = 1; // 当 level &lt; MAX_LEVEL，且随机数小于设定的晋升概率时，level + 1 while (Math.random() &lt; SKIPLIST_P &amp;&amp; level &lt; MAX_LEVEL) level += 1; return level;&#125; 上述代码可以实现我们的功能，而且，我们的案例中晋升概率 SKIPLIST_P 设置的 1&#x2F;2，即：每两个结点抽出一个结点作为上一级索引的结点。如果我们想节省空间利用率，可以适当的降低代码中的 SKIPLIST_P，从而减少索引元素个数，Redis 的 zset 中 SKIPLIST_P 设定的 0.25。 整体思路大家应该明白了，那插入数据时维护索引的时间复杂度是多少呢？元素插入到单链表的时间复杂度为 O(1)，我们索引的高度最多为 logn，当插入一个元素 x 时，最坏的情况就是元素 x 需要插入到每层索引中，所以插入数据到各层索引中，最坏时间复杂度是 O(logn)。 过程大概理解了，再通过一个例子描述一下跳表插入数据的全流程。现在我们要插入数据 6 到跳表中，首先 randomLevel() 返回 3，表示需要建二级索引，即：一级索引和二级索引需要增加元素 6。该跳表目前最高三级索引，首先找到三级索引的 1，发现 6 比 1大比 13小，所以，从 1 下沉到二级索引。 下沉到二级索引后，发现 6 比 1 大比 7 小，此时需要在二级索引中 1 和 7 之间加一个元素6 ，并从元素 1 继续下沉到一级索引。 下沉到一级索引后，发现 6 比 1 大比 4 大，所以往后查找，发现 6 比 4 大比 7 小，此时需要在一级索引中 4 和 7 之间加一个元素 6 ，并把二级索引的 6 指向 一级索引的 6，最后，从元素 4 继续下沉到原始链表。 下沉到原始链表后，就比较简单了，发现 4、5 比 6小，7比6大，所以将6插入到 5 和 7 之间即可，整个插入过程结束。 整个插入过程的路径与查找元素路径类似， 每层索引中插入元素的时间复杂度 O(1)，所以整个插入的时间复杂度是 O(logn)。 删除数据跳表删除数据时，要把索引中对应节点也要删掉。如下图所示，如果要删除元素 9，需要把原始链表中的 9 和第一级索引的 9 都删除掉。 跳表中，删除元素的时间复杂度是多少呢？删除元素的过程跟查找元素的过程类似，只不过在查找的路径上如果发现了要删除的元素 x，则执行删除操作。跳表中，每一层索引其实都是一个有序的单链表，单链表删除元素的时间复杂度为 O(1)，索引层数为 logn 表示最多需要删除 logn 个元素，所以删除元素的总时间包含 查找元素的时间 加 删除 logn个元素的时间 为 O(logn) + O(logn) &#x3D; 2 O(logn)，忽略常数部分，删除元素的时间复杂度为 O(logn)。 总结跳表是可以实现二分查找的有序链表； 每个元素插入时随机生成它的level； 最底层包含所有的元素； 如果一个元素出现在level(x)，那么它肯定出现在x以下的level中； 每个索引节点包含两个指针，一个向下，一个向右；（笔记目前看过的各种跳表源码实现包括Redis 的zset 都没有向下的指针，那怎么从二级索引跳到一级索引呢？留个悬念，看源码吧，文末有跳表实现源码） 跳表查询、插入、删除的时间复杂度为O(log n)，与平衡二叉树接近； 为什么Redis选择使用跳表而不是红黑树来实现有序集合？Redis 中的有序集合(zset) 支持的操作： 插入一个元素 删除一个元素 查找一个元素 有序输出所有元素 按照范围区间查找元素（比如查找值在 [100, 356] 之间的数据） 其中，前四个操作红黑树也可以完成，且时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"跳表","slug":"跳表","permalink":"http://example.com/tags/%E8%B7%B3%E8%A1%A8/"}]},{"title":"分段锁实现并发安全Map","slug":"分段锁","date":"2022-12-11T00:20:00.000Z","updated":"2023-02-27T12:30:27.046Z","comments":true,"path":"/post/分段锁.html","link":"","permalink":"http://example.com/post/%E5%88%86%E6%AE%B5%E9%94%81.html","excerpt":"","text":"1.引言我们一般有两种方式来降低锁的竞争： 第一种：减少锁的持有时间，sync.Map即是采用这种策略，通过冗余的数据结构，使得需要持有锁的时间，大大减少。 第二种：降低锁的请求频率，锁分解和锁分段技术即是这种思想的体现。 锁分段技术又可称为分段锁机制 什么叫做分段锁机制？ 将数据分为一段一段的存储，然后给每一段数据配备一把锁. 这样在多线程情况下，不同线程操作不同段的数据不会造成冲突，线程之间也不会存在锁竞争，有效的提高了并发访问的效率. 2.实现原理首先我们需要给数据进行分段，属于同一个段的数据放在一起，我们采用golang原生的map来充当段的容器，用于存储元素，将key通过哈希映射的形式分配到不同的段中。 12345// SharedMap 并发安全的小map,ShardCount 个这样的小map数组组成一个大maptype SharedMap struct &#123; items map[string]interface&#123;&#125; sync.RWMutex // 读写锁，保护items&#125; 可以看到，我们给每个段都配备了一个内置的读写锁，用于保护段内的数据安全 12345// ShardCount 底层小shareMap数量var ShardCount = 32// ConcurrentHashMap 并发安全的大map，由 ShardCount 个小mao数组组成，方便实现分段锁机制type ConcurrentHashMap []*SharedMap 然后 ShardCount 个ShareMap就组成了一个大的并发安全的map。 其哈希函数采用了著名的fnv函数 123456789101112// fnv32 hash函数func fnv32(key string) uint32 &#123; // 著名的fnv哈希函数，由 Glenn Fowler、Landon Curt Noll和 Kiem-Phong Vo 创建 hash := uint32(2166136261) const prime32 = uint32(16777619) keyLength := len(key) for i := 0; i &lt; keyLength; i++ &#123; hash *= prime32 hash ^= uint32(key[i]) &#125; return hash&#125; 1.New 12345678// New 创建一个新的concurrent map.func New() ConcurrentHashMap &#123; m := make(ConcurrentHashMap, ShardCount) for i := 0; i &lt; ShardCount; i++ &#123; m[i] = &amp;SharedMap&#123;items: make(map[string]interface&#123;&#125;)&#125; &#125; return m&#125; 直接采用make初始化指定数量个ShareMap，并采用数组的形式保证这些初始化好的ShareMap 2.Set Get Delete Has 123456789101112// GetShardMap 返回给定key的sharedMapfunc (m ConcurrentHashMap) GetShardMap(key string) *SharedMap &#123; return m[uint(fnv32(key))%uint(ShardCount)]&#125;// Set 添加 key-valuefunc (m ConcurrentHashMap) Set(key string, value interface&#123;&#125;) &#123; // Get map shard. shard := m.GetShardMap(key) shard.Lock() shard.items[key] = value shard.Unlock()&#125; 12345678// Get 返回指定key的value值func (m ConcurrentHashMap) Get(key string) (interface&#123;&#125;, bool) &#123; shard := m.GetShardMap(key) shard.RLock() val, ok := shard.items[key] shard.RUnlock() return val, ok&#125; 12345678// Remove 删除一个元素func (m ConcurrentHashMap) Remove(key string) &#123; // Try to get shard. shard := m.GetShardMap(key) shard.Lock() delete(shard.items, key) shard.Unlock()&#125; 12345678910// Has 判断元素是否存在func (m ConcurrentHashMap) Has(key string) bool &#123; // Get shard shard := m.GetShardMap(key) shard.RLock() // See if element is within shard. _, ok := shard.items[key] shard.RUnlock() return ok&#125; 都是先将key通过hash函数确定和获取其所属的ShareMap，然后锁住该段，直接操作数据。 3.Count Keys 1234567891011// Count 统计元素总数func (m ConcurrentHashMap) Count() int &#123; count := 0 for i := 0; i &lt; ShardCount; i++ &#123; shard := m[i] shard.RLock() count += len(shard.items) shard.RUnlock() &#125; return count&#125; 遍历所有的ShareMap，逐个统计，注意，遍历的时候每个ShareMap时，都需要加锁. 12345678910111213// Keys 以字符串数组的形式返回所有keyfunc (m ConcurrentMap) Keys() []string &#123; count := m.Count() keys := make([]string, 0, count) for _, shard := range m &#123; shard.RLock() for key := range shard.items &#123; keys = append(keys, key) &#125; shard.RUnlock() &#125; return keys&#125;","categories":[{"name":"Map","slug":"Map","permalink":"http://example.com/categories/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"http://example.com/tags/Map/"}]},{"title":"Golang - sync.Map原理","slug":"sync.map","date":"2022-12-10T00:20:00.000Z","updated":"2023-02-27T13:18:20.635Z","comments":true,"path":"/post/sync.map.html","link":"","permalink":"http://example.com/post/sync.map.html","excerpt":"","text":"1.引言 在Go v1.6之前，内置map是部分goroutine安全的，并发读没有问题，并发写可能有问题 在Go v1.6之后，并发读写内置map会报错，在一些知名的开源库都有这个问题，所以在Go v1.9之前，解决方案是加一个额外的大锁，锁住map。 在Go v1.9中，go官方提供了并发安全的map，sync.map。 2.sync.Map的设计思想在map内数据非常大的时候，采用一个大锁，会使得锁的竞争十分激烈，存在性能问题。 Java内的解决方案是分段锁机制，比如ConcurrentHashMap,内部使用多个锁，每个区间共用一把锁，这样锁的粒度更小了，减少了数据共享一把大锁带来的性能影响。 但是由于其实现的复杂性和其他因素，Go官方并没有采用上述方案，而是另辟蹊径，采用读写分离的形式，来实现了一个并发安全的map 1.空间换时间 如果采用传统的大锁方案，其锁的竞争十分激烈，也就意味着需要花在锁上的时间很多，我们要尽可能的减少时间消耗，针对耗时太长的情况，算法中有一种常见的解决方案，空间换时间，采用冗余的数据结构，来减少时间的消耗。 sync.map中冗余的数据结构就是dirty和read，二者存放的都是key-entry，entry其实是一个指针，指向value，read和dirty各自维护一套key，key指向的都是同一个value，也就是说，只要修改了这个entry，对read和dirty都是可见的 那空间换时间策略在sync.map中到底是如何体现的呢？到底在哪些地方减少了耗时？ 遍历操作：只需遍历read即可，而read是并发读安全的，没有锁，相比于加锁方案，性能大为提升 查找操作：先在read中查找，read中找不到再去dirty中找 核心思想就是一切操作先去read中执行，因为read是并发读安全的，无需锁，实在在read中找不到，再去dirty中。read在sycn.map中是一种冗余的数据结构，因为read和dirty中数据有很大一部分是重复的，而且二者还会进行数据同步。 2.读写分离 sync.map中有专门用于读的数据结构：read，将其和写操作分离开来，可以避免读写冲突。而采用读写分离策略的代价就是冗余的数据结构，其实还是空间换时间的思想。 3.双检查机制 通过额外的一次检查操作，来避免在第一次检查操作完成后，其他的操作使得检查条件产生突然符合要求的可能。 在sync.map中，每次当read不符合要求要去操作dirty前，都会上锁，上锁后再次判断是否符合要求，因为read有可能在上锁期间，产生了变化，突然又符合要求了，read符合要求了，尽量还是在read中操作，因为read并发读安全。 4.延迟删除 在删除操作中，删除kv，仅仅只是先将需要删除的kv打一个标记，这样可以尽快的让delete操作先返回，减少耗时，在后面提升dirty时，再一次性的删除需要删除的kv。 5.read优先 需要进行读取，删除，更新操作时，优先操作read，因为read无锁的，更快，实在在read中得不到结果，再去dirty中。 read的修改操作需要加锁，read只是并发读安全，并发写并不安全。 6.状态机机制 entry的指针p，是有状态的，nil，expunged(指向被删除的元素)，正常，三种状态.那其状态在sync.map各个操作间又是怎么变化的呢？ 主要是两个操作会引起p状态的变化：Store(新增&#x2F;修改) 和 删除 我们先来看看第一个操作 Store(新增&#x2F;修改)： 在Store更新时，如果key在read中存在，并且被标记为已删除，会将kv加入dirty，此时read中key的p指向的是expunged，经过unexpungeLocked函数，read中的key的p指向会从expunged改为nil，然后经过storeLocked更新value值，p从指向nil，改为指向正常。 (p-&gt;expunged) &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; (p-&gt;nil) &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; (p-&gt;正常)。 在Store增加时，如果需要从read中刷新dirty数据，会将read中未删除的元素加入dirty，此时会将所有指向nil的p指针，改为指向expunged。 (p-&gt;nil) &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; (p-&gt;expunged). 我们再来看看第二个操作： 在Delete时，删除value时，p从指向正常值，改为指向nil. (p-&gt;正常) &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; (p-&gt;nil). p的状态转换如下： 从上图我们可以看出: update时：p的状态从expunged转为nil，然后又转为正常值. add时：当需要刷新dirty，p的状态从nil转为expunged. delete时：p的状态从正常值转为nil. 3.sync.Map源码分析基础数据结构 entry 1234// entry 键值对中的值结构体type entry struct &#123; p unsafe.Pointer // 指针，指向实际存储value值的地方&#125; sync.map中key和value是分开存放的，key通过内置map指向entry，entry通过指针，指向value实际内存地址. Map 1234567891011121314151617// Map 并发安全的map结构体type Map struct &#123; mu sync.Mutex // 锁，保护read和dirty字段 read atomic.Value // 存仅读数据，原子操作，并发读安全，实际存储readOnly类型的数据 dirty map[interface&#123;&#125;]*entry // 存最新写入的数据 misses int // 计数器，每次在read字段中没找所需数据时，+1 // 当此值到达一定阈值时，将dirty字段赋值给read&#125;// readOnly 存储mao中仅读数据的结构体type readOnly struct &#123; m map[interface&#123;&#125;]*entry // 其底层依然是个最简单的map amended bool // 标志位，标识m.dirty中存储的数据是否和m.read中的不一样，flase 相同，true不相同&#125; 需要注意的地方： read在进行非读操作时，需要锁mu进行保护 写入的数据，都是直接写到dirty，后面根据read miss次数达到阈值，会进行read和dirty数据的同步 readOnly中专门有一个标志位，用来标注read和dirty中是否有不同，以便进行read和dirty数据同步 sync.Map中查找k-v12345678910111213141516171819202122232425262728293031323334// Load 查询key是否存在func (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; // 1.先在read中查找key read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 2. 在read中没有找到，并且read和dirty数据不一样(dirty中有read中不存在的数据，因为写数据是直接往dirty中写的) if !ok &amp;&amp; read.amended &#123; m.mu.Lock() // 锁住，因为要操作dirty中数据 // 3.双检查机制，再次在read中查找key，因为有可能read从dirty中更新了数据 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // 4.在read中还是没有找到，并且read和dirty数据仍然不一致 if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] // 直接从dirty获取数据 // read 不命中次数 +1，到达阈值后，为避免read命中率太低，会从dirty中更新read数据 m.missLocked() &#125; m.mu.Unlock() // 解锁，后续不再操作dirty数据 &#125; // 5.最后仍然没有找到key，说明key在map中确实不存在，返回nil if !ok &#123; return nil, false &#125; // 6.找到key了，返回value return e.load()&#125; 123456789101112// missLocked readmiss次数+1 ,并且判断dirty是否需要晋升(dirty置给read）func (m *Map) missLocked() &#123; m.misses++ // read 没命中次数统计+1 if m.misses &lt; len(m.dirty) &#123; return &#125; // dirty 置给read ，因为read没有命中的次数太多了，原子操作 m.read.Store(readOnly&#123;m: m.dirty&#125;) m.dirty = nil // dirty 也置空 m.misses = 0&#125; 通过对源码的分析，我们可以在宏观上总结一下搜索的流程：先在read中搜，搜不到再去dirty中搜，但是这个太宏观了，有些东西没有讨论到，比如 双检查机制 read miss次数达到阈值，刷新read数据 上面两项操作，其实归根结底都是为了提升搜索的效率，比如read miss的统计和read数据的刷新，都是为了让直接可以在read中找到key，尽可能不去dirty中找，因为read并发读是安全的，性能很高，而去dirty中找，则需要加锁，耗时就增加了. 调用Load或LoadOrStore函数时，如果在read中没有找到key，则会将miss值原子增加1，当miss值增加到和dirty长度相等时，会将dirty提升为read，以期望减少 “读 miss”。 sync.Map中添加或修改k-v123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081// Store 添加/修改 key-valuefunc (m *Map) Store(key, value interface&#123;&#125;) &#123; // 1. 在read中查找key，找到了则尝试更新value read, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123; return &#125; m.mu.Lock() // 操作dirty，锁住先 // 2. 双检查机制，再次在read中查找key read, _ = m.read.Load().(readOnly) // 3. key在read中存在 if e, ok := read.m[key]; ok &#123; if e.unexpungeLocked() &#123; // key被标记为已删除，则将k/v加入dirty中 m.dirty[key] = e &#125; e.storeLocked(&amp;value) // 无论key是否为已删除状态，都要更新key的value值 &#125; else if e, ok := m.dirty[key]; ok &#123; // 4. key在dirty中存在，则直接在dirty中更新value值 e.storeLocked(&amp;value) &#125; else &#123; // 5. key在read和dirty中都不存在，则走新增逻辑 // read和dirty中数据相同，则从read中刷新dirty的数据(因为dirty为nil，有可能是初始化或dirty之前提升过了)，并将amended标识为read和dirty不相同，因为后面即将走新增逻辑 if !read.amended &#123; m.dirtyLocked() m.read.Store(readOnly&#123;m: read.m, amended: true&#125;) &#125; m.dirty[key] = newEntry(value) // 新增逻辑，直接在dirty中加入kv键值对 &#125; m.mu.Unlock() // 不再操作dirty数据，解锁啦&#125;// tryStore 尝试更新value 原子操作func (e *entry) tryStore(i *interface&#123;&#125;) bool &#123; for &#123; p := atomic.LoadPointer(&amp;e.p) if p == expunged &#123; // 被删除状态，无法更新 return false &#125; if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) &#123; return true &#125; &#125;&#125;// unexpungeLocked 判断是否指向expunged，如果指向expunged则修改为指向nilfunc (e *entry) unexpungeLocked() (wasExpunged bool) &#123; // 之所以需要将指向expunged的修改为指向nil ，是因为后续会将k/v加入dirty中，都已经加入dirty中，并且不是未删除状态，当然需要指向nil啦 // 此value在read中暂时指向nil，但后续会更新value值，这样read中和dirty中都是指向同一个value的 ( Store中第四步，更新value值) return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)&#125;// storeLocked 更新指向的value值func (e *entry) storeLocked(i *interface&#123;&#125;) &#123; atomic.StorePointer(&amp;e.p, unsafe.Pointer(i))&#125;// dirtyLocked 刷新dirty数据逻辑,将read中未删除的数据加入到dirty中func (m *Map) dirtyLocked() &#123; // 此函数仅在以下情况会执行： read和dirty相同时，比如初始化或dirty刚提升到read，dirty肯定是nil // dirty 非nil，则没必要走刷新dirty数据逻辑 if m.dirty != nil &#123; return &#125; read, _ := m.read.Load().(readOnly) m.dirty = make(map[interface&#123;&#125;]*entry, len(read.m)) // dirty 申请内存空间 // 1.遍历read，将read中未删除元素加入dirty中（加入的其实不是真正的底层数据副本，而是指向底层数据的指针） for k, e := range read.m &#123; if !e.tryExpungeLocked() &#123; // 保证加入dirty中都是read中未删除的元素，read中被删除状态的元素则没必要加入dirty m.dirty[k] = e &#125; &#125;&#125; 12345678910111213141516// tryExpungeLocked 判断元素是否为被删除状态func (e *entry) tryExpungeLocked() (isExpunged bool) &#123; // 进入此函数的指针，有三种指向： 指向正常value，指向nil，指向expunged，本函数的目的就是在判断是否指向expunged之余，将指向nil的都改为指向expunged p := atomic.LoadPointer(&amp;e.p) // 原子操作，载入指针 // 将指向nil的指针，改为指向expunged for p == nil &#123; if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) &#123; // 原子操作，比较和交换 return true &#125; p = atomic.LoadPointer(&amp;e.p) // 原子操作，重新载入指针 &#125; // 有可能是正常元素，判断是否指向expunged return p == expunged&#125; 大致总结一下上述流程： 在read中查找key，找到了则通过原子操作，尝试更新value key在read中存在，但是被标记为已删除，则kv加入dirty中，并更新value值 key在read中不存在，但在dirty中存在，则直接在dirty中更新value key在read和dirty中都不存在，则直接在dirty中加入kv，需要注意的是，此时dirty可能为nil(因为之前可能没有初始化或之前dirty提升过),需要将read中未删除的元素加入dirty 新写入的key会保存到dirty中，如果此时dirty为nil，就会先创建一个dirty，并将read中未删除的数据拷贝到dirty. 当dirty为nil时，read就代表map所有数据，当dirty不为nil的时候，dirty才代表map所有数据。 sync.Map中删除k-v1234567891011121314151617181920212223242526// Delete 删除元素func (m *Map) Delete(key interface&#123;&#125;) &#123; // 1.先在read中查找key read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 2.在read中没有找到key，并且read和dirty中数据不相同(即dirty中有read中没有的数据，因为插入数据都是直接插入到dirty中的，read还来不及根据dirty数据进行刷新) if !ok &amp;&amp; read.amended &#123; m.mu.Lock() // 操作dirty，锁住先 // 3.双检查机制，继续在read中查找key read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // 4. 在read中没有找到key，并且read和dirty中数据不相同，则在dirty中删除key if !ok &amp;&amp; read.amended &#123; delete(m.dirty, key) &#125; m.mu.Unlock() // 解锁，不再操作dirty &#125; // 5. 通过key，找到了value，则删除value if ok &#123; e.delete() &#125;&#125; 1234567891011121314// delete 删除valuefunc (e *entry) delete() (hadValue bool) &#123; for &#123; p := atomic.LoadPointer(&amp;e.p) // 原子操作方式加载指针 if p == nil || p == expunged &#123; // p 指向nil或已删除元素，删除失败 return false &#125; // 将p指向nil // 为何不将p设置为expunged ? 因为p为expunged时，表示其已经不在dirty中了，这是由p的状态机决定的！ if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) &#123; return true &#125; &#125;&#125; 大致总结一下删除操作的流程： 在read中查key，找到了则直接删除value(修改entry的指针p，改为指向nil，因为是指针，所以在read和dirty中都是可见的)。 在read中没有找到key，但read数据和dirty数据有不同，则去dirty中直接删除key(不管dirty中有无key，都是直接删除，不会返回任何响应)，最后也是entry的delete直接删除value。 此函数的特点就是不会有任何的返回值，存在就删除了，没存在就不会删，也删不了，这些对函数外部的调用者都是不可见的 sync.Map中遍历k-v12345678910111213141516171819202122232425262728293031// Range 回调方式遍历mapfunc (m *Map) Range(f func(key, value interface&#123;&#125;) bool) &#123; read, _ := m.read.Load().(readOnly) // 1.dirty中有新数据，则提升dirty，然后再遍历 if read.amended &#123; m.mu.Lock() //操作dirty，锁住 read, _ = m.read.Load().(readOnly) if read.amended &#123; // 双检查机制，再次检测dirty中是否有新数据 read = readOnly&#123;m: m.dirty&#125; // 提升dirty为read，重置dirty和miss计数器 m.read.Store(read) m.dirty = nil m.misses = 0 &#125; m.mu.Unlock() &#125; // 到这就代表，read中的数据和dirty中数据是一致的，直接遍历read即可 // 2.回调的方式遍历read for k, e := range read.m &#123; v, ok := e.load() if !ok &#123; continue &#125; if !f(k, v) &#123; break &#125; &#125;&#125; 注意事项： 底层遍历的其实是read，而如果dirty中有不同于read的新数据，则需要先提升dirty再进行遍历，这样数据才能一致 小结 sync.map 是并发安全的. 通过读写和追加扩容分离，降低锁时间来提高效率，适用于读多写多追加少的场景。 sync.map底层其实是两个map，一个read map，一个dirty map，read map 并发读安全，所有读操作优先read map，所有写操作直接在dirty map中，read map和dirty map在需要时间会进行数据同步。","categories":[{"name":"Map","slug":"Map","permalink":"http://example.com/categories/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"http://example.com/tags/Map/"}]},{"title":"哈希表原理","slug":"哈希表","date":"2022-12-01T00:20:00.000Z","updated":"2023-02-27T13:46:13.926Z","comments":true,"path":"/post/哈希表.html","link":"","permalink":"http://example.com/post/%E5%93%88%E5%B8%8C%E8%A1%A8.html","excerpt":"","text":"map映射结构频繁地运用在日常的开发之中，是面试中的高频考点。 什么是map维基百科的定义： In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection. map又称为关联数组、字典、映射，是一个抽象的数组结构，用于存取1:1映射的键值对。其实数组也是一种映射结构，提供数组索引到值的映射，但数组的索引必须为整数类型，而map却可以让键为任何可比较类型如字符串。 map一般会提供如下操作：增删改查键值对。map大致有两种底层数据结构实现：hash表以及红黑树。根据实现的不同，从而具有不同的特性以及存取效率。 hash表也称散列表，实现采用空间换时间的思想，理想情况下能让hash map的平均存取效率达到O(1)，最坏情况下退化为O(n)，hash表采用哈希函数将键值对打散到不同的桶中，对桶的顺序遍历无法做到对键的排序。 红黑树是一种平衡二叉查找树结构，插入时保持左子树每个节点的key小于根节点，右子树每个节点的key大于根节点，这种特性使得红黑树实现的map能够进行排序。为了防止极端情况下可能出现单支树，从而使时间复杂度退化为O(n)，对二叉查找树的插入和删除都会使其保持平衡(非严格平衡条件)，因此红黑树的性能极为稳定，能够保持在O(logN)。 golang的map、python的dict以及c++的unordered_map采用hash实现，c++的map采用红黑树实现，在java1.8的哈希表的实现中采用的是红黑树与哈希结构混合的方式。 不论是上述哪一种实现，都是面试的高频考点，时常被要求手写。本系列前两章就用这两种方式实现最简单的map结构，让你最快速地把握map的本质。在了解最核心原理后，会详解go语言的原生map结构以及其中的众多优化技巧。除此之外，我们会简单剖析下开源库concurrent-map，分析如何实现一个高性能的并发安全的map。 哈希表原理如果让你实现一个结构，能够提供键值对的增删改查，最容易想到的就是使用链表实现。欲插入键值对，只需要将键值对构成一个节点插入链表；给定Key查找Value，只需要从链表头开始迭代所有节点，比较节点的key即可。 但问题是这样实现查找的效率很低，为O(N)。hash表采取了空间换时间的方式，其核心思想是开辟一个数组空间，数组中每个元素称为桶，我们用这些预先分配的桶存储键值对。 那么问题就是如何组织键值对放入到这些有限桶中。对于hash表来说，都会存在一个哈希函数，输入一个key，通过某种hash(key)函数的计算能够输出一个确切的哈希值，且这个过程是幂等的。给定key就能得到哈希值，进而确定将这个KV(key-value)对存储在哪一个桶中。 举个最简单的例子：我们现在拥有10个桶，现在插入一个key为21的键值对，hash函数为f(key)&#x3D;key%10​，则21得到的hash值为1，我们就将这个键值对存到第2(数组下标从0开始)个桶。当下次再查找21时，我们用同样的哈希函数得到同样的哈希值，立马定位到第2个桶，进而查找即可。这样进行就可以省略掉链表实现中遍历所有节点的过程，将查找效率提升到O(1)。 哈希冲突：桶是预分配且有限的，除此之外不同的key可能通过hash函数得到同样的hash值，如31和21通过上述的hash函数都得到1，两个不同键放入同一桶，这样就会导致冲突，这样哈希值相同的Key称为同义词。 21和31就为同义词，一山不容二虎，那么如何去解决冲突问题呢？①开放地址法。②拉链法。 开放地址法开发地址法的意思是一个桶并不一定只能存放符合哈希要求的键，如下标为2的桶不一定只能存求余为2的key。 例如，目前要依次插入键21、31、23、41、47。key 21插入到桶1中；在准备插入31时，由于桶1已经被key 21占用，我们可以将31插入到桶1后遇到的第一个空桶即桶2；key 23插入到桶3中；在插入41时，本应存入桶1，但由于桶1、桶2、桶3都被占用，key 41就被迫存入空桶4；key 47存入桶7. 对于查找也同理，给定key 31，我们先查看桶1，判断桶里的key与31是否相同，相同则找到目标值，不同则可能存在同义词，去依次查看桶2、桶3、桶4等后续桶，直至找到空桶或者目标key，找到空桶说明待查找的key并没有存于map中。如图所示： 很明显的是，通过这种方式，一旦map的负载因子(键值对个数与桶个数比值)过大，查找需要线性遍历多个桶，性能会退化为O(n)，所以这种实现需要更频繁地对桶进行扩容，保持负载因子在低水平。 拉链法拉链法是大多数编程语言的选择，采用数组以及链表实现。依旧是预先开辟一定容量的桶(数组)，不过和开放地址法的区别是，每个桶后面跟上一个链表，所有的同义词通过链表中节点形式串联在一起。如上例中key 31、21和41就可以跟在桶1的链表中，查找时通过hash函数定位桶以区分非同义词，遍历桶的链表每个节点以及比较key来区分同义词。 开放地址法存在堆积问题，比如key1可能因为同义词占用了key2的位置，导致key2插入时又不得不占用key3的位置，所以开发地址法对负载因子过于敏感。而拉链法通过链表方式解决冲突问题，非同义词之间不会相互影响。 代码实现为了简便起见，我们map实现中键值都为int类型，因此hash函数直接利用求余函数即可。不同key类型只是对应的hash函数不同而已，不是map的核心思想，我们从简。 开放地址法 开放地址法的实现比较简单，但需要有一点注意，在删除操作中，被删除清空的桶不能直接标记为空桶。如上例中21、31、41为同义词，哈希值都为1，则按照开发地址法的原理，则它们分别存储的桶编号为1、2、3。如果在删除31时将桶2置为空，则查找41时，还没迭代到桶3就止步于空桶2，从而返回错误的结果。 我们的解决方案：一个桶根据是否存储键值对分为空(E)状态以及占用(O)状态，除此之外我们引入第三种删除(D)状态，通过Del删除操作的桶将处于此状态。 当执行查找或者删除操作时，我们将D状态桶以O状态处理，不会在D桶就停止向后迭代查询的过程；但当执行插入操作时，可以将此桶当做E状态处理，也即可以向此桶插入数据。 数据结构以及宏定义： 123456789101112131415161718192021222324const ( stateEmpty = iota //空状态 stateOccupied //占用状态 stateDeleted //删除状态 defaultSize = 128 //初始默认桶的个数)type pair struct &#123; state int //bucket状态 key int //键 value int //值&#125;// 每个桶存取一个键值对type HashMap struct &#123; buckets []pair // 桶 count int // 键值对个数&#125;func NewHashMap() *HashMap &#123; return &amp;HashMap&#123; buckets: make([]pair, defaultSize), &#125;&#125; 提供一个通用的access方法，这个方法将被Set、Get、Del方法使用： 12345678910111213141516171819202122// hash函数采用最简单的取模func (hm *HashMap) hash(key int) int &#123; return key % len(hm.buckets)&#125;// inSet设为true代表执行Set操作// 当执行Set操作时，找到存储key的桶、或者第一个空桶、或者Delete状态的桶，就结束遍历// 当执行Get、Del操作时，碰到存储key的桶或者第一个空桶就结束遍历func (hm *HashMap) access(key int, inSet bool) (p *pair) &#123; h := hm.hash(key) for i := 0; i &lt; len(hm.buckets); i++ &#123; bucket := hm.buckets[h] if !inSet &amp;&amp; bucket.state == stateDeleted || bucket.state == stateOccupied &amp;&amp; bucket.key != key &#123; h = (h + 1) % len(hm.buckets) continue &#125; p = &amp;hm.buckets[h] break &#125; return&#125; 前面提到，对map的操作，除了要查看哈希指向的桶外，还要因为同义词问题查看后续的一些桶。 对于Get查找以及Del删除这两个查询操作，我们的线性迭代终止于碰到存储了对应key的目标桶或者碰到了空桶，前者代表map中保存了此key，后者表示未保存该key。 对于Set方法，它有两种可能：①map中键已存在，我们将对应桶的value更新。②map中键不存在，我们找到一个空桶或者处于Delete状态的桶进行插入即可。 access方法就是把上述各情况下终止迭代的桶返回，我们再判断桶的state成员即状态，就可以知道该做哪些操作。 Set、Del以及Get方法： 1234567891011121314151617181920212223242526272829303132333435363738func (hm *HashMap) set(key int, value int) &#123; p := hm.access(key, true) //如果终止迭代的桶为非占用桶，即为空桶或者已被删除的桶，我们需要插入KV if p.state != stateOccupied &#123; hm.count++ p.state = stateOccupied p.key = key &#125; //否则，只需要更新value p.value = value&#125;func (hm *HashMap) Set(key int, value int) &#123; //如果负载因子过大，就需要扩容 if hm.needGrow() &#123; hm.grow() &#125; hm.set(key, value)&#125;func (hm *HashMap) Del(key int) &#123; p := hm.access(key, false) //终止于空桶，说明map并未存取该key if p.state == stateEmpty &#123; return &#125; hm.count-- p.state = stateDeleted&#125;func (hm *HashMap) Get(key int) (val int, ok bool) &#123; p := hm.access(key, false) //终止于空桶，说明map并未存取该key if p.state == stateEmpty &#123; return &#125; return p.value, true&#125; 上面grow方法用于在负载因子过大情况下进行扩容，我们扩容采取桶倍增的方式： 12345678910111213141516171819// 哈希表扩容func (hm *HashMap) grow() &#123; oldbuckets := hm.buckets //桶数量倍增 hm.buckets = make([]pair, len(oldbuckets)&lt;&lt;1) hm.count = 0 for i := 0; i &lt; len(oldbuckets); i++ &#123; bucket := oldbuckets[i] if bucket.state == stateOccupied &#123; //将旧桶数据插入新桶 hm.set(oldbuckets[i].key, oldbuckets[i].value) &#125; &#125;&#125;// 负载因子&gt;0.25时就扩容func (hm *HashMap) needGrow() bool &#123; return hm.count*4 &gt;= len(hm.buckets)&#125; 整体比较简单，理清楚增删改查的过程即可。 拉链法 对于拉链法实现，我们让预先分配内存的桶作为链表的头结点，同义词存在同一个桶后链表中。 欲查询键值对，只需要先通过hash定位到目标桶，然后遍历桶后的所有链表节点即可。欲插入键值对，还需要考虑已经存在键，需要覆盖value的情况。 数据结构定义： 123456789101112131415161718192021const defaultSize = 1024//存取键值对的链表节点，每个节点存取一个键值对type node struct &#123; key int value int next *node&#125;type bucket nodetype HashMap struct &#123; buckets []bucket //桶，每个桶还是链表的头结点，头结点实际不存取数据 count int&#125;func NewHashMap() *HashMap &#123; return &amp;HashMap&#123; buckets: make([]bucket, defaultSize), &#125;&#125; 基础操作方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172func (m *HashMap) hash(key int) int &#123; return key % len(m.buckets)&#125;//头插法插入节点func (m *HashMap) set(key int, value int, hash int) &#123; m.count++ m.buckets[hash].next = &amp;node&#123; key: key, value: value, next: m.buckets[hash].next, &#125;&#125;func (m *HashMap) Set(key int, value int) &#123; if m.needGrow() &#123; m.grow() &#125; //先通过哈希值找到对应桶 h := m.hash(key) //再遍历桶后同义词链表，查找key是否存在，如果存在则只需更新value即可 for n := m.buckets[h].next; n != nil; n = n.next &#123; if n.key == key &#123; n.value = value return &#125; &#125; //否则插入键值对 m.set(key, value, h)&#125;//查询func (m *HashMap) Get(key int) (value int, ok bool) &#123; h := m.hash(key) // 定位到桶后，顺序遍历桶后链表 for n := m.buckets[h].next; n != nil; n = n.next &#123; if n.key == key &#123; return n.value, true &#125; &#125; return&#125;//删除func (m *HashMap) Del(key int) &#123; h := m.hash(key) for n := (*node)(&amp;m.buckets[h]); n.next != nil; n = n.next &#123; tmp := n.next if tmp.key == key &#123; n.next = tmp.next m.count-- &#125; &#125;&#125;//负载因子&gt;=1就扩容func (m *HashMap) needGrow() bool &#123; return m.count &gt;= len(m.buckets)&#125;func (m *HashMap) grow() &#123; oldbuckets := m.buckets //倍增 m.buckets = make([]bucket, len(m.buckets)&lt;&lt;1) m.count = 0 for i := 0; i &lt; len(oldbuckets); i++ &#123; bucket := oldbuckets[i] for n := bucket.next; n != nil; n = n.next &#123; m.set(n.key, n.value, m.hash(n.key)) &#125; &#125;&#125; 逻辑方面比开放地址法更简单。如果负载因子过大，则会让每个桶后的链表过长，因此区分同义词还是需要遍历链表，从而使效率变低。甚至在极端情况，所有key都是同义词，查找时间效率最差为O(n)。 我们这里采取的负载因子上限为1，也就说如果哈希均匀的情况下，每个桶后链表仅存储一个节点，查询的时间开销为O(1)。 我们所写的均为最简实现，但已经把拉链法最核心的思想展现，其他的只是些优化技巧，比如哈希的取模操作转化为位运算、预先分配溢出桶、一个桶存取多个键值对减少节点数以优化内存占用以及gc等，这些我们会在go语言的map源码剖析中详解。 总结从最基本原理角度出发，抛开各种优化，其实实现一个基本能用的hash表也仅仅只需要100行左右代码。","categories":[{"name":"Map","slug":"Map","permalink":"http://example.com/categories/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"http://example.com/tags/Map/"}]},{"title":"从零实现Golang的HTTP标准库-（6）","slug":"从零实现Golang的HTTP标准库-（6）","date":"2022-10-09T00:20:00.000Z","updated":"2022-10-06T09:52:24.105Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（6）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%886%EF%BC%89.html","excerpt":"","text":"1.概述前文对Body进行了设置，不论客户端是使用Content-Type还是chunk编码的方式，服务端都能够正确的解析。本文将在Body功能的基础上，着重完成form表单中的multipart表单的解析。个人认为是整个框架最难实现部分，不过与chunkReader实现的思路类似，可以借鉴实现。 2.两种form表单客户端提交的form表单是利用http请求的报文主体部分携带的，前文已经做到了去轻松读取报文主体的字节数据，今天的任务就是从字节流中解析出表单内容。 按照RFC标准而言，POST请求存在两种表单： application&#x2F;x-www-form-urlencoded。只能用来提交纯文本请求参数，与url的queryString字段起一样的作用，例前端的用户名和密码一般通过这个表单传递给后端。 前端通过以下代码发起该form请求： 12345&lt;form action=&quot;/login&quot; method=&quot;post&quot; enctype=”application/x-www-form-urlencoded”&gt; name:&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt; password:&lt;input type=&quot;text&quot; name=&quot;password&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;login&quot;&gt; &lt;/form&gt; 转化为的报文大致如下： 1234567POST /login HTTP/1.1\\r\\n# 通过Content-Type告知对端传输的是哪种表单Content-Type: application/x-www-form-urlencoded Content-Length: 20\\r\\n#other unconcerned headers\\r\\nname=gu&amp;password=123 #报文主体 form表单会出现在报文主体部分，以&#x3D;拼接key、value，以&amp;拼接每一项，与queryString如出一辙。其解析很简单，相信读者坚持到这里后能够自行完成解析，用一个map保存KV即可，我们在下一讲中简要介绍。 multipart&#x2F;form-data。这个表单的功能比上一个表单强大许多，不仅可以发送文本请求，还可以发送任意数量的文件，当然功能强大的同时会增加解析的复杂度。 前端通过以下代码发起multipartForm请求： 1234567&lt;form action=&quot;/login&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; username:&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt; password:&lt;input type=&quot;text&quot; name=&quot;password&quot;&gt;&lt;br&gt; uploadFile:&lt;input type=&quot;file&quot; name=&quot;file1&quot;&gt;&lt;br&gt; uploadFile:&lt;input type=&quot;file&quot; name=&quot;file2&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;login&quot;&gt; &lt;/form&gt; 上述代码除了传输username和password文本信息外，还额外上传两个文件。 顾名思义，multipart表单会以一块(part)一块的方式传输上面的四部分。转化为的报文如下： 123456789101112131415161718192021222324POST /login HTTP/1.1\\r\\n[[ Less interesting headers ... ]]Content-Type: multipart/form-data; boundary=---------------------------735323031399963166993862150\\r\\nContent-Length: 414\\r\\n\\r\\n-----------------------------735323031399963166993862150\\r\\n #--boundary，注意比上面的boundary多了两个-Content-Disposition: form-data; name=&quot;username&quot;\\r\\n #第一部分，username\\r\\ngu\\r\\n-----------------------------735323031399963166993862150\\r\\n #--boundaryContent-Disposition: form-data; name=&quot;password&quot;\\r\\n #第二部分，password\\r\\n123\\r\\n-----------------------------735323031399963166993862150\\r\\n #--boundaryContent-Disposition: form-data; name=&quot;file1&quot;; filename=&quot;1.txt&quot;\\r\\n #第三部分，文件1Content-Type: text/plain\\r\\n\\r\\nContent of 1.txt.\\r\\n-----------------------------735323031399963166993862150\\r\\n #--boundaryContent-Disposition: form-data; name=&quot;file2&quot;; filename=&quot;2.html&quot;\\r\\n #第四部分，文件2Content-Type: text/html\\r\\n\\r\\n&lt;!DOCTYPE html&gt;&lt;title&gt;Content of 2.html.&lt;/title&gt;\\r\\n-----------------------------735323031399963166993862150--\\r\\n #--bounadry--标识表单结束 3.multipart表单详解以上面的报文为例，15行为报文首部，624行为报文主体用于存储表单。 上述表单总共被划分为4个部分，正好对应于html代码中的四项，每一部分之间以\\r\\n–boundary作为分隔符(delimiter)，其中boundary在首部的第3行给出，服务端知道boundary之后就可以区分不同的part。表单的末尾是以\\r\\n–boundary–为结束。要注意的是分隔符是\\r\\n–boundary，相较于boundary前面多了两个-(dash)。 multipart表单转化为报文分为几个部分，有些是文本，有些是文件。文件部分的头部比文本部分的头部多一个filename。各个部分之间通过\\r\\n–boundary来区分。Boundary在最开始设置，是一串随机数字。 但事实上很多客户端的实现都不会有这些空格，同时为了让代码更紧凑，我们将不考虑出现空格的情况，因此我们的框架并没有严格按照标准，读者须知。 每一个part中又分为两部分，第一个部分为头部信息，第二个部分为消息主体，头部信息遵循MIME标准，头部信息与消息主体之间通过两个CRLF分隔。如果该part用于传输文件，则在头部信息中还会多出filename字段。 4.解析思路先看看标准库的是如何解析multipart的，我们要做的就是模仿它的API(代码忽略了所有err)： 1234567891011121314func handleUpload(w http.ResponseWriter, r *http.Request) &#123; // 生成一个MultipartReader mr, _ := r.MultipartReader() // 通过NextPart就可以获取每一个part part, _ := mr.NextPart() // 如果没有了下一个part，err会返回io.EOF // 对part读取就能不多不少获取属于该part的消息主体(没有头部信息) data, _ := ioutil.ReadAll(part) // FileName不为空，则这part承载的是文件 if part.FileName() != &quot;&quot; &#123; fmt.Printf(&quot;filename=%s, data:\\n%s\\n&quot;, part.FileName(), data) &#125; else if part.FormName() != &quot;&quot; &#123; // 否则是文本信息 fmt.Printf(&quot;formname=%s, data:\\n%s\\n&quot;, part.FormName(), data) &#125;&#125; 先通过r.MultipartReader创建了一个multipart.Reader，multipartReader的NextPart方法作为迭代器，不停调用能够得到一个个part(我们演示里只调用了一次)，这个part是multipart.Part类型，实现了Reader接口，我们可以通过调用Read方法读取属于该part的内容。如果NextPart返回io.EOF错误，则代表没有下一个part了，表单处理完毕。part通过判断filename是否为空来判断这个part是传输文件还是文本。 API的使用非常的清晰简单，以part为单位依次处理，也很符合我们的逻辑。 尽管用户使用方便，但标准库肯定把解析的复杂性封装到了内部，可以推测标准库底层做了哪些工作以及存在哪些难点： 前文讲到每个part报文是分头部和消息主体两部分的，但上述代码中对part的读取只能读取消息主体部分，说明了头部信息已经被mr.NextPart()消费、预解析后存取在了part结构体的成员中。 part的Read方法只能读取属于该part的消息主体数据，所以必须得规定读取的结束，不能让其无限制对Body随意读从而将下一个part数据读出。每个part是以boundary为分割，所以只要发现boundary就说明该part数据读取完毕了，应该让Read方法返回io.EOF。 问题就出现在将不同的part区分开并不是很容易。对于chunk编码来说，是利用chunk size来标记这一块的长度，因此很轻松就可以区分不同的块。但对于multipart来说，是利用一特殊字符串标记范围的方式，我们需要进行数据的比对，找到boundary的出现位置。 如果我们能一开始把整个http报文主体先读完然后缓存起来，那么找出所有boundary的位置会简单许多，但这显然不现实。我们只能通过开辟固定大小缓存的方式，通过滑动窗口解决问题。 part的Read方法实现的大致思路： 注意：我们会利用bufio.Reader的缓存功能完成我们的需求，能完成下面代码的前提是您能完全了解bufio.Reader，熟悉它的Read以及Peek的原理。 此处确实需要很强的抽象思维，我尽量讲述清楚，读者如果心有困惑可以结合后续代码查看。 我们对上文实现的Body分配4KB的缓存形成一个bufio.Reader，以这个缓存作为滑动窗口，每次从Body中peek出4KB的数据(peek的目的就是预查看)，然后检测这4KB数据中是否出现分隔符\\r\\n–boundary，通过分隔符就可以确立两个part之间的交界，从而就能知道当前part应该读到哪就停止。 如果没有出现分隔符，则代表peek预查看的数据就属于当前的part，我们将这4KB的数据放心读出即可。 如果出现了分隔符，分隔符之前的数据属于该part，分隔符之后的数据属于下一个part，那么这个part只允许将分隔符之前的数据读出，剩下数据等待用户调用mr.NextPart切换到下一个part后读取。 事实上，对于第一种情况就算没有出现分隔符，我们也不能将这4KB全部当作该part数据读出，因为分隔符并不是一个字符，而是一个字符串，如果这个字符串前一半出现在这4KB数据的末尾，还有一半还在IO流中待读出，我们将这前一半也当作part数据读走后，multipart的解析绝对会出现问题，因此我们一次最多只能读取4KB-len(\\r\\n–boundary)+1的数据。 5.代码实现先介绍几个结构体的意义： MultipartReader结构体 1234567891011121314151617181920212223242526272829const bufSize = 4096 // 滑动窗口大小type MultipartReader struct &#123; // bufr是对Body的封装，方便我们预查看Body上的数据，从而确定part之间边界 // 每个part共享这个bufr，但只有Body的读取指针指向哪个part的报文， // 哪个part才能在bufr上读取数据，此时其他part是无效的 bufr *bufio.Reader // 记录bufr的读取过程中是否出现io.EOF错误，如果发生了这个错误， // 说明Body数据消费完毕，表单报文也消费完，不需要再产生下一个part occurEofErr bool crlfDashBoundaryDash []byte //\\r\\n--boundary-- crlfDashBoundary []byte //\\r\\n--boundary，分隔符 dashBoundary []byte //--boundary dashBoundaryDash []byte //--boundary-- curPart *Part //当前解析到了哪个part crlf [2]byte //用于消费掉\\r\\n&#125;//传入的r将是Request的Body，boundary会在http首部解析时就得到func NewMultipartReader(r io.Reader, boundary string) *MultipartReader &#123; b := []byte(&quot;\\r\\n--&quot; + boundary + &quot;--&quot;) return &amp;MultipartReader&#123; bufr: bufio.NewReaderSize(r, bufSize), //将io.Reader封装成bufio.Reader crlfDashBoundaryDash: b, crlfDashBoundary: b[:len(b)-2], dashBoundary: b[2 : len(b)-2], dashBoundaryDash: b[2:], &#125;&#125; multipartReader结构体对象：这个结构体对象代表读取某个multipart表单对应的请求报文结构中某一个部分part，它的属性都是和读取multipart表单该部分part相关的，所绑定的方法是获取multipart表单相关的方法。比如获取下一个部分的方法nextpart（），这个方法返回一个part结构体对象，part结构体介绍在下面。 multipartReader结构体绑定了初始化方法NewmultipartReader，初始化bufr时，调用bufio包下的newReader方法，传入底层的io.reader以及缓存切片的容量即可初始化，因为bufio.reader的底层其实就是io.reader加上一个缓存切片。 因为所有Part都会在bufr上读取数据，前面part将属于它的数据消费掉之后，后续的part才能读取自己的数据。因此我们用curPart记录当前是哪个part占有了bufr，方便我们对其管理。 我们的滑动窗口大小为4KB，每次peek固定4KB大小的数据，也就意味着我们可能从bufr的底层Reader中一次最多读出4KB的数据，用来填充缓冲区。既然会对底层的Reader读取，就可能产生错误，对于非io.EOF错误，我们直接返回即可。但对于io.EOF错误，只是意味着bufr底层的Reader流中没有了数据，并不意味着bufr的缓存中没数据，因此我们需要记录是否出现了io.EOF错误，如果出现了这个错误，我们只需要将bufr缓存里的数据处理完即可。 NextPart()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// https://www.gufeijun.com// 生成下一个part Readerfunc (mr *MultipartReader) NextPart() (p *Part, err error) &#123; if mr.curPart != nil &#123; // 将当前的Part关闭掉，即消费掉当前part数据，好让body的读取指针指向下一个part // 具体实现见后文 if err = mr.curPart.Close(); err != nil &#123; return &#125; if err = mr.discardCRLF(); err != nil &#123; return &#125; &#125; // 下一行就应该是boundary分割 line, err := mr.readLine() if err != nil &#123; return &#125; // 到multipart报文的结尾了，直接返回 if bytes.Equal(line, mr.dashBoundaryDash) &#123; return nil, io.EOF &#125; if !bytes.Equal(line, mr.dashBoundary) &#123; err = fmt.Errorf(&quot;want delimiter %s, but got %s&quot;, mr.dashBoundary, line) return &#125; // 这时Body已经指向了下一个part的报文 p = new(Part) p.mr = mr // 前文讲到要将part的首部信息预解析，好让part指向消息主体，具体实现见后文 if err = p.readHeader(); err != nil &#123; return &#125; mr.curPart = p return&#125;// 消费掉\\r\\nfunc (mr *MultipartReader) discardCRLF() (err error) &#123; if _, err = io.ReadFull(mr.bufr, mr.crlf[:]); err == nil &#123; if mr.crlf[0] != &#x27;\\r&#x27; &amp;&amp; mr.crlf[1] != &#x27;\\n&#x27; &#123; err = fmt.Errorf(&quot;expect crlf, but got %s&quot;, mr.crlf) &#125; &#125; return&#125;// 读一行func (mr *MultipartReader) readLine() ([]byte, error) &#123; return readLine(mr.bufr)&#125;// 直接利用了解析http报文首部的函数readHeader，很简单func (p *Part) readHeader() (err error) &#123; p.Header, err = readHeader(p.mr.bufr) return err&#125;// 将当前part剩余的数据消费掉，防止其报文残存在Reader上影响下一个partfunc (p *Part) Close() error &#123; if p.closed &#123; return nil &#125; _, err := io.Copy(ioutil.Discard, p) p.closed = true //标记状态为关闭 return err&#125; 实现很简单，NextPart首先会将当前的Part关闭，Close方法会将当前Part中用户未消费的数据给消费掉，防止影响下一个Part的读取。接着就是读取一行，将boundary读出，切换到下一个part，并将该part的Header解析，readHeader是往期文章的辅助函数。这时bufr的读取指针自然指向了part的消息主体部分，解决了part的读取指针初始指向的问题。 解析一下NextPart方法 这个方法也是绑定在multipart结构体上的，它的作用是返回下一个part结构体对象。如果curpart不为空，而我们此时要获取下一个part，所以要先将当前的part关闭，即消费掉当前part的数据。关闭后，读取一行数据，读到的应该就是分隔符。如果发现是表单结尾的分割符，说明表单读取结束了。如果既不是表单结尾分隔符，也不是中间分隔符，说明出错了，返回错误。此时读指针应该正好指向下一个part了，新建一个part结构体，赋值给p。p就代表下一个part，让这个p的mr属性等于当前的multipartReader结构体对象mr，代表这个part是从这个表单上读的。此时，读指针应该是指向表单中这个part的头部信息，而我们需要的是这个part的消息主体信息，所以调用readHeader方法预解析头部信息，预解析后读指针就刚好指向了这个新part的消息主体。然后将当前的multipartReader对象的curpart设定为当前这个新part，结束。nextPart方法就解析完了。 下面的重头戏就是Part结构的Read方法如何保证读取的结束了。 part结构体 12345678910type Part struct &#123; Header Header // 存取当前part的首部 mr *MultipartReader // 下两者见前面的part报文 formName string fileName string // 当该part传输文件时，fileName不为空 closed bool // part是否关闭 substituteReader io.Reader // 替补Reader parsed bool // 是否已经解析过formName以及fileName&#125; Part结构体对象：这个结构体对象实际上就是对应了multipart表单某个部分的映射。注意：上面那个对象实际上是一个读取相关的，而这里的part对象则是具体的一个部分实例。这个part结构体内部嵌套了multipartReader结构体对象这个属性。主要讲讲substituteReader，如果它不为空，我们对Part的Read则优先交给substituteReader处理，主要是为了方便引入io.LimiteReader来凝练我们的代码。substituteReader不为nil的时机，就是已经能够确定这个part还剩下多少数据可读了。这个见下面read代码就很容易理解。 part的read（）方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// https://www.gufeijun.comfunc (p *Part) Read(buf []byte) (n int, err error) &#123; // part已经关闭后，直接返回io.EOF错误 if p.closed &#123; return 0, io.EOF &#125; // 不为nil时，优先让substituteReader读取 if p.substituteReader != nil &#123; return p.substituteReader.Read(buf) &#125; bufr := p.mr.bufr var peek []byte //如果已经出现EOF错误，说明Body没数据了，这时只需要关心bufr还剩余已缓存的数据 if p.mr.occurEofErr &#123; peek, _ = bufr.Peek(bufr.Buffered()) // 将最后缓存数据取出 &#125; else &#123; //bufSize即bufr的缓存大小，强制触发Body的io，填满bufr缓存 peek, err = bufr.Peek(bufSize) //出现EOF错误，代表Body数据读完了，我们利用递归跳转到另一个if分支 if err == io.EOF &#123; p.mr.occurEofErr = true return p.Read(buf) &#125; if err != nil &#123; return 0, err &#125; &#125; //在peek出的数据中找boundary index := bytes.Index(peek, p.mr.crlfDashBoundary) //两种情况： //1.即||前的条件，index!=-1代表在peek出的数据中找到分隔符，也就代表顺利找到了该part的Read指针终点， // 给该part限制读取长度即可。 //2.即||后的条件，在前文的multipart报文，是需要boudary来标识报文结尾，然后已经出现EOF错误, // 即在没有多余报文的情况下，还没有发现结尾标识，说明客户端没有将报文发送完整，就关闭了链接， // 这时让substituteReader = io.LimitReader(-1)，逻辑上等价于eofReader即可 if index != -1 || (index == -1 &amp;&amp; p.mr.occurEofErr) &#123; p.substituteReader = io.LimitReader(bufr, int64(index)) return p.substituteReader.Read(buf) &#125; //以下则是在peek出的数据中没有找到分隔符的情况，说明peek出的数据属于当前的part //见上文讲解，不能一次把所有的bufSize都当作消息主体读出，还需要减去分隔符的最长子串的长度。 maxRead := bufSize - len(p.mr.crlfDashBoundary) + 1 if maxRead &gt; len(buf) &#123; maxRead = len(buf) &#125; return bufr.Read(buf[:maxRead])&#125; 这个part结构体绑定了一个read()方法，这个read方法实现了对这个multipart表单的这个部分的内容的正确读取。这里的read方法的作用其实就类似于上一章中从报文主体中读取chunk编码方式的内容，只不过现在是从报文主体中读取mutipart表单的内容。 Body中有数据，我们就每次取固定bufSize滑动窗口大小的数据进行处理；如果表单报文读完、没有数据了即出现io.EOF错误，我们只需要将bufr最后的缓存处理完毕即可。对应于代码的if else分支。 Peek方法出现io.EOF错误有两种情况：①一种异常：客户端主动关闭连接，提前终止。②Body的数据我们正常消费完毕了。不管是那种情况，Body都不能再读取，我们接下来只需要关注已经缓存且未处理的内容，通过bufr.Peek(bufr.Buffered())将最后缓存取出。因为第一种情况是我们不希望看到的(报文没发送完整)，第二种情况是正常情况，我们需要区分是那种原因导致了io.EOF，解决办法就是查看最后缓存中是否存在boundary(正常的multipart报文会以boundary标识结束)，存在则说明报文发送完整了，是第二种情况。 Part的Read指针应该终止在哪，也对应两种情况，一种是正常碰到该part与下一个part的分隔符，另一种是出现异常错误比如客户端主动断开连接提前终止。对于第一种情况，当前part最多能读取index个字节的数据，即将分隔符前的数据读完，对于第二种情况我们不能再读取即最多能读0B的数据，也就是说不管是哪一种情况，我们都知道这个Read方法最多还能读多少字节，从而比较巧妙地用io.LimitReader进行统一处理，代码优雅许多。对应代码的36~39行。 代码已经写了详细的注释，强烈建议读者自行思考实现一遍，才能真正理会这个解析过程。 再次梳理流程 是这样的，在文章（4）中，我们知道requset结构体中有一个属性叫作body，它是一个reader类型的属性，其实这个就是用来读取请求报文的报文主体的，但是要注意不要误认为body是用来存放报文主体的内容的，body实际上是一个接口，可以理解为他只是用来读取报文主体内容的一个方法。再回到第三章，这个chunkReader结构体实际上也是一个读取报文主体内容的接口，所以可以赋值给body。在这个chunkReader结构体内部，实际上是封装了一个属性，也即bufio包的reader，它是利用bufio包下的reader来实现读取内容的。我们知道bufio.reader里面有一个bufr切片，他其实是一个缓存切片。我们现在要干什么事呢？其实就是现在报文主体的内容不是和第三章一样那么简单了，现在报文主体内容中携带有mutipart表单了，以前读取简单的内容，现在我们读取复杂的内容，也就是利用bufio.reader从mutipart表单中读取内容，但是这个表单的内容部分分为了好几个part，不同part之间用分隔符标识。所以我们重新自定义一个切片叫peek，这个切片的大小是预先设定好了的，比如我们给它分配4kb，利用bufio.reader里面自带的缓存切片bufr的peek方法去从bufr里面预加载设定好的容量也即4kb到这个新切片peek中。此时，我们观察这个新切片peek，去看这个切片里是否含有分割符。注意：这里实际上有两个切片，一个是bufio.reader自带的切片bufr，它的作用是bufio.reader在读数据时先缓存进这个切片bufr当中。而我们自定义的新切片peek是用来存从bufr已缓存的内容中预加载的东西。bufr容量更大，peek容量设定好为4kb，每次从bufr中取出4kb放进peek。整体逻辑是bufio.reader先读，缓存进切片，然后再分情况是用io.reader的read读，还是就用bufio.reader的read方法读。如下。 如果发现切片peek中含有了分隔符，说明我们找到了part与part之间的临界点，切片中临界点后面的数据不属于当前part，此时我们规定读取的范围就到这个临界点，也就是说读取出数据，读到这个临界点时就正好把其中一个part不多不少的取出来了，但是这里并不是从切片中读。那么从哪里读取出来呢？它调用了substituReader，这个其实是一个io.reader类型的东西，io.reader是个什么东西呢？实际上io.reader就是对底层文件直接操作读取的意思，而bufr.reader就是先将底层文件预加载缓存到切片中，可以减少直接对底层文件的IO操作。所以io.reader实际上就是直接对底层文件读取，这里也就是直接对报文中body的某个part部分的读取，直接读取到临界点（通过limitreader方法限制范围）。 如果切片中没有发现分隔符，但是body数据已经读完了，此时也是直接调用io.reader来对底层数据直接读取。 如果切片中没有分隔符，也没有数据读完的报警，理论上说明此时切片中的数据就是当前part的数据，这时候我们读取数据是直接从切片中读取，而不是从底层读取。但是此时我们并不能安心的把切片中所有数据作为当前part的数据，因为有可能出现一种意外情况，就是分隔符还挺长的，如果一半出现则切片中，另一半还在底层文件，此时切片中也没有发现分隔符，但实际上切片中存在一半的分隔符，这部分内容不属于当前part的数据，需要剔除。这种情况无法针对性解决。只能从整体上防止这种情况的发生。通过设置从切片中读取的范围来防止这种情况，设置的读取长度length&#x3D;切片的容量减去分隔符的长度，这样可以始终保证切片从0到length范围内在这种情况下一定是当前part的数据，从length到切片结尾这段无法保证，就不读它，留着下一段缓存进来的时候再判断，这是因为切片有一个机制，你如果切片里内容没读完的话，本轮结束时它会清空内容，将剩余内容返回到底层body中去，这样即使没读完，下一轮预加载同样也可以接着上一轮的结尾了（这个设定在nextpart方法中，当前part结束时，会关闭当前part，并消费剩余内容）。 注意：这种情况下，我们读数据直接调用切片的read方法，即bufio.reader类型对象的read方法。Part的read方法到此结束。 再详解一下part的read方法具体代码 若发现当前part已被关闭，则不能再读，直接返回读取0字节和错误。如果发现substitueReader属性不为空，说明这个属性被赋过值了，这个属性的类型是io.reader类型的，上面我们提到如果发现切片含有分割符，我们要用io.reader直接从底层读取，因为这样可以用limitreader方法来保证恰好读取到分隔符。所以如果发现substitureader不为空，说明找到了分割符，我们就直接用substitureader的read方法读取。将当前part的所属表单的读接口bufr赋值给bufr，自定义了一个缓存切片叫peek。如果发现occurEofErr为true，说明读不到数据了，也即这个part的内容读完了，而我们一开始都是用bufio.reader将数据全部装入缓存切片中的，所以此时我们只需要将缓存切片中的剩余内容全部提取出来装进peek切片即可。如果没有错误，说明part的内容还没读完，我们只需要从缓存切片中提取4kb内容放进peek切片即可。也有可能缓存切片此时没有4kb的内容，报错了，但是此时occurEofErr还是false，所以我们将它设定为true，重新递归调用part的read方法，这样就会走上面那个将缓存切片剩余内容提取。此时peek中已有数据，我们在里面找分隔符的索引。如果发现索引不等于-1，说明在peek里面找到了分隔符，此时要用io的Limitreader来读到索引为止。或者没有找到分隔符，但是却出现了eof错误，说明客户端没有将报文发送完整，就关闭了连接，此时也用Limitreader来读到-1。若没有找到分隔符，如上，不能一次读完。 关于Part最硬核的操作已经完成，下面就是简单的工作。 为part提供获取formName以及fileName的方法，和http解析首部极为类似，就是简单的字符串处理，对比上述的part首部字段报文自行观看： 1234567891011121314151617181920212223242526272829303132333435363738394041// 获取FormNamefunc (p *Part) FormName() string &#123; if !p.parsed &#123; p.parseFormData() &#125; return p.formName&#125;// 获取FileNamefunc (p *Part) FileName() string &#123; if !p.parsed &#123; p.parseFormData() &#125; return p.fileName&#125;func (p *Part) parseFormData() &#123; p.parsed = true cd := p.Header.Get(&quot;Content-Disposition&quot;) ss := strings.Split(cd, &quot;;&quot;) if len(ss) == 1 || strings.ToLower(ss[0]) != &quot;form-data&quot; &#123; return &#125; for _, s := range ss &#123; key, value := getKV(s) switch key &#123; case &quot;name&quot;: p.formName = value case &quot;filename&quot;: p.fileName = value &#125; &#125;&#125;func getKV(s string) (key string, value string) &#123; ss := strings.Split(s, &quot;=&quot;) if len(ss) != 2 &#123; return &#125; return strings.TrimSpace(ss[0]), strings.Trim(ss[1], `&quot;`)&#125; 比较简单，不再赘述。 request.go MultipartReader已经搞定，万事具备，只欠东风。下面要做的就是从http协议的首部字段中解析出boundary，然后交给MultipartReader即可。 在request.go中增加如下方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344type Request struct &#123; // 本章给Request新增的属性 contentType string boundary string // ....&#125;func readRequest(c *conn) (r *Request, err error) &#123; // .... // 记得在readRequest中调用parseContentType r.parseContentType() return r, nil&#125;// boundary是存取在Content-Type字段中func (r *Request) parseContentType() &#123; ct := r.Header.Get(&quot;Content-Type&quot;) //Content-Type: multipart/form-data; boundary=------974767299852498929531610575 //Content-Type: multipart/form-data; boundary=&quot;&quot;------974767299852498929531610575&quot; //Content-Type: application/x-www-form-urlencoded index := strings.IndexByte(ct, &#x27;;&#x27;) if index == -1 &#123; r.contentType = ct return &#125; if index == len(ct)-1 &#123; return &#125; ss := strings.Split(ct[index+1:], &quot;=&quot;) if len(ss) &lt; 2 || strings.TrimSpace(ss[0]) != &quot;boundary&quot; &#123; return &#125; // 将解析到的CT和boundary保存在Request中 r.contentType, r.boundary = ct[:index], strings.Trim(ss[1],`&quot;`) return&#125;// 得到一个MultipartReaderfunc (r *Request) MultipartReader()(*MultipartReader,error)&#123; if r.boundary==&quot;&quot;&#123; return nil,errors.New(&quot;no boundary detected&quot;) &#125; return NewMultipartReader(r.Body,r.boundary),nil&#125; 前面我们定义了multipartReader结构体，他其实对应了读取一个表单的结构体。里面有一个分隔符boundary属性，这个属性需要从http请求的表单中解析出来才能拿到。解析表单分隔符的工作在readRequest方法中调用。 ParsecontentType方法解析出分隔符。 解析出来以后赋值给request结构体的分隔符属性。另外，这个multipartreader结构体里面还有一个bufio.reader属性，这个应该就是和chunkReader结构体里面一样的，因为这两个结构体的意义其实是一样的嘛，都是用来读取报文主体内容的。 6.测试测试很简单，对于前段传输的multipart表单，如果part传输的是文本，我们将其输出到中断，如果是文件，我们对文件保存到硬盘上。 main.go代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;example/httpd&quot; &quot;fmt&quot; &quot;io&quot; &quot;log&quot; &quot;os&quot;)type myHandler struct&#123;&#125;func (*myHandler) ServeHTTP(w httpd.ResponseWriter, r *httpd.Request) &#123; mr, err := r.MultipartReader() if err != nil &#123; log.Println(err) return &#125; var part *httpd.Partlabel: for &#123; part, err = mr.NextPart() if err != nil &#123; break &#125; // 判断是文本part还是文件part switch part.FileName() &#123; case &quot;&quot;: //文本 fmt.Printf(&quot;FormName=%s, FormData:\\n&quot;, part.FormName()) // 输出到终端 if _, err = io.Copy(os.Stdout, part); err != nil &#123; break label &#125; fmt.Println() default: //文件 // 打印文件信息 fmt.Printf(&quot;FormName=%s, FileName=%s\\n&quot;, part.FormName(), part.FileName()) var file *os.File if file, err = os.Create(part.FileName()); err != nil &#123; break label &#125; if _, err = io.Copy(file, part); err != nil &#123; file.Close() break label &#125; file.Close() &#125; &#125; if err != io.EOF &#123; fmt.Println(err) &#125; // 发送响应报文 io.WriteString(w, &quot;HTTP/1.1 200 OK\\r\\n&quot;) io.WriteString(w, fmt.Sprintf(&quot;Content-Length: %d\\r\\n&quot;, 0)) io.WriteString(w, &quot;\\r\\n&quot;)&#125;func main() &#123; svr := &amp;httpd.Server&#123; Addr: &quot;127.0.0.1:80&quot;, Handler: new(myHandler), &#125; panic(svr.ListenAndServe())&#125; 利用curl测试我们的接口： 12#发送两个文本，上传两个文件：1.md以及2.md$ curl -F &quot;username=gu&quot; -F &quot;password=123&quot; -F &quot;file1=@1.md&quot; -F &quot;file2=@2.md&quot; http://127.0.0.1 服务端输出： 123456FormName=username, FormData:guFormName=password, FormData:123FormName=file1, FileName=1.mdFormName=file2, FileName=2.md 查看服务端程序所在目录，正确保存了1.md以及2.md文件，且保存的文件hash值与原文件相同。 7.总结本文完成了multipart&#x2F;form-data表单的解析，难度比较高，需要多加理解。但我们提供的解析表单API依旧比较繁琐，下一文会在今天的基础上，再做封装。","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-（5）","slug":"从零实现Golang的HTTP标准库-（5）","date":"2022-10-08T00:20:00.000Z","updated":"2022-10-06T09:23:19.192Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（5）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%885%EF%BC%89.html","excerpt":"","text":"1.概述前文进行了Request首部字段的解析，已经完整的支持了GET请求。对于POST请求来说，其传送的表单数据在HTTP请求的报文主体body部分，服务端需要进一步IO操作才能读出，为了提高性能我们将POST表单的解析权交给用户，为此我们给Request结构体封装一个Body字段，作为IO的接口。 2.如何知道报文主体的长度以下一段http协议post请求报文为例： 12345678910POST /index?name=gu HTTP/1.1\\r\\n #请求行Content-Type: text/plain\\r\\n #此处至报文主体为首部字段User-Agent: PostmanRuntime/7.28.0\\r\\nHost: 127.0.0.1:8080\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nCookie: uuid=12314753; tid=1BDB9E9; HOME=1\\r\\nContent-Length: 18\\r\\n\\r\\nhello,I am client! #报文主体 报文主体与首部字段之间通过两个\\r\\n(CRLF)为分隔。前文中我们框架已经解析出了首部字段，本文的任务就是解析报文主体部分。 报文主体就是用于携带客户端的额外信息，Body报文主体部分只有post或者put请求才会有。由于报文主体中能包含任何信息，更是不限长度，所以http协议就不能像首部字段一样以某个字符如CRLF为边界，来标记报文主体的范围。那么客户端是怎么保证服务端能够完整的不多不少的读出报文主体数据呢？ 其实很简单，我们只要在首部字段中用一项标记报文主体长度，就解决了问题。就以上述报文为例，首部字段中包含一个Content-Length字段，其值为18，服务端随后从tcp连接中读取18个字节的数据，就正好把hello,I am client!这18B的数据读出，恰恰满足我们的需要。 当然除了使用Content-Length之外，http还可以使用chunk编码的方式，这里先埋个伏笔。 3.需求分析还是得明确一点，http报文的头部部分很短，上一章中框架将这部分读取并解析后直接交给用户，既省时也省力。 但问题是http的报文主体是不限长度的，框架无脑将这些字节数据读出来，是很糟糕的设计。 最明智的做法是，将这个解析的主动权交给用户，框架只提供方便用户读取解析报文主体的接口而已。 因此在上文中，Request中存在一个Body(io.Reader接口类型)字段，用户对Body的读取就正好能读出对应的报文主体。 仅仅让Body能读取到报文主体还不行，为了防止读多或读少，用户还需要限定只读取上述的Content-Length的长度，让用户手动指定读取长度的方式很麻烦也极为出错，我们想要的是能够达到以下效果： 12345678func (*myHandler) ServeHTTP(w httpd.ResponseWriter,r *httpd.Request)&#123; // 不需要指定长度就能将报文主体不多不少读出 buf,err:=ioutil.ReadAll(r.Body) if err!=nil&#123; return &#125; fmt.Printf(&quot;%s\\n&quot;,buf)&#125; 要保证Body达到我们期望的行为，这就意味着Body提供的Read方法能够保证以下两点： 对Body读取的这个指针一开始应该指向报文主体的开头，也就是说不能将报文主体前面的首部字段读出。规定了读取的起始。 多个http的请求相继在tcp连接上传输，当前http请求的Body就应该只能读取到当前请求的报文主体，即只能读取Content-Length长度的数据。规定了读取的结束。 如果单纯保证第一点，完全可以用上一文中conn结构体的bufr字段作为Body，因为我们已经将首部字段从bufr中读出，下一次对bufr的读取自然会从报文主体开始。 但这样做，第二点就无法满足。在go语言中，对一个io.Reader的读取，如果返回io.EOF错误代表我们将这个Reader中的所有数据读取完了。ioutil.ReadAll就是利用了这个特点，如果不出现一些异常错误，它会不停的读取数据直至出现io.EOF。而一个网络连接net.Conn，只有在对端主动将连接关闭后，对net.Conn的Read才会返回io.EOF错误。所以就意味着如果服务端出现以下代码： 12conn,_ := listener.Accept()ioutil.ReadAll(conn) 只要客户端不主动关闭连接，我们也不设置超时事件，我们会永久的阻塞在第二行处。 将bufr设置成Body就有这个问题，对bufr的读取最终会落到底层tcp连接(net.Conn)的读取，就算我们把当前请求的报文主体读取出来了，只要客户端不关闭连接，我们会永久阻塞。要是客户端继续发送了下一个http请求，我们当前的body还会顺带把下一个请求报文读出来，这绝对是不满足我们的需求的。 所以必须保证Body这个Reader在将报文主体读取完毕即读取Content-Length长的数据后，立即返回一个io.EOF错误，通知ReadAll函数我们已经读取完毕了！ 现在的任务就是好好思量，Body的Read方法该如何设置，从而达到想要的效果。 4.代码实现思维敏锐的朋友可能已经有了解决方案，那就是用io.LimitReader！ 上文用它来解决无限解析首部字段的问题，这里又派上用场。我们只需要将N设置成Content-Length，在最多读取N字节的长度后，LimitReader就会返回io.EOF错误，问题也迎刃而解。 在readRequest中有一个setupBody方法，其实readRequest方法就是从一个请求报文中读取数据从而创建一个request对象。所以setupBody方法其实就是从报文中解析报文主体部分来填充request对象的body属性。同时在解析出报文主体赋给body属性的同时，还规定了body的一些规则：比如规定body读取的起始以及结尾。 更改request.go的setupBody方法： 12345678910111213141516func (r *Request) setupBody() &#123; if r.Method != &quot;POST&quot; &amp;&amp; r.Method != &quot;PUT&quot; &#123; r.Body = &amp;eofReader&#123;&#125; //POST和PUT以外的方法不允许设置报文主体 &#125;else if cl := r.Header.Get(&quot;Content-Length&quot;); cl != &quot;&quot; &#123; //如果设置了Content-Length contentLength, err := strconv.ParseInt(cl, 10, 64) if err != nil &#123; r.Body = &amp;eofReader&#123;&#125; return &#125; // 允许Body最多读取contentLength的数据 r.Body = io.LimitReader(r.conn.bufr, contentLength) &#125;else&#123; r.Body = &amp;eofReader&#123;&#125; &#125;&#125; 对于非PUT以及POST方法，按照http协议的规定是不允许设置报文主体的，所以我们将Body设置成eofReader就好，对它的Read只会返回io.EOF错误。 5.chunk上面这种方法是针对客户端发请求过来，带有content-length的情况，还有一种情况不带content-length，而是采用chunk编码的方式分块传输。 除了通过Content-Length通知对端报文主体的长度外，http1.1引入了新的编码方式——chunk编码(分块传输编码)，顾名思义就是会将报文主体分块后进行传输。 利用Content-Length存在一个问题：我们需要事先知道待发送的报文主体长度，而有些时候我们是希望数据边产生边发送，根本无从知道将要发送多少的数据。因此http1.1相较http1.0除了长连接之外的另一大改进就是引入了chunk编码，客户端需要在请求头部设置Transfer-Encoding: chunked。 chunk编码的示例： 12345678910111213HTTP/1.1 200 OK\\r\\nContent-Type: text/plain\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n# 以下为body17\\r\\n #chunk sizehello, this is chunked \\r\\n #chunk dataD\\r\\n #chunk sizedata sent by \\r\\n #chunk data7\\r\\n #chunk sizeclient!\\r\\n #chunk data0\\r\\n\\r\\n #end 每一分块中包含两部分： 第一部分为chunk size，代表该块chunk data的长度，利用16进制表示。 第二部分为chunk data，该区域存储有效载荷，实际欲传输的数据存储在这部分。 chunk size与chunk data之间都利用\\r\\n作为分割，通过0\\r\\n\\r\\n来标记报文主体的结束。 6.chunkReader这个时候body属性的赋值就不是像content-length那样了，而是给body赋值了一个chunkReader结构体对象。 这个chunkreader结构体对象同样要规定body可读的开头和结尾。这个chunkreader结构体对象有一个read方法，调用read（）方法可以读取出chunk编码内的报文内容。 在readRequest方法中的setupbody方法中，我们需要增加一个判断，判断当前请求是否采用了chunk编码方式，如果采用了chunk编码方式，就将chunkreader结构体对象赋值给body属性，否则还按content -length处理。 显然，我们对Body的设置就需要分类讨论了！ 抽象出一个chunkReader结构体，当客户端利用chunk传输报文主体时，我们将Body设置成chunkReader即可。那么这个chunkReader需要满足什么功能呢？ 依旧是满足上述Body的两点：规定Body读取的起始以及结尾。起始已经满足，重点考虑结尾的设计，我们这就不能使用LimitReader了，既然chunk编码的结束标志是0\\r\\n\\r\\n，那么我们的Read方法在碰到0\\r\\n\\r\\n时返回io.EOF错误即可，不允许继续向下读，因为后续的字节数据是属于下一个http请求。 如果仅做到将报文主体不多不少读出，但读取的数据包含chunk编码的控制信息(chunk size以及CRLF)，而我们只关心chunk data部分，还需要用户手动解码，这也是不可取的。 所以我们的chunkReader还需要具有解码chunk的功能，保证用户调用到的Read方法只读到有效载荷(chunk data)：hello, this is chunked data sent by client!。 新建chunk.go文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576type chunkReader struct &#123; //当前正在处理的块中还剩多少字节未读 n int bufr *bufio.Reader //利用done来记录报文主体是否读取完毕 done bool crlf [2]byte //用来读取\\r\\n&#125;func (cw *chunkReader) Read(p []byte) (n int, err error) &#123; // 报文主体读取完后，不允许再读 if cw.done &#123; return 0, io.EOF &#125; // 当前块没数据了，准备读取下一块 if cw.n == 0 &#123; // 先获取chunk Size cw.n, err = cw.getChunkSize() if err != nil &#123; return &#125; &#125; // 获取到的chunkSize为0，说明读到了chunk报文结尾 if cw.n == 0 &#123; cw.done = true //将最后的CRLF消费掉，防止影响下一个http报文的解析 err = cw.discardCRLF() return &#125; //如果当前块剩余的数据大于欲读取的长度 if len(p) &lt;= cw.n &#123; n, err = cw.bufr.Read(p) cw.n -= n return n, err &#125; //如果当前块剩余的数据不够欲读取的长度，将剩余的数据全部取出返回 n, _ = io.ReadFull(cw.bufr, p[:cw.n]) cw.n = 0 //记得把每个chunkData后的\\r\\n消费掉 if err = cw.discardCRLF(); err != nil &#123; return &#125; return&#125;func (cw *chunkReader) discardCRLF() (err error) &#123; if _, err = io.ReadFull(cw.bufr, cw.crlf[:]); err == nil &#123; if cw.crlf[0] != &#x27;\\r&#x27; || cw.crlf[1] != &#x27;\\n&#x27; &#123; return errors.New(&quot;unsupported encoding format of chunk&quot;) &#125; &#125; return&#125;func (cw *chunkReader) getChunkSize() (chunkSize int, err error) &#123; line, err := readLine(cw.bufr) if err != nil &#123; return &#125; //将16进制换算成10进制 for i := 0; i &lt; len(line); i++ &#123; switch &#123; case &#x27;a&#x27; &lt;= line[i] &amp;&amp; line[i] &lt;= &#x27;f&#x27;: chunkSize = chunkSize*16 + int(line[i]-&#x27;a&#x27;) + 10 case &#x27;A&#x27; &lt;= line[i] &amp;&amp; line[i] &lt;= &#x27;F&#x27;: chunkSize = chunkSize*16 + int(line[i]-&#x27;A&#x27;) + 10 case &#x27;0&#x27; &lt;= line[i] &amp;&amp; line[i] &lt;= &#x27;9&#x27;: chunkSize = chunkSize*16 + int(line[i]-&#x27;0&#x27;) default: return 0, errors.New(&quot;illegal hex number&quot;) &#125; &#125; return&#125; 我们用一个结构体成员n来记录当前块剩余未处理的的chunk data长度，一旦该块的数据读取完毕后就通过chunk size获取下一块的长度。 chunk编码的控制信息全部在Read方法内部消费掉了，外界能读取的仅仅只有chunk data。 详解chunk.go 首先我们定义一个chunkReader的结构体，这个结构体如果被赋值给请求对象的body属性，就代表我们将采用chunk编码的方式来读取报文主体。body属性的类型是io.reader，所以这个chunkReader类型也是reader类型的，这个结构体里面有几个属性，n代表当前正在读取的chunk块还剩多少字节未读。bufr是一个bufio.reader类型的对象，等于是这个reader里面封装了一个bufio.reader，主要是用这个bufr来读。一个bool类型的done表示所有的块是否被读完，也即报文主体是否被读完。最后有一个切片名叫crlf，用来读取换行符。 详解chunkReader的read（）方法 cw是chunkReader结构体的对象，若发现cw的done属性为true，说明报文主体全部读取完毕，返回io.eof错误停止读。如果发现cw的n属性为0，说明当前读取的chunk块读完了，应当读取下一个chunk块。所以调用getchunksize方法获取下一个chunk块的长度赋值给n，代表下一个chunk块还有n长度未读。如果此时发现n还是为0，说明读完了，将done设置为true，将最后的crlf消费掉，防止影响下一个http报文的解析。如果发现切片p的长度&lt;当前chunk中未读取的长度，说明一次读不完，要分几次来读。所以我们先调用那个bufio类型的reader里面的那个read方法，这个read方法可以看下面的蓝色链接，这个read方法返回的是已经读取的字节数，所以我们调用这个read先读取一部分数据进入p中，并获取了已经读取的字节数，再让当前cw属性的n（代表未读数）减去已经读取的字节数，就是还剩下的未读数。调用bufio.reader的目的就是为了让块剩余未读数量小于切片p的长度。如果发现切片p的长度&gt;当前chunk中未读取的长度，说明可以一次读完，直接将块中剩下的数据全部读到切片p中，这里用的方法是io.readfull，这个方法应该就会在将数据放入p的同时将p中读到的数据上传上去。将cw的n属性设为0。消费crlf。read方法至此详解结束。 别忘了更改request.go中的setupBody方法： 12345678910111213141516171819202122232425// 对端是否使用了chunk编码func (r *Request) chunked() bool &#123; te := r.Header.Get(&quot;Transfer-Encoding&quot;) return te == &quot;chunked&quot;&#125;func (r *Request) setupBody() &#123; if r.Method != &quot;POST&quot; &amp;&amp; r.Method != &quot;PUT&quot; &#123; r.Body = &amp;eofReader&#123;&#125; //POST和PUT以外的方法不允许设置报文主体 &#125;else if r.chunked()&#123; r.Body = &amp;chunkReader&#123;bufr: r.conn.bufr&#125; r.fixExpectContinueReader() //见下文 &#125; else if cl := r.Header.Get(&quot;Content-Length&quot;); cl != &quot;&quot; &#123; //如果设置了Content-Length contentLength, err := strconv.ParseInt(cl, 10, 64) if err != nil &#123; r.Body = &amp;eofReader&#123;&#125; return &#125; r.Body = io.LimitReader(r.conn.bufr, contentLength) r.fixExpectContinueReader() &#125;else&#123; r.Body = &amp;eofReader&#123;&#125; &#125;&#125; 做到这一点后，不论客户端时使用Content-Length还是chunk编码，用户看到的Body这个Reader都具有一样的行为即不多不少读到有效载荷，用户不需要自己手动分类处理，这就是封装的思想以及go语言接口的妙用。 注意：这里其实只是对body属性赋值了chunkreader对象，而没有去调用chunkreader的read方法，那是在哪里去调用的这个read方法呢？其实是在main文件测试中，调用listenandserve方法，然后进去调用serve方法，再调用serveHTTP方法，在serveHTTP方法中，我们调用ioutil.readAll方法来读取请求的body属性，在这个底层才调用了read方法，将读到的内容存入buf中，然后再利用serveHTTP方法的第一个参数：这个ResponseWriter类型的w，来往w里面写入buf，相当于将读到的报文主体内容原封不动写回去来构造一个回显响应。这个serveHTTP方法的第一个参数我原来一直以为就是响应，其实不是，它是一个用来写响应的输入器。 细心的你应该发现了我们多出了一个fixExpectContinueReader方法。这是因为为了防止资源的浪费，有些客户端在发送完http首部之后，发送body数据前，会先通过发送Expect: 100-continue查询服务端是否希望接受body数据，服务端只有回复了HTTP&#x2F;1.1 100 Continue客户端才会再次发送body。因此我们也要处理这种情况： 1234567891011121314151617181920212223242526type expectContinueReader struct&#123; // 是否已经发送过100 continue wroteContinue bool r io.Reader w *bufio.Writer&#125;func (er *expectContinueReader) Read(p []byte)(n int,err error)&#123; //第一次读取前发送100 continue if !er.wroteContinue&#123; er.w.WriteString(&quot;HTTP/1.1 100 Continue\\r\\n\\r\\n&quot;) er.w.Flush() er.wroteContinue = true &#125; return er.r.Read(p)&#125;func (r *Request) fixExpectContinueReader() &#123; if r.Header.Get(&quot;Expect&quot;) != &quot;100-continue&quot; &#123; return &#125; r.Body = &amp;expectContinueReader&#123; r: r.Body, w:r.conn.bufw, &#125;&#125; 实现也很简单，一旦发现客户端的请求报文的首部中存在Expect: 100-continue，那么我们在第一次读取body时，也就意味希望接受报文主体，expectContinueReader会自动发送HTTP&#x2F;1.1 100 Continue。 我们的框架目前依旧存在一个问题，如果用户在Handler的回调函数中没有去读取Body的数据，就意味着处理同一个socket连接上的下一个http报文时，Body未消费的数据会干扰下一个http报文的解析。所以我们的框架还需要在Handler结束后，将当前http请求的数据给消费掉。给Request增加一个finishRequest方法，以后的一些善尾工作都将交给它： 123456789func (r *Request) finishRequest() (err error)&#123; //将缓存中的剩余的数据发送到rwc中 if err=r.conn.bufw.Flush();err!=nil&#123; return &#125; //消费掉剩余的数据 _,err = io.Copy(ioutil.Discard,r.Body) return err&#125; 在conn.go的serve方法中调用finishRequest： 12345678910111213141516171819202122func (c *conn) serve()&#123; defer func() &#123; if err:=recover();err!=nil&#123; log.Printf(&quot;panic recoverred,err:%v\\n&quot;,err) &#125; c.close() &#125;() //http1.1支持keep-alive长连接，所以一个连接中可能读出 //多个请求，因此实用for循环读取 for&#123; req,err:=c.readRequest() if err!=nil&#123; handleErr(err,c) return &#125; res:=c.setupResponse() c.svr.Handler.ServeHTTP(res,req) if err=req.finishRequest();err!=nil&#123; return &#125; &#125;&#125; 7.测试目前已经可以很方便的解析报文主体了，我们的测试代码如下： 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;example/httpd&quot; &quot;fmt&quot; &quot;io&quot; &quot;io/ioutil&quot;)type myHandler struct&#123;&#125;// echo回显服务器，将客户端的报文主体原封不动返回func (*myHandler) ServeHTTP(w httpd.ResponseWriter, r *httpd.Request) &#123; buf, err := ioutil.ReadAll(r.Body) if err != nil &#123; return &#125; const prefix = &quot;your message:&quot; io.WriteString(w, &quot;HTTP/1.1 200 OK\\r\\n&quot;) io.WriteString(w, fmt.Sprintf(&quot;Content-Length: %d\\r\\n&quot;, len(buf)+len(prefix))) io.WriteString(w, &quot;\\r\\n&quot;) io.WriteString(w, prefix) w.Write(buf)&#125;func main() &#123; svr := &amp;httpd.Server&#123; Addr: &quot;127.0.0.1:80&quot;, Handler: new(myHandler), &#125; panic(svr.ListenAndServe())&#125; 利用curl测试，使用Content-Type方式： 12345678# -d用于加上报文主体curl -d &quot;hello, this is chunked message from client!&quot; http://127.0.0.1 -i输出：HTTP/1.1 200 OKContent-Length: 56your message:hello, this is chunked message from client! 使用chunk编码的方式： 1234567$ curl -H &quot;Transfer-Encoding: chunked&quot; -d &quot;hello, this is chunked message from client!&quot; http://127.0.0.1 -i输出：HTTP/1.1 200 OKContent-Length: 56your message:hello, this is chunked message from client! 不论是用哪一种方法传输报文主体，服务端都能够正确的解析。 客户端的Form表单以报文主体为载体，所以Body的设置是解析Form表单的基础，下一文将对两种表单：application&#x2F;x-www-form-urlencoded以及multipart&#x2F;form-data进行解析。 8.总结这章整体的一个逻辑是：request结构体对象c会绑定一个readRequest方法，这个readRequest方法是用来构造serveHTTP方法的第二个参数的req的，而这个readRequest方法内部会解析请求行，解析首部字段，这两个都是上一章的内容。同时readRequest方法内部还会调用setupBody方法，这个就是解析报文主体，就是我们这一章的内容。setupBody里面会判断是采用chunk方法还是采用content-length方法，然后分别构造body。其中若采用chunk方法，就会给body属性赋值chunkReader对象。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-（4）","slug":"从零实现Golang的HTTP标准库-（4）","date":"2022-10-07T00:20:00.000Z","updated":"2022-10-06T06:47:54.562Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（4）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%884%EF%BC%89.html","excerpt":"","text":"1.概述本文将正式开始HTTP协议的解析，主要完成Request结构体的属性组成，HTTP请求报文首部字段以及请求行的解析。 2.项目结构因为在这一章中，我们会完成客户端请求报文中首部字段的解析，首部字段为一个个键值对，显而易见的是使用map结构进行一个存储，所以增加header.go文件，其中存在Header结构体，专门用于存放请求报文中请求行的键值对。此处并非重点也极为简单，所以直接从标准库中拷贝，读者自行理解： 1234567891011121314151617181920212223242526package httpdtype Header map[string][]stringfunc (h Header) Add(key, value string) &#123; h[key] = append(h[key], value)&#125;// 插入键值对func (h Header) Set(key, value string) &#123; h[key] = []string&#123;value&#125;&#125;// 获取值，key不存在则返回空func (h Header) Get(key string) string &#123; if value, ok := h[key]; ok &amp;&amp; len(value) &gt; 0 &#123; return value[0] &#125; else &#123; return &quot;&quot; &#125;&#125;// 删除键func (h Header) Del(key string) &#123; delete(h, key)&#125; Header是一个map类型，用来存储请求报文中首部字段的所有键值对。并且绑定了增删改查键值对的方法。 3.需求分析我们需要为Request结构体增加相应的属性，就应该从http请求报文出发，看看我们需要保存哪些信息。一段http请求报文： 12345678910POST /index?name=gu HTTP/1.1\\r\\n #请求行Content-Type: text/plain\\r\\n #此处至报文主体为首部字段User-Agent: PostmanRuntime/7.28.0\\r\\nHost: 127.0.0.1:8080\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nCookie: uuid=12314753; tid=1BDB9E9; HOME=1\\r\\nContent-Length: 18\\r\\n\\r\\nhello,I am client! #报文主体 http的请求报文分为三部分： 请求行(第一行)分别由方法Method、请求路径URL以及协议版本Proto组成。将这三者加入到Request结构即可。 首部字段由一个个键值对组成，我们的头部信息就存放在此处。这部分就用上面讲到了的Header存储。 报文主体部分，相较于前面两个更为复杂，可能具有不同的编码方式，长度也可能特别大。平时前端提交的form表单就放置在报文主体部分。仅只有POST和PUT请求允许携带报文主体。 本篇只涉及前两部分的解析，读者需知。 除此之外，像cookie以及queryString(如上面的URL中的?name&#x3D;gufeijun)，是日常开发经常使用到的部分，为了方便用户的获取，我们分别用cookies以及queryString这两个map去保存解析后的字段。因此Request结构体如下： 123456789101112type Request struct&#123; Method string //请求方法，如GET、POST、PUT URL *url.URL //URL Proto string //协议以及版本 Header Header //首部字段 Body io.Reader //用于读取报文主体 RemoteAddr string // 客户端地址 RequestURI string //字符串形式的url conn *conn //产生此request的http连接 cookies map[string]string //存储cookie queryString map[string]string //存储queryString&#125; URL隶属于uri。 URI 就是由某个协议方案表示的资源的定位标识符。采用http协议时，协议方案就是http。URI 用字符串标识某一互联网资源，而 URL表示资源的具体地点（互联网上所处的位置）。可见 URL是 URI 的子集。 Body字段在下一章中讲解，读者只需要知道用户可以对(*Request).Body读取，进而读出当前请求的报文主体即可。 4.readRequest上一章我们将框架的骨干搭好后，这里开始第一个空白处readRequest的填充，它的作用就是从tcp字节流中解析http报文，从而封装出一个Request对象。 直接上代码，请对比着上述的http报文观看： 1234567891011121314151617181920212223242526272829303132func readRequest(c *conn)(r *Request,err error)&#123; r = new(Request) r.conn = c r.RemoteAddr = c.rwc.RemoteAddr().String() //读出第一行,如：Get /index?name=gu HTTP/1.1 line, err := readLine(c.bufr) if err != nil &#123; return &#125; // 按空格分割就得到了三个属性 _, err = fmt.Sscanf(string(line), &quot;%s%s%s&quot;, &amp;r.Method, &amp;r.RequestURI, &amp;r.Proto) if err != nil &#123; return &#125; // 将字符串形式的URI变成url.URL形式 r.URL, err = url.ParseRequestURI(r.RequestURI) if err != nil &#123; return &#125; //解析queryString r.parseQuery() //读header r.Header, err = readHeader(c.bufr) if err != nil &#123; return &#125; const noLimit = (1&lt;&lt;63)-1 r.conn.lr.N = noLimit //Body的读取无需进行读取字节数限制 //设置body r.setupBody() return r, nil&#125; 对readRequest方法的解读： 新建一个request的实例r，这个request的conn属性就是c；客户端地址就调用tcp连接的方法得到；readline用来读取出一行数据，传入的参数为bufr；这个读出来的是第一行，所以就是请求行的三个属性。 用到了一个parseRequsetURI方法，将URI转化为了URL，前面不是提到URL是URI的子集吗，这个应该就是一个转化，因为我们在第一行读取到的是URI，现在通过这个方法就可以拿到URL。又调用parseQuery（）方法解析&amp;&#x3D;？那个，解析出来一个个键值对，存放到一个叫querystring的map中。 再调用readHeader（）方法，这个方法同样是传入bufr，会返回一个Header。这个Header前面介绍过，就是一个map。用来存储首部字段里的所有键值对的。 最后调用setbody（）方法设置报文主体。 6~16行为解析请求行，分别读出Method、URI以及Proto。21行解析queryString。23行读取首部字段。30行设置Body。上述代码中有四个辅助函数：readLine、parseQuery、readHeader以及setupBody，这四个我们一个一个单独讲解。 5.readLine()上文提到bufio.Reader具有ReadLine方法，其存在三个返回参数line []byte, isPrefix bool, err error，line和err都很好理解，但为什么还多出了一个isPrefix参数呢？这是因为ReadLine会借助到bufio.Reader的缓存切片(见上篇)，如果一行大小超过了缓存的大小，这也会无法达到读出一行的要求，这时isPrefix会设置成true，代表只读取了一部分。 因此我们需要对ReadLine方法进行封装，得到readLine函数，能够保证缓存容量不足的情况下也能读出一行，如下： 123456789101112131415func readLine(bufr *bufio.Reader) ([]byte, error) &#123; p, isPrefix, err := bufr.ReadLine() if err != nil &#123; return p, err &#125; var l []byte for isPrefix &#123; l, isPrefix, err = bufr.ReadLine() if err != nil &#123; break &#125; p = append(p, l...) &#125; return p, err&#125; 只要isPrefix一直为true，我们则一直读取，并将读取的部分汇总在一起，直至读到\\r\\n。 6.parseQuery()对于客户端访问的url，如127.0.0.0?name&#x3D;gu&amp;token&#x3D;1234，其中name&#x3D;gu&amp;token&#x3D;1234即为queryString字段，将这部分以KV方式存入map中。 1234567891011121314151617func (r *Request) parseQuery() &#123; //r.URL.RawQuery=&quot;name=gu&amp;token=1234&quot; r.queryString = parseQuery(r.URL.RawQuery)&#125;func parseQuery(RawQuery string) map[string]string &#123; parts := strings.Split(RawQuery, &quot;&amp;&quot;) queries := make(map[string]string, len(parts)) for _, part := range parts &#123; index := strings.IndexByte(part, &#x27;=&#x27;) if index == -1 || index == len(part)-1 &#123; continue &#125; queries[strings.TrimSpace(part[:index])] = strings.TrimSpace(part[index+1:]) &#125; return queries&#125; 先以&amp;符为分隔得到一个个k-v对，然后以&#x3D;符为分割分别得到key以及value，存入map即可。 7.readHeader()readHeader实现很简单，一直调用readLine读取一行，如果碰到CR+LF(\\r\\n\\r\\n)，这时readLine读取到的该行长度为0，也即代表首部字段的结束。我们将读到的每一行都保存到header这个map中，代码如下： 123456789101112131415161718192021222324func readHeader(bufr *bufio.Reader) (Header, error) &#123; header := make(Header) for &#123; line, err := readLine(bufr) if err != nil &#123; return nil, err &#125; //如果读到/r/n/r/n，代表报文首部的结束 if len(line) == 0 &#123; break &#125; //example: Connection: keep-alive i := bytes.IndexByte(line, &#x27;:&#x27;) if i == -1 &#123; return nil, errors.New(&quot;unsupported protocol&quot;) &#125; if i == len(line)-1 &#123; continue &#125; k, v := string(line[:i]), strings.TrimSpace(string(line[i+1:])) header[k] = append(header[k], v) &#125; return header, nil&#125; 8.setupBody()Body的设置是本框架的重难点之一，它是一个提供给用户的读取报文主体的接口，其将涉及到报文主体的解析，将是下一章的内容。我们这里暂时将Body设置成eofReader，让用户目前在Handler中无法从Body中读取任何数据。此处读者可以暂时略过。 12345678910type eofReader struct &#123;&#125;// 实现了io.Reader接口func (er *eofReader)Read([]byte)(n int,err error)&#123; return 0,io.EOF&#125;func (r *Request)setupBody()&#123; r.Body=new(eofReader)&#125; 9.绑定方法Request结构中的cookie以及queryString字段都是私有属性，因为只希望用户具有查询的权限，而不能够进行删除或者修改。为了让用户去查询这个私有字段，需要绑定相应的公共方法，这就是封装的思想。 除了安全性之外，利用公有方法的方式也能让我们的控制更加灵活，可以实现懒加载(lazy load)，从而提升性能。 比如在gin框架中每一个gin.Context中都会有一个叫做keys的map，用于在HandlerChain中传输数据，用户可以调用Set方法存数据，Get方法取数据。显而易见，为了实现这个功能，我们需要在操作keys这个map之前，就为其make分配内存。问题就出现在，如果我在生成一个gin.Context之初就为这个map进行初始化，但如果用户的Handler中并未使用这个功能怎么办？这个为keys初始化的时间是不是白白浪费了？ 所以gin采用了比较高明的方式，在用户使用Set方法时，Set方法会先检测keys这个map是否为nil，如果为nil，这时我们才为其初始化。这样懒加载就能减少一些不必要的开销。 我们给域名生成的cookie，一旦颁发给用户浏览器之后，浏览器在访问我们域名下的后端接口时都会在请求报文中将这个cookie带上，要是后端接口不关心客户端的cookie，而框架无脑全部提前解析，这就做了徒工。 所以也需要将Cookie的解析滞后，不是在readRequest中解析，而是在用户接口有需求，调用Cookie方法第一次查询时再进行解析。这就是为什么readRequest中没有解析cookie代码的原因。 接下来为Request绑定两个公有方法Query以及Cookie，分别用于查询queryString以及cookie： 123456789101112131415161718192021222324252627282930313233343536373839// 查询queryStringfunc (r *Request) Query(name string) string &#123; return r.queryString[name]&#125;// 查询cookiefunc (r *Request) Cookie(name string) string &#123; if r.cookies == nil &#123; //将cookie的解析滞后到第一次cookie查询处 r.parseCookies() &#125; return r.cookies[name]&#125;func (r *Request) parseCookies() &#123; if r.cookies != nil &#123; return &#125; r.cookies = make(map[string]string) rawCookies, ok := r.Header[&quot;Cookie&quot;] if !ok &#123; return &#125; for _, line := range rawCookies &#123; //example(line): uuid=12314753; tid=1BDB9E9; HOME=1(见上述的http请求报文) kvs := strings.Split(strings.TrimSpace(line), &quot;;&quot;) if len(kvs) == 1 &amp;&amp; kvs[0] == &quot;&quot; &#123; continue &#125; for i := 0; i &lt; len(kvs); i++ &#123; //example(kvs[i]): uuid=12314753 index := strings.IndexByte(kvs[i], &#x27;=&#x27;) if index == -1 &#123; continue &#125; r.cookies[strings.TrimSpace(kvs[i][:index])] = strings.TrimSpace(kvs[i][index+1:]) &#125; &#125; return&#125; 解析很简单，就是字符串的处理。 下面再啰嗦一下关于cookie。 首先解释一下，当客户端向服务器请求过某个资源后，服务器会向这个客户端颁发一个cookie。下次客户端再向服务器请求这个资源时，在请求报文中会携带这个cookie。此时服务器端只需要解析这个cookie便可以快速拿到资源返回给客户端。 先理解一下解析cookie是什么意思？ 解析cookie 的意思是有一个请求报文过来，这个请求报文会对应一个request结构体对象，我们需要根据这个请求报文里面的信息来给request结构体对象的各个属性赋值。其中有一步就会将请求报文里面的cookie赋值给request对象的cookie属性。这个任务就叫做解析cookie。具体的解析方法就是一次请求报文过来时，报文里面会带有cookies字段，cookies属于首部字段。而所有的首部字段我们都存进header结构体中了，所以我们要做的就是将cookies从header中取出来。然后赋值给这个请求报文对应的requset结构体对象里面的cookies属性。 所以我们如果把解析cookie的任务放在readRequest方法中，那么不管此时这个请求报文对应的request对象的cookie属性是否为空，他都会全部解析一遍再赋值给cookie属性。其实有的请求报文不是第一次来了，它的cookie早就被解析过了，已经被赋值过，所以不需要重复的解析。故不能放在此处。 那放在哪里呢？标准库中给Request结构体绑定了两个公用方法，一个是查询&amp;？&#x3D;的，一个就是查询cookie的。这个查询方法什么时候被调用呢？当客户端有请求过来时，框架会调用查询方法，查询此时这个请求报文对应的request结构体对象中的那个cookie属性是否为空？如果为空，就从这个请求报文中解析出cookie来补上这个属性，让这个请求对象的cookie属性不为空。 注意：当请求同一个资源时，第一次请求，请求报文第一次过来时，不带有cookie，所以此时request结构体中cookie属性为空。第二次请求，即第二次这个请求报文过来时，带有cookie了，所以此时应当给这个请求报文对应的request对象补上这个cookie属性。 所以，我们将解析cookie的任务放在查询cookie的方法中，当此时请求报文对应的request对象的cookie属性为空，我们就解析请求报文中的cookie给对象。不为空时，我们就不解析，直接返回这个cookie就行了。 10.测试为了方便我们的测试，我们为response.go进行如下更改： 123456789101112131415type response struct&#123; c *conn&#125;type ResponseWriter interface&#123; Write([]byte)(n int,err error)&#125;func setupResponse(c *conn)*response&#123; return &amp;response&#123;c:c&#125;&#125;func (w *response) Write(p []byte)(int,error)&#123; return w.c.bufw.Write(p)&#125; 为ResponseWriter加入Write方法，同时让response实现这个接口。这样我们可以在Handler中可以使用Write方法与客户端交互，从而手动构造http响应报文。 同时记得要在conn.go文件中对setupResponse进行调用： 123func (c *conn) setupResponse()*response&#123; return setupResponse(c)&#125; 测试文件main.go如下： 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;bytes&quot; &quot;example/httpd&quot; &quot;fmt&quot; &quot;io&quot;)type myHandler struct &#123;&#125;func (*myHandler) ServeHTTP(w httpd.ResponseWriter,r *httpd.Request)&#123; // 用户的头部信息保存到buff中 buff:=&amp;bytes.Buffer&#123;&#125; // 测试Request的解析 fmt.Fprintf(buff,&quot;[query]name=%s\\n&quot;,r.Query(&quot;name&quot;)) fmt.Fprintf(buff,&quot;[query]token=%s\\n&quot;,r.Query(&quot;token&quot;)) fmt.Fprintf(buff,&quot;[cookie]foo1=%s\\n&quot;,r.Cookie(&quot;foo1&quot;)) fmt.Fprintf(buff,&quot;[cookie]foo2=%s\\n&quot;,r.Cookie(&quot;foo2&quot;)) fmt.Fprintf(buff,&quot;[Header]User-Agent=%s\\n&quot;,r.Header.Get(&quot;User-Agent&quot;)) fmt.Fprintf(buff,&quot;[Header]Proto=%s\\n&quot;,r.Proto) fmt.Fprintf(buff,&quot;[Header]Method=%s\\n&quot;,r.Method) fmt.Fprintf(buff,&quot;[Addr]Addr=%s\\n&quot;,r.RemoteAddr) fmt.Fprintf(buff,&quot;[Request]%+v\\n&quot;,r) //手动发送响应报文 io.WriteString(w, &quot;HTTP/1.1 200 OK\\r\\n&quot;) io.WriteString(w, fmt.Sprintf(&quot;Content-Length: %d\\r\\n&quot;,buff.Len())) io.WriteString(w,&quot;\\r\\n&quot;) io.Copy(w,buff) //将buff缓存数据发送给客户端&#125;func main()&#123; svr:=&amp;httpd.Server&#123; Addr: &quot;127.0.0.1:8080&quot;, Handler: new(myHandler), &#125; panic(svr.ListenAndServe())&#125; 利用curl测试我们的接口： 12345678910111213141516# -b发送cookie，-i显示响应报文$ curl &quot;127.0.0.1:8080?name=gu&amp;token=123&quot; -b &quot;foo1=bar1;foo2=bar2;&quot; -i输出：HTTP/1.1 200 OKContent-Length: 488[query]name=gu[query]token=123[cookie]foo1=bar1[cookie]foo2=bar2[Header]User-Agent=curl/7.55.1[Header]Proto=HTTP/1.1[Header]Method=GET[Addr]Addr=127.0.0.1:4179[Request]&amp;&#123;Method:GET URL:/?name=gu&amp;token=123 Proto:HTTP/1.1 Header:map[Accept:[*/*] Cookie:[foo1=bar1;foo2=bar2;] Host:[127.0.0.1:8080] User-Agent:[curl/7.55.1]] Body:0x489290 RemoteAddr:127.0.0.1:4179 RequestURI:/?name=gu&amp;token=123 conn:0xc00007e690 cookies:map[foo1:bar1 foo2:bar2] queryString:map[name:gu token:123]&#125; 11.总结这一章我们对Request完成了请求行以及首部字段的解析，同时提供了更简便的查询queryString以及cookie的方法，我们已经完成了除POST以及PUT之外请求地解析。下一章我们将对Request的Body属性进行更为细致地设置，即对应POST请求的解析。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-（3）","slug":"从零实现Golang的HTTP标准库-（3）","date":"2022-10-06T00:20:00.000Z","updated":"2022-10-06T04:05:08.831Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（3）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%883%EF%BC%89.html","excerpt":"","text":"1.概述在正式开始HTTP协议的解析之前，我们先对几个包进行整理。 在上一篇中，我们对conn结构体进行了改进。 其中，提到了有关于标准库的bufio包的内容，包括bufio.Reader以及bufio.Writer等。 在上一篇中，对于这部分内容只是做了一个简单的介绍，在本篇中，我将单独对这部分内容进行一个梳理，并额外扩充了ioutil包以及io包等相关的内容。 这部分内容并不难，通常只是一些结构体和方法的梳理。但如果事先没能够很好理解结构体或方法的意义，往往会对理解后面的代码造成困难。 2.io包1.io包 IO 操作是我们在编程中不可避免会遇到的，例如读写文件，Go语言的 io 包中提供了相关的接口，定义了相应的规范，不同的数据类型可以根据规范去实现相应的方法，提供更加丰富的功能。 io.Reader io.Reader接口定义了 Read 方法，用于读取数据到字节数组中： 入参：字节数组 p，会将数据读入到 p 中 返回值：本次读取的字节数 n，以及遇到的错误 err io.Reader是一个接口，任何实现了Read()函数的对象，都可以作为Reader来使用 123type Reader interface &#123; Read(p []byte) (n int, err error)&#125; 方法功能详解 方法读取数据写入到字节数组 p 中，由于 p 是有大小的，所以一次至多读取 len(p) 个字节 方法返回读取的数据字节数 n(0 &lt;&#x3D; n &lt;&#x3D; len(p))，以及读取过程中遇到的 error 即使一次调用读取到的数据小于 len(p)，也可能会占用整个字节数组 p 作为暂存空间 如果数据源的数据量小于 len(p) 个字节，方法只会读取当前可用数据，不会等待更多数据的到来 io.Writer io.Writer接口定义了 Write 方法，用于写数据到底层文件中 入参：字节数组 p，会将 p 中的数据写入到底层文件中 返回值：成功写入完成的字节数 n，以及遇到的错误 err 123type Writer interface &#123; Write(p []byte) (n int, err error)&#125; 方法功能详解 该方法将 p 中的数据写到文件中 方法返回成功写入的字节数 n（0 &lt;&#x3D; n &lt;&#x3D; len(p)），以及写入过程中遇到的错误 err 如果 n&lt;len(p)，方法必须返回 err!&#x3D;nil 方法一定不能修改字节数组 p，即使是临时修改也不被允许 io.LimitedReader 它包含一个属性N代表能够在这个LimitReader上读取的最多字节数，如果在此LimitReader上读取的总字节数超过了上限，则接下来对这个LimitReader的读取都会返回io.EOF，从而有效终止读取过程，避免首部字段的无限读。 12345type LimitedReader struct &#123; R Reader // underlying reader N int64 // max bytes remaining&#125; io.copy(dst,src) 从src读,写入dst中.，复制文件 总结 io.Reader : 读取底层文件中的数据到字节数组p中io.Writer : 将字节数组p的数据写入到底层文件中 可以看到 Reader 和 Writer 接口中定义的方法中，都有字节数组p，而底层要操作的文件在方法中却没有体现出来,我们只需要知道底层文件会通过p被read和write操作即可。 Read方法是将文件的数据读入字节数组p，Write 是将字节数组p的数据写入文件，这一点不要记混。 3.ioutil包Go语言 ioutil包中提供了一些常用、方便的IO操作函数，我们在平时的时候中可以直接拿来使用。对于IO读操作来说，比较适用于读小文件，因为相关方法都是一次性将内容读入内存，文件太大内存吃不消。 ioutil.readAll（） readAll 是一个内部方法，从入参 io.reader 中读取全部数据，然后返回读取到的数据以及产生的 error，主要是调用 butes.Buffer 的 ReadFrom 方法（读取完数据产生的EOF error 在这里不算做 error，因为目的就是读取完数据）。 1234567891011121314151617181920212223242526272829// io.Reader r : 保存着底层数据，数据从 r 中读取// capacity： 用于设置保存数据的字节缓冲区的初始容量，但是在读取过程中会自动扩容的func readAll(r io.Reader, capacity int64) (b []byte, err error) &#123; var buf bytes.Buffer // 如果字节缓冲区在读取过程中一直扩容，最终超出了系统设置的最大容量，会产生 ErrTooLarge panic，在这里捕获，改为返回一个 error // 如果是其他类型的 panic，保持 panic defer func() &#123; e := recover() if e == nil &#123; return &#125; if panicErr, ok := e.(error); ok &amp;&amp; panicErr == bytes.ErrTooLarge &#123; err = panicErr &#125; else &#123; panic(e) &#125; &#125;() // 设置默认容量 if int64(int(capacity)) == capacity &#123; buf.Grow(int(capacity)) &#125; // 读取数据 _, err = buf.ReadFrom(r) return buf.Bytes(), err&#125; ioutil.Readfile（） ioutil.ReadFile 读取文件只需要传入一个文件名做为 参数，读取成功，会将文件的内容做为一个字节数组返回，如果读取错误，将返回 error 信息。 使用 ReadFile 读取文件，不需要手动 打开与关闭文件，打开与关闭文件的动作，系统自动帮我们完成。同时，使用 ReadFile 读取文件时，只适合读取小文件，不适合读取大文件。 总结 ReadAll 方法，我们比较常用的工具类方法，一次性读取文件的所有内容并返回，适用于读取小文件，如果文件太大会占用太多内存。调用 ReadAll 方法成功，会读取 io.Reader r 的所有内容，返回的 err &#x3D;&#x3D; nil，而不是 err &#x3D;&#x3D; EOF，因为读取完所有数据了，完成了我们的任务，此时 EOF 不应当是 error。 4.bufio包bufio.reader 我们都知道，对底层文件的IO操作，是比较费时的。如果每操作一次数据就要读取一下底层文件，IO操作是非常多的。那么如何提高效率呢？可以考虑预加载，读取数据的时候，提前加载部分数据到缓冲区中，如果缓冲区长度大于每次要操作的数据长度，这样就减少了 IO 次数；同样，对于写底入层文件，我们可以先将要写入的数据存入缓冲区，然后一次性将数据写入底层文件。 bufio包 基于缓冲区，提供了便捷的对底层文件IO操作方法，并利用缓冲区减少了IO次数，本篇文章就先来学习文件读取相关结构 bufio.Reader。 bufio.Reader 利用一个缓冲区，在底层文件读取器和读操作方法间架起了桥梁。底层文件读取器就是初始化 Reader 的时候需要传入的io.Reader。有这样一个缓冲区的好处是，每次我们想读取底层文件内容时，会首先从缓冲区读取，提高了读取速度，也避免了频繁的 底层文件IO，同时必要时会利用底层文件读取器io.Reader提前加载部分数据到缓冲区中，做到未雨绸缪。 有这样一个缓冲区的好处是，可以在大多数的时候降低读取方法的执行时间。虽然，读取方法有时还要负责填充缓冲区，但从总体来看，读取方法的平均执行时间一般都会因此有大幅度的缩短。 bufio.Reader 的结构如下： bufio.Reader结构 bufio.Reader中的 r、w 分别代表当前读取和写入的位置，读写都是针对缓存切片 buf 来说的。io.Reader rd 是用来写入数据到 buf 的，因此当写入了部分字节，w 会增大相应的写入字节数；而当从 buf 中读出数据后，r 会增大，被读取过的数据就是无用数据了。始终 w&gt;&#x3D;r，当 w&#x3D;&#x3D;r 时，说明写入的数据都被读取过了，没有有效数据可读了。 buf：用作缓冲区的字节切片，虽然是切片类型，但是一旦初始化完成之后，长度不会改变 rd：初始化时传入的io.Reader，用于读取底层文件数据，然后写入到缓冲区 buf 中 r：下一次读取缓冲区 buf 时的起始位置，即 r 之前的数据都是被读取过的，下次读取会从 r 位置开始，我们称之为已读计数 w：下一次写入缓冲区 buf 时的起始位置，即 w 之前都是之前写过的数据，下次写入从 w 位置开始，我们称之为已写计数 err：记录 rd 读取数据时产生的 error，err 在被读取或忽略之后，会被置为nil lastByte：保存上一次读取的最后一个字节的位置，用于回退一个字节；-1 表示无效值，不能回退 lastRuneSize：保存上一次读取的 rune 的位置，用于回退一个rune；-1 表示无效值，不能回退 12345678type Reader struct &#123; buf []byte rd io.Reader // reader provided by the client r, w int // buf read and write positions err error lastByte int // last byte read for UnreadByte; -1 means invalid lastRuneSize int // size of last rune read for UnreadRune; -1 means invalid&#125; Buffered() Buffered方法返回当前缓冲的字节数 1func (b *Reader) Buffered() int &#123; return b.w - b.r &#125; peek() peek方法用于查看未读数据的前n个字节，该方法并不会更改 bufio.Reader 的状态，不会更新已读计数，同时该方法不属于读取操作，不能用于后续的回退操作。 需要注意的是，该方法返回的是缓冲区的切片，可能造成数据泄露的风险，因为调用者可以通过返回的切片直接修改缓冲区的值；其次，返回数据的有效期是在下次数据读取之前，因为下次读取数据可能会数据压缩平移，导致当前数据的位置被改变。 1func (b *Reader) Peek(n int) ([]byte, error) Discard() Discard方法 会丢弃缓冲区的n个字节，最后返回实际丢弃的字节数和产生的 error。 对于合法参数 n，方法使用 for 循环不断装填数据，来尽量满足丢弃 n 个字节。即如果有效数据长度小于 n 的话，丢弃现有数据后，再重新调用fill 方法，填充新的数据用于丢弃，如果在这个过程中遇到err，方法就终止，最终返回实际丢弃的字节数和遇到的error。如果 buf 可丢弃的有效字节数大于 n，丢弃部分字节即可。 1func (b *Reader) Discard(n int) (discarded int, err error) Read() Read 方法读取数据到 字节切片 p 中，返回读取的字节数和产生的 error。 当缓冲区有效数据不为空时，直接将缓冲区的有效数据复制到字节切片p中，有多少就写入多少，不会再读取底层数据填充，因此如果当前缓冲区的有效数据长度小于传入字节切片 p 的长度，读取的字节数 n &lt; len(p)； 当缓冲区有效数据为空时，从底层文件读取数据，填充字节切片p。 当 p 的长度小于缓冲区长度时，从底层读取 一次 数据到缓冲区，然后将缓冲区的数据复制到 p 中 当 p 的长度大于缓冲区长度时，有一个优化，不会先写入缓冲区再复制到 p，这种方式不仅多复制一次，读取的数据还少于想要的数据长度，而是直接读取底层数据到 p 中，简单高效。 1func (b *Reader) Read(p []byte) (n int, err error) ReadLine() ReadLine方法 用于读取一行数据，且不会包含回车符和换行符(“\\r\\n” 或者 “\\n”)。该方法是 low-level 的，如果想要读取一行数据，应该尽量用 ReadBytes(‘\\n’) 或者 ReadString(‘\\n’) 来代替该方法。 在读取过程中，如果一行数据过长，超过了缓冲区长度，那么只会返回缓冲数组中的全部数据，并将 isPrefix 设置为 true，剩余的数据只会在后续再次调用 ReadLine方法 返回。如果正确返回一行数据，isPrefix&#x3D;false。 1func (b *Reader) ReadLine() (line []byte, isPrefix bool, err error) 总结 我们可以看到在bufio包下的read（）方法中只出现了字节切片p，也没有出现底层文件，这和io包下是一致的，我们只需知道底层文件确实被操作过了即可。 另外，bufio包的read机制需要熟记：首先切片p的含义是：要将底层文件的数据读取到p中当缓存切片bufr中有内容时，会优先从缓存切片中读内容到切片p中，并清空缓存切片bufr。当缓存切片bufr中没有内容时，会进行判断：当len(p) &gt; len(bufr)，即想要读取的内容比缓存切片bufr要大，直接去底层文件读取即可。当len(p) &lt; len(buf)，即想要读取的内容比缓存切片bufr小，先从底层文件读取内容充满缓存切片bufr，并将p填满，此时缓存切片bufr有剩余内容。再次读取时缓存切片bufr有内容，则将缓存区内容全部填入p并清空缓存切片bufr。 当缓存区中有内容时，程序的读取会从缓存区读而不会发生文件I&#x2F;O。只有当缓存区为空时才会发生文件I&#x2F;O 若缓存区的大小足够则启用缓存读，先会将内容载入填满缓存区，程序再从缓存区中读取。若缓存区过小则会直接从文件中读取而不使用缓存读 bufio.writer write机制：首先切片p的含义是：要将p中的数据写入到底层文件中当len(p) &gt; len(bufr)，即想要写入的内容比缓存切片bufr要大，直接往底层文件写入即可。当len(p) &lt; len(buf)，即想要写入的内容比缓存切片bufr小，先将p中的数据copy到缓存切片中去，再从缓存切片中将所有数据写入到底层文件中去。 flush（）方法 bufio.writer的flush方法，代表将缓存切片中剩余的数据一次性写入到底层文件中并清空缓存切片。 5.其他操作终端相关文件句柄常量： os.Stdin ： 标准输入 os.Stdout ： 标准输出 os.Stderr ： 标准错误 os.Open : 打开文件 os.OpenFile ：写入文件 WriteString()函数用于将字符串“s”的内容写入到写入器“w”, “w”是Writer类型的写入器，而“s”是写入写入器的字符串。 fmt.Printf，是把格式字符串输出到标准输出（一般是屏幕）。 1func Printf(format string, a ...interface&#123;&#125;) (n int, err error) fmt.Fprintf， 是把格式字符串输出到指定文件设备中，所以参数笔printf多一个文件指针FILE*。它返回已写入的字节数以及遇到的任何写入错误。 1func Fprintf(w io.Writer, format string, a ...interface&#123;&#125;) (n int, err error) 6.总结以上整理的基本上都是在接下来实现HTTP标准库过程中会用到的，暂时就整理这么多，其余的当我们遇到后再整理至此。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-（2）","slug":"从零实现Golang的HTTP标准库-（2）","date":"2022-10-05T14:20:00.000Z","updated":"2022-10-06T06:49:43.529Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（2）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%882%EF%BC%89.html","excerpt":"","text":"1.概述在上一篇中，我们介绍了如何启动一个Web服务， 在本篇中，我们主要构建框架的基本结构，即所需要的一些结构体。 我们暂时需要4个结构体： ① Server：代表WEB服务器，属性包含监听地址Addr以及Handler，负责服务器的启动逻辑。 ② conn：代表HTTP连接，net.Conn表达能力过弱，故将其封装成conn。仅服务于框架内部，不应由用户使用，包内不可导出。 ③ Request：代表客户端的HTTP请求，由框架从字节流中解析http报文从而生成的结构。 ④ response：代表响应，实现了ResponseWriter接口。包内不可导出。 2.结构体构建本节只为搭建框架的骨干，因此部分结构体内部暂时为空，部分函数也空实现，在随后的章节中我们一步步进行填充。 1.request.go 123type Request struct&#123;&#125;func readRequest(c *conn)(*Request,error)&#123;return nil,nil&#125; //暂时空实现 Request结构体就代表了客户端提交的http请求，我们使用readRequest函数从http连接上解析出这个对象。 它是http.Handler的ServeHTTP方法的第二个参数。 2.response.go 123type response struct&#123;&#125;type ResponseWriter interface&#123;&#125; response结构体就代表服务端的响应对象，我们后期会给其绑定些与客户端交互的方法，供用户使用。这里暂时让response和ResponseWriter都空实现。 它是http.Handler的ServeHTTP方法的第一个参数。 3.server.go 1234567891011121314151617181920212223type Handler interface &#123; ServeHTTP(w ResponseWriter,r *Request)&#125;type Server struct&#123; Addr string //监听地址 Handler Handler //处理http请求的回调函数&#125;func (s *Server) ListenAndServe()error&#123; l,err:=net.Listen(&quot;tcp&quot;,s.Addr) if err!=nil&#123; return err &#125; for&#123; rwc,err:=l.Accept() if err!=nil&#123; continue &#125; conn:=newConn(rwc,s) go conn.serve() // 为每一个连接开启一个go程 &#125;&#125; rwc是net包里的那个连接，此时还没有封装成代表http的连接。conn是封装好的连接对象。通过newConn（rwc）初始化出来。 conn是封装好的连接对象，它隶属于一个conn结构体。这个conn结构体里面提供了一个serve方法。这个serve方法就是用来处理连接的。Serve方法主要干三件事：一个是从连接中解析出客户端的请求request，另一个是设置response。这是serverHTTP方法的两个参数。最后一个是调用serverHTTP方法。注意：这个serverHTTP方法是和具体的tcp连接绑在一起的，而不是和封装好的那个连接绑在一起的。 上一节提到启动一个服务器其必须项只有Addr以及Handler，他们分别告诉了框架监听地址以及如何处理客户端的请求。事实上，Server结构体中还可以加入很多字段如读取或写入超时时间、能接受的最大报文大小等控制信息，但为了专注于一个框架最核心的实现，我们忽略这些细节内容。 ListenAndServe方法中展现的是go语言socket编程的写法，其大致意思是在Addr上监听TCP连接，将得到的TCP连接rwc(ReadWriteCloser)以及s进行封装得到conn结构体。接着调用conn.serve()方法，开启goroutine处理请求。 项目的开发尽量遵循模块分工原则，server.go只负责WEB服务器的启动逻辑，接下来的http协议的解析交给另一个模块conn.go进行。 4.conn.go 1234567891011121314151617181920212223242526272829303132333435type conn struct&#123; svr *Server // 引用服务器对象 rwc net.Conn // 底层tcp连接&#125;func newConn(rwc net.Conn,svr *Server)*conn&#123; return &amp;conn&#123;svr: svr, rwc: rwc&#125;&#125;func (c *conn) serve()&#123; defer func() &#123; if err:=recover();err!=nil&#123; log.Printf(&quot;panic recoverred,err:%v\\n&quot;,err) &#125; c.close() &#125;() //http1.1支持keep-alive长连接，所以一个连接中可能读出个请求，因此实用for循环读取 for&#123; req,err:=c.readRequest() //解析出Request if err!=nil&#123; handleErr(err,c) //将错误单独交给handleErr处理 return &#125; res:=c.setupResponse() //设置response // 有了用户关心的Request和response之后，传入用户提供的回调函数即可 c.svr.Handler.ServeHTTP(res,req) &#125;&#125;//暂时为空实现，后续小节再填充func (c *conn) readRequest()(*Request,error)&#123;return readRequest(c)&#125;func (c *conn) setupResponse()*response&#123;return nil&#125;func (c *conn) close()&#123;c.rwc.Close()&#125;func handleErr(err error,c *conn)&#123;fmt.Println(err)&#125; 对conn结构体作了扩充：拥有服务器属性、tcp连接属性。 在serve方法中，会分别调用readRequest以及setupResponse方法，从而得到Request以及response，随后将它们传入用户指定的Handler中，开启实际的请求处理过程。defer中使用recover，防止用户指定的Handler中存在逻辑错误导致发生panic。 利用for循环读取的原因： 对于HTTP 1.0来说，客户端为了获取服务端的每一个资源，都需要为每一个请求进行TCP连接的建立，因此每一个请求都需要等待2个RTT(三次握手+服务端的返回)的延时。而往往一个html网页中往往引用了多个css或者js文件，每一个请求都要经历TCP的三次握手，其带来的代价无疑是昂贵的。 因此在HTTP 1.1中进行了巨大的改进，即如果将要请求的资源在同一台服务器上，则我只需要建立一个TCP连接，所有的HTTP请求都通过这个连接传输，平均下来可以减少一半的传播时延。 如果客户端的请求头中包含connection: keep-alive字段，则我们的服务器应该有义务保证长连接的维持，并持续从中读取HTTP请求，因此这里我们使用for循环。 将err交给handleErr函数处理的原因： eadRequest可能会出现各种错误，如用户连接的断开、请求报文格式错误、服务器系统故障、使用了不支持的http版本、使用了不支持的协议等等错误。 对于有些错误如客户端连接断开或者使用了不支持的协议，我们服务端不应该进行回复。但对于一些错误如使用了不支持的http版本，我们应该返回505状态码；对于请求报文过大的错误，我们应该返回413状态码。因此在handleErr中，我们应该对err进行分类处理。 3.对conn结构体的改进目前conn结构体很简单，我们在读写两个方面进行分别改进，抽象出两个结构成员，一个负责对tcp连接读的逻辑，一个负责写的逻辑。两个改进如下： 1.写的改进 写的改进比较简单，主要是从性能优化角度出发。以下面代码为例： 12345http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; for i:=0;i&lt;100;i++&#123; io.WriteString(w,strconv.Itoa(i)) &#125; &#125;) 100次循环每次写入1~2B的小片段，每一次写入都会进行一次系统调用、一次IO操作，这势必会极大降低应用程序的性能。很显然，可以对用户写入数据进行缓存，缓存不下时再发送就能较少IO次数，从而提升效率。 go标准库提供了现有的工具，不需要重复造轮子。bufio.Writer可以解决我们的问题，它的底层会分配一个缓存切片，我们对这bufio.Writer写入时会优先往这个切片中写入，如果缓存满了，则将切片中缓存的数据发送到最底层的writer中，因此可以保证每次写入的大小都是大于或等于缓存切片的大小。在conn结构中引入bufw成员： 12345678910111213141516171819202122232425262728293031323334353637type conn struct&#123; svr *Server rwc net.Conn bufw *bufio.Writer //带缓存的writer&#125;func newConn(rwc net.Conn,svr *Server)*conn&#123; return &amp;conn&#123; svr: svr, rwc: rwc, bufw: bufio.NewWriterSize(rwc,4&lt;&lt;10), //缓存大小4kB &#125;&#125;func (c *conn) serve()&#123; defer func() &#123; if err:=recover();err!=nil&#123; log.Printf(&quot;panic recoverred,err:%v\\n&quot;,err) &#125; c.close() &#125;() //http1.1支持keep-alive长连接，所以一个连接中可能读出 //多个请求，因此实用for循环读取 for&#123; req,err:=c.readRequest() if err!=nil&#123; handleErr(err,c) return &#125; resp:=c.setupResponse() c.svr.Handler.ServeHTTP(resp,req) //将缓存中的剩余的数据发送到rwc中 if err=c.bufw.Flush();err!=nil&#123; return &#125; &#125;&#125; 我们给conn加入了bufw属性，以后的写入操作都将直接操纵bufw，其缓存的默认大小为4KB。同时在serve方法中，在一个请求处理结束后，bufw的缓存切片中还缓存有部分数据，我们需要调用Flush保证数据全部发送。 2.读的改进 对于HTTP协议来说，一个请求报文分为三部分：请求行、首部字段以及报文主体，一个post请求的报文如下： 123456789POST / HTTP/1.1\\r\\n #请求行Content-Type: text/plain\\r\\n #2~7行首部字段，首部字段为k-v对User-Agent: PostmanRuntime/7.28.0\\r\\nHost: 127.0.0.1:8080\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nContent-Length: 18\\r\\n\\r\\nhello,I am client! #报文主体 其中首部字段部分是由一个个key-value对组成，每一对之间通过\\r\\n分割，首部字段与报文主体之间则是利用两个连续的CRLF即\\r\\n\\r\\n作为分界。首部字段到底有多少个key-value对于服务端程序来说是无法预知的，因此我们想正确解析出所有的首部字段，我们必须一直解析到出现两个连续的\\r\\n为止。 对于一个正常的http请求报文，其首部字段总长度不会超过1MB，所以直接不加限制的读到空行完全可行，但问题是无法保证所有的客户端都没有恶意。 他可能在阅读框架源码后发现对首部字段的读取未采取任何限制措施，于是发送了一个首部字段无限长的http请求，导致服务器无限解析最终用掉了所有内存直至程序崩溃。因此我们应该为我们的reader限制最大读取量，这是第一个改进，改进用到了标准库的io.LimitedReader。 除此之外，首部字段的每个key-value都占用一行(\\r\\n是换行符)，为了方便解析，我们的reader应该有ReadLine方法。这是第二个改进，改进用到了标准库的bufio.Reader。 代码变动如下： 123456789101112131415161718type conn struct&#123; svr *Server rwc net.Conn lr *io.LimitedReader bufr *bufio.Reader //bufr是对lr的封装 bufw *bufio.Writer&#125;func newConn(rwc net.Conn,svr *Server)*conn&#123; lr:=&amp;io.LimitedReader&#123;R: rwc, N: 1&lt;&lt;20&#125; return &amp;conn&#123; svr: svr, rwc: rwc, bufw: bufio.NewWriterSize(rwc,4&lt;&lt;10), lr:lr, bufr: bufio.NewReaderSize(lr,4&lt;&lt;10), &#125;&#125; 第一处改进：为conn增加了lr字段，它是一个io.LimitedReader，它包含一个属性N代表能够在这个reader上读取的最多字节数，如果在此reader上读取的总字节数超过了上限，则接下来对这个reader的读取都会返回io.EOF，从而有效终止读取过程，避免首部字段的无限读。 第二处改进：为conn增加bufr字段，它是一个bufio.Reader，其底层的reader为上述的LimitedReader。对于一个io.Reader接口而言，它是无法提供ReadLine方法的，而将其封装程bufio.Reader后，就可以使用这个方法。 bufio.Reader相较io.Reader来说多出了ReadLine方法的原因： io.Reader提供的Read方法需要传入一个切片，如果传入的切片太小了，可能导致一行未读完；如果传入的切片太大了，则可能导致读取超过了一行。首部字段中的任何一行其长度是不可预知的，所以单纯利用io.Reader的Read方法很难达成目的。当然你可以传入一个字节大小的切片，每次读取1B然后通过不断append的方式，但这样会带来多次的IO开销。 bufio.Reader相较于io.Reader的改进就是，它会存在一个缓存切片，如果缓存切片中存在数据，我们对bufio.Reader进行Read优先会从这个缓存中取。我们平时会遇到一个使用场景就是，我们希望查看一下某个reader中的前多少B的数据，但又不希望我们这次查看之后后续的Read方法再也读不到这些数据，这时我们会将其转为一个bufio.Reader，通过其Peek方法就可以实现上述的要求。其原理就是Peek方法会将你peek出的数据暂存入切片缓存，尽管底层的reader流中不存在了这些数据，但对bufio.Reader进行Read会优先从缓存取，依旧可以将以前消费的数据读取出来。 ReadLine方法就是借助了这个缓存，它会不断地读取数据，如果读取的数据不够一行，则会将这些数据暂存；如果读取的数据够了一行，则将这一行返回，并将剩余未够一行的数据继续缓存。这样不论是一次读多读少，都不会影响Read方法的调用，同时也能减少IO次数提升性能。具体实现可以查看标准库bufio.go源码。 那么以后，我们直接操作的IO对象就是bufr和bufw： 读数据时直接操作bufr，bufr进而读取io.LimitedReader，进而读取tcp连接。 写数据时直接操作bufw，bufw进而写入到tcp连接。 4.测试编写main.go： 1234567891011121314151617181920package mainimport ( &quot;example/httpd&quot; &quot;fmt&quot;)type myHandler struct &#123;&#125;func (*myHandler) ServeHTTP(w httpd.ResponseWriter,r *httpd.Request)&#123; fmt.Println(&quot;hello world&quot;)&#125;func main()&#123; svr:=httpd.Server&#123; Addr: &quot;127.0.0.1:8080&quot;, Handler:new(myHandler), &#125; panic(svr.ListenAndServe())&#125; 由于目前未解析request以及response，所以无法去真正写我们的业务代码，但可以测试我们的Handler是否能被正常触发。执行curl命令： 1curl 127.0.0.1:8080 测试的执行流程为：框架使用者先指定一个myhandler结构体，给结构体绑定一个serverhttp方法，自己自定义实现serverhttp（其实是继承handler并重写）。 然后在main函数里面初始化一个server服务器对象svr，然后调用服务器对象的listenandserve方法，然后转进入到conn的serve方法，serve方法最后调用服务器对象的handler属性，handler是一个接口，里面有serverhttp方法但没有去实现，故handler可以调用serverhttp方法。 5.总结这一章我们完成了httpd框架骨干的搭建，以及完成对conn的封装。下一章则正式开始HTTP协议的解析工作，我们将封装Request、完成请求行以及请求首部字段的解析。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-（1）","slug":"从零实现Golang的HTTP标准库-（1）","date":"2022-10-05T02:21:31.000Z","updated":"2022-10-05T14:18:52.922Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-（1）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%EF%BC%881%EF%BC%89.html","excerpt":"","text":"1.前言在正式开始我们对Golang的HTTP标准库的实现之前，我还是想先推荐几个学习资源！ 这几个学习资源不是我们实现HTTP标准库所需的必备知识，所以我没有将他们放在前文的预备知识篇中，但是这几个资料的实现过程都和HTTP标准库有着一定相同的地方。 但如果你能够提前对以下推荐的几个学习资源事先做了阅读与研究，那么在实现Golang的HTTP标准库的过程中一定会如鱼得水，得心应手。 B站韩顺平的网络编程部分p294-p343 这一部分韩老师讲解了一个案例，其中的服务端部分思路值得借鉴。 B站刘丹冰的Zinx轻量级TCP服务框架 这个课程的质量非常高，up主刘丹冰老师的讲课风格十分干练，直击重点。在这门课中，老师实现了一个TCP服务框架，其实非常类似于我们将要实现的HTTP标准库，有很多思路都是共通的。我强烈建议大家有空的时候先完成对这门课程的学习，一定能够在这门课程中提前学到HTTP标准库的一些难点。 一位华科同学的博客 这个博客的博主是华中科技大学的一名计算机专业研究生，他在博客中记录了自己实现HTTP标准库的过程，其质量之高，让我收获良多。但由于博主计算机基础非常扎实，其语言风格比较干练，默认读者具有了一定的网络编程水平，故我在阅读的过程中对于一些细节之处难以理解，遇到了不少的阻碍。经过反复阅读与研究，我在阅读过程中做了不少的笔记，都是基于原博客写出来的，可以说，正是看了原博主的关于从零实现HTTP标准库的内容，让我萌发了对HTTP标准库研究的兴趣。所以，无论你之前是否有过网络编程基础，只要你想尝试研究实现HTTP标准库，你都应该或者说必须去看看这个博客。对于基础好的同学，我相信原博客内容已经能够满足你的需要；对于一些和我一样事先不太了解网络底层编程的同学，我觉得你仍需先看看原文的博客，当看到某处难以理解时，可以参考参考我博客中对应的地方，也许这处也是我当时疑惑的点。因此强烈建议各位去看看这个博客，我在此也对博主辜飞俊同学表示感谢！ 极客时间web框架教程 这是一门手把手教你写一个web框架的课程，总体来说应该具有一定的难度。我目前也没有学习完这门课程，但我认为其质量也是非常好的，可以作为我们实现完HTTP框架后的一个进阶与补充。其中，文章开头就以Golang的net&#x2F;HTTP标准库为例，引领读者一步步实现web框架。 以上四个内容都是我在学习过程中发现的优质资源，都对我有着比较大的帮助，所以也分享出来给大家学习。 2.概述Go语言的官方net&#x2F;HTTP标准库，搭建一个webServer非常容易。因为这个搭建过程中所使用到的函数、方法、接口往往是标准库帮我们封装好了的，我们只需要根据现成的已有的工具即可完成搭建。而我们今天将要实现的自然并不是使用现成的工具，而是要钻进HTTP标准库源码中，看看这些工具是怎么设计、怎么封装的。 3.webServerwebServer在维基百科上的解释为：Web Server 是一个通过 HTTP 协议处理 Web 请求的计算机系统。 HTTP 协议，在 OSI 网络体系结构中，是基于 TCP&#x2F;IP 之上第七层应用层的协议，全称叫做超文本传输协议。啥意思？就是说 HTTP 协议传输的都是文本字符，只是这些字符是有规则排列的。这些字符的排列规则，就是一种约定，也就是协议。这个协议还有一个专门的描述文档，就是RFC 2616。 对于 HTTP 协议，无论是请求还是响应，传输的消息体都可以分为两个部分：HTTP 头部和 HTTP Body 体。头部描述的一般是和业务无关但与传输相关的信息，比如请求地址、编码格式、缓存时长等；Body 里面主要描述的是与业务相关的信息。 Web Server 的本质，实际上就是接收、解析 HTTP 请求传输的文本字符，理解这些文本字符的指令，然后进行计算，再将返回值组织成 HTTP 响应的文本字符，通过 TCP 网络传输回去。 4.标准库启动Web服务的示例用 net&#x2F;http 来创建一个 HTTP 服务，其实很简单，下面是官方文档里的例子。我做了些注释，帮你理解。 1234567891011// 创建一个Foo路由和处理函数http.Handle(&quot;/foo&quot;, fooHandler)// 创建一个bar路由和处理函数http.HandleFunc(&quot;/bar&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, &quot;Hello, %q&quot;, html.EscapeString(r.URL.Path))&#125;)// 监听8080端口log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil)) 有基础的同学是可以看得懂上述代码的，无非是注册了两个路由，然后让服务器监听在8080端口上并运行。 但是零基础的同学看着上述代码，那可就疑问多多了，Handle是啥？HandleFunc是啥？ListenAndServe又是啥？有什么作用呢？不要担心，我最开始也是这样。 不要在意上面的代码细节，暂时有个印象，先继续往下看吧！ 5.自编代码启动Web服务第4节中的代码是官方的写法，他其实已经是经过了一些封装和简化的，那我们现在就自己动手写一个启动Web服务的代码，没有封装、没有简化，从这个自编代码入手开始学习！ 注意：官方代码中前两个方法是注册路由，关于这一块我们目前无需涉及，所以我先将路由这部分省略！ 1234567891011121314151617package mainimport &quot;net/http&quot;type myHandler struct&#123;&#125;func (*myHandler) ServeHTTP(w http.ResponseWriter,r *http.Request)&#123; w.Write([]byte(&quot;hello world!&quot;))&#125;func main()&#123; svr:=&amp;http.Server&#123; Addr: &quot;127.0.0.1:8080&quot;, Handler: new(myHandler), &#125; panic(svr.ListenAndServe())&#125; 我们来解析一下上述代码！解析过程并没有按照代码顺序，因为代码间存在先后因果的逻辑关系，需要仔细梳理！ 第1-3行为在main包下，引入“net&#x2F;http”库。 在main函数中，第12行我们初始化了一个http.server的对象并对其进行属性进行赋值，起名叫svr。 那么这个http.server是什么呢？它其实是一个结构体，代表了一个我们将要启动的服务器。 123456789type Server struct &#123; // 请求监听地址 Addr string // 请求核心处理函数 Handler Handler // 为了理解方便，其余非核心属性省略 ...&#125; 你可以看到这个server服务器结构体中有两个核心属性： 一个是String类型的Addr，初始化server时给Addr赋值表示希望服务器监听哪个地址端口； 一个是Handler类型的Handler，Handler是一个有ServeHTTP方法的接口，就好比一个拦截所有http请求的拦截器，告诉框架如何处理来自客户端的所有http请求。 我们来重点解析一下这个Handler接口。它代表了一个抽象的业务处理逻辑。 在自编代码中，我们在初始化服务器对象时，除了给Addr赋值，我们也给Handler属性进行了赋值，其值为myHandler。 显而易见，这个myHandler是我们自己定义的一个结构体，它会去实现Handler接口，因而myHandler可以赋值给Handler。前面说了这个Handler代表了一个抽象的业务处理逻辑，我们自己写这个myHandler并赋值给Handler，目的就是我们想要自己定义这个处理逻辑。 注意： 不论是Handler还是myHandler，他们都是代表抽象的笼统的，请不要将myHandler理解为具体的业务处理方法。具体的处理方法是另一个东西叫serverHTTP方法，这个serverHTTP方法是Handler接口里的一个成员方法，而myHandler结构体实现了Handler里的这个成员方法，也即实现了Handler接口。 在初始化server时，也可以不给Handler进行赋值，也即我们不想要自定义处理方法，那么这时候标准库会启动自己的默认处理方式。 在serverHTTP方法中我们才真正的去定义具体的业务请求处理方法。 比如在自编代码中，我们对业务请求的处理非常简单：直接输出“hello world!” 关于这个serverHTTP方法的参数： w http.ResponseWriter ：从名字你可以将它理解为“响应构造器”。当我们收到一个HTTP请求后，我们的框架会对这个请求进行处理。请求处理完毕后，肯定要往回发送一个响应。我们直接调用这个响应构造器w的write方法，即可完成响应的发送。 r *http.Request ：这个很简单，就是我们服务器或者框架从客户端收到的请求。这个请求的类型为Request，很显然，这个类型到时候是需要我们后面自己构建的。 其实，当客户端发来一个请求时，它的请求形式是一个HTTP请求报文的形式。而我们服务器对客户端的响应也是一个HTTP响应报文的形式。我们框架要做的就是当接收到HTTP报文后，我们对HTTP报文进行解析，获取关键信息并将其封装成一个Request结构体形式，代表一个请求。有了这个请求后，进行处理请求，通过响应构造器的write方法构建一个HTTP响应报文，再将其发送回去。 最后，关于ListenAndServe()函数，可以参照一下下面这幅图。 这部分其实就和go的socket编程相关。 如果你觉得层次比较多，对照着思维导图多看几遍就顺畅了。这里我也给你整理了一下逻辑线各层的关键结论： 第一层，标准库创建 HTTP 服务是通过创建一个 Server 数据结构完成的； 第二层，Server 数据结构在 for 循环中不断监听每一个连接； 第三层，每个连接默认开启一个 Goroutine 为其服务； 第四、五层，serverHandler 结构代表请求对应的处理逻辑，并且通过这个结构进行具体业务逻辑处理； 第六层，Server 数据结构如果没有设置处理函数 Handler，默认使用 DefaultServerMux 处理请求； 第七层，DefaultServerMux 是使用 map 结构来存储和查找路由规则。 最后，再多说一句，这个Handler接口除了有自定义处理逻辑的功能外，还有着路由的功能。 Handler的存在给框架的拓展带来了极大的灵活性，有了Handler，我们可以让任何一个HTTP请求以自己的规则映射到自己的路由。比如http标准库用ServeMux类型实现了Handler接口，从而实现了静态路由(将在本系列的末尾讨论)；gin的gin.Engine也是实现了自己的Handler，有了动态路由功能。 路由部分我们最后再说。 6.自定义框架的需求分析从需求分析的角度出发，看看我们要实现的web框架大体上需要哪些功能： http协议的解析不应该由开发者完成，我们需要从tcp字节流中解析出http的报文。 框架需要设置Request并为Request绑定易用API。 框架需要设置Response并为Response绑定易用API。 乍一看，我们需要给框架完成的功能甚少，但每一步都会有很多情况需要处理： 比如对于http 1.1协议来说，因为支持长连接，一个tcp连接能发送多个http请求，如果框架未正确完成上一个请求的解析(如未将当前报文主体全部读完)，那么随之到来的下一个请求就无法正确解析。 客户端有时会以chunk方式传输报文主体，我们应该保证用户read到的只有有效载荷(playload)，而没有chunk协议里的控制信息。 前端提交上来的form表单有多种类型，最常见的如application&#x2F;x-www-form-urlencoded以及multipart&#x2F;form-data，我们框架应该予以区分并分别提供解析方法。 服务端发送的数据是放在http响应报文的响应体中，客户端怎么知道我们发送了多少数据呢？一般来说可以查看响应头中的Content-Length字段，从而知道响应体的长度。观察上述的代码的ServeHTTP方法，我们并没有显式为头部指定Content-Length，但客户端依旧可以完整的读取出数据，这就说明标准库帮助我们完成了相关的设置工作。 从可行性角度来说，框架为我们的每一次响应都自动正确设置Content-Length(以下简称CT)是不现实的，发送CT所在的响应头必须是先于发送响应报文主体的，如果框架要自动设置CT，也就意味着我们必须为用户Write的所有数据进行缓存，这对一定长度内的发送量还实用，但对于大响应主体来说绝对是不可行。所以我们的框架还需要在必要时刻转化为利用chunk方式传输数据，这一部分对用户来说必须是无感知的。 7.总结本篇是从零实现Golang的HTTP标准库服务端部分的第一篇，开头给大家推荐了几个优秀的学习资源，然后介绍了webServer，标准库启动webServer的方法以及我们自定义启动webServer的方法并进行了详细的分析，最后给出了我们框架的需求以及难点。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}]},{"title":"从零实现Golang的HTTP标准库-预备知识（2）","slug":"从零实现Golang的HTTP标准库-预备知识（2）","date":"2022-10-04T14:17:12.000Z","updated":"2022-10-04T10:30:26.038Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-预备知识（2）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%EF%BC%882%EF%BC%89.html","excerpt":"","text":"1.概述在预备知识（1）中，我们介绍了三个学习内容，其中前两个学习内容：go语言的基础语法以及计算机网络的概念了解，我们不再详细介绍与梳理，请读者自行完成这两个部分的学习。 在本篇中，我将对socket编程流程做一个简单的介绍，同时梳理一下go语言的socket编程。 本篇默认你已经对socket有所了解，故基本的概念性问题将不再被提及。如果你在阅读以下内容的过程中，有任何不明白的地方，去看上一篇文章中推荐的学习资源，里面应该都会有答案，或者直接网上搜索疑问。 2.传统TCP套接字编程流程注意：以下内容是我学习《计算机网络自顶向下》中相关部分自己总结而来，可能存在说辞严谨性问题，目的只是为了提供给大家一个借鉴和参考。具体也可以听一听中科大郑老师的课上的讲解！ TCP套接字编程流程：1 服务器首先运行，等待连接建立。 1.1 服务器创建一个欢迎socket，即可以返回一个整数。 此时这个整数无任何意义。创建socket可以调用socket API的创建函数。 1.2 将这个整数和服务器本地的IP和服务器本地端口相捆绑，捆绑可以调用socket API的捆绑函数。 1.3 在服务器的欢迎scoket上阻塞式的等待接收用户的连接。即调用socket API的accept函数，接收来自远端的用户和服务器的欢迎scoket进行TCP连接。如果此时没有连接，则函数停在当前不往下走，即阻塞式等待连接。 2 客户端主动与服务器建立连接 2.1 客户端创建本地socket，不需要捆绑，是隐式自动捆绑。 2.2 指定服务器进程的IP地址和端口号，与服务器进程连接。 3 服务器收到来自客户端的连接请求3.1 服务器接收来自用户端的连接请求，解除阻塞式等待。 此时服务器会返回一个新的socket整数 新的socket叫connection socket，这个connection socket仍然和服务器的IP、端口捆绑但同时connection socket又和客户端的IP和端口相捆绑。此时连接建立完成。 这个新的connection socket就是通道，在这个通道上就可以收和发。 3.传统TCP套接字编程伪代码1.welcomeSocket&#x3D;Socket（）;&#x2F;&#x2F;创建一个欢迎socket 2.bind（welcomeSocket&amp;sad）&#x2F;&#x2F;将欢迎socket和服务器本地IP、端口相捆绑 3.connectionSocket&#x3D;accept（welcomeSocket）&#x2F;&#x2F;在welcomeSocket所在的的端口上阻塞式等待来自客户端用户的连接请求 4.clientSocket&#x3D;socket（）；&#x2F;&#x2F;创建一个客户端本地的clientSocket 5.connect（clientSocket，sad）&#x2F;&#x2F;将客户端的socket和服务器的ip、端口捆绑此时客户端的TCP实体向服务端发出一个连接建立请求，服务端收到请求后解除阻塞，accept会返回一个新的值connectionSocket，且服务端TCP实体给出连接建立响应，客户端处connect返回一个有效值clientSocket，此时连接建立。 6.客户端用clientSocket发送信息，用到send函数。 7.服务器端用connectionSocket接收信息，用到read函数。 8.服务器端用connectionSocket处理信息，用到write函数。 9.客户端用clientSocket接收信息，用到read函数。 10.关闭掉本次connectionSocket，等待用户下一次连接建立请求。关闭掉本次clientSocket。 用到close函数 以上为传统编码形式的TCP Socket编程。 (1) 建立Socket：使用socket()函数。 (2) 绑定Socket：使用bind()函数。 (3) 监听：使用listen()函数。或者连接：使用connect()函数。 (4) 接受连接：使用accept()函数。 (5) 接收：使用receive()函数。或者发送：使用send()函数。 4.go的socket编程以下内容是我学习B站韩顺平老师go语言基础课中网络编程部分的笔记，具体代码可以去视频中参考。 Golang TCP Socket编程： 1.分为服务器端和客户端，客户端可以有多个。 2.服务器端在8888端口监听，等待客户端的连接。 3.客户端向服务器端IP地址的端口8888建立连接，这个连接的双向箭头是Conn类型的，先记住。 4.服务器端有一个主线程P，当某一个客户端与服务器端建立连接后，这个主线程会开辟一个单独的协程goroutine来处理这个客户端的请求。 5.若有多个客户端，则可以开辟多个协程来处理。 5.go语言net包中的主要函数介绍本部分主要介绍net包中一些以后会用到的函数方法，详细内容参考以下链接。 https://studygolang.com/pkgdoc 12package netimport &quot;net&quot; net包提供了可移植的网络I&#x2F;O接口，包括TCP&#x2F;IP、UDP、域名解析和Unix域socket。 虽然本包提供了对网络原语的访问，大部分使用者只需要Dial、Listen和Accept函数提供的基本接口；以及相关的Conn和Listener接口。 1.Listen函数 func Listen(net, laddr string) (Listener, error)，用Listener类型和error类型接收。 解析：Listen函数是net包直接调用的函数，写作net.Listen（）。它里面含有两个参数，其中net是指网络协议的类型：TCP,UDP等，laddr是一个网络地址，由IP：端口号组成。Listen函数的作用是返回在一个本地网络地址laddr上监听的Listener。 net.Listen（x1，x2）就代表让服务器守候在x2端口上等候客户端的连接请求，并且连接必须是x1协议类型的。 2.Listener接口 12345678type Listener interface &#123; // Addr返回该接口的网络终端地址 Addr() Addr // Accept等待并返回下一个连接到该接口的连接 Accept() (c Conn, err error) // Close关闭该接口，并使任何阻塞的Accept操作都会不再阻塞并返回错误。 Close() error &#125; 如上所示，Listenr是一个监听接口类型，它是Listen函数的返回值类型。 比如说listenr是Listen函数的返回值，listener是Listener接口类型的“对象”。由最初的TCP套接字编程流程可知，accept函数是阻塞式的等待客户端和服务器进行连接，若连接上了，返回一个connection socket。 若没有连接上，则继续等待。在这里我们就可以用listenr对象调用Accept方法来实现。即listener.Accept（），因为accept是接口里的方法，所以可以直接调用。又因为需要阻塞式等待，所以该语句应该写在一个无限循环中。listener代表一个监听接口对象。关闭listener代表不监听了。 Accept() (c Conn, err error)再来细看Accept方法，返回值是Conn类型和error类型。 2.Conn接口 1234567891011121314type Conn interface &#123; // Read从连接中读取数据 Read(b []byte) (n int, err error) // Write从连接中写入数据 Write(b []byte) (n int, err error) // Close方法关闭该连接 // 并会导致任何阻塞中的Read或Write方法不再阻塞并返回错误 Close() error // 返回本地网络地址 LocalAddr() Addr // 返回远端网络地址 RemoteAddr() Addr&#125; Conn是Accept函数的返回值类型。 Conn接口代表网络连接。多个线程可能会同时调用同一个Conn的方法。 Conn也是一个接口类型。 这个Conn类型代表了一个客户端与服务器端的连接，也即前面图中提到的双向箭头，就是Conn接口类型的。 假如设Conn接口的对象是conn，那么这个conn就是传统编码中服务器端返回的那个connection socket。我们可以对这个conn进行读数据操作和写数据操作。 6.总结以上内容是我当时在学习这些知识时自己做的一些笔记，仅供大家参考！ 当你差不多掌握了上述预备知识以后，下面我们将真正步入Golang的HTTP标准库的实现中去！ 对于上述内容，你可以在实践的过程中慢慢体会！ 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"从零实现Golang的HTTP标准库-预备知识（1）","slug":"从零实现Golang的HTTP标准库-预备知识（1）","date":"2022-09-25T14:09:40.000Z","updated":"2022-10-04T10:32:00.663Z","comments":true,"path":"/post/从零实现Golang的HTTP标准库-预备知识（1）.html","link":"","permalink":"http://example.com/post/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Golang%E7%9A%84HTTP%E6%A0%87%E5%87%86%E5%BA%93-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%EF%BC%881%EF%BC%89.html","excerpt":"","text":"1.概述在我们从零实现Golang的HTTP标准库之前，我们首先需要学习一些预备知识，学习了这些预备知识作为基础以后，我们才能更好的理解Golang的HTTTP标准库的代码，也有利于我们后面自己动手实现它。 在预备知识中，我不会过多介绍关于Golang的HTTP标准库有关的内容，这一部分的介绍等我们学习完预备知识以后，会更新在后续的真正实现HTTP标准库的文章中。 2.所需要的预备知识以及学习资源推荐 Golang的基本语法 B站韩顺平的go语言基础课 《go语言编程基础》 国内七牛云团队编写的书，国人编写，通俗易懂 《go语言程序设计》 Go语言圣经，经典书籍但翻译略显晦涩 因为我们是要实现Golang的HTTP标准库，所以首先我们需要了解Golang这门语言的基础语法。 当然，我们不需要对Go语言有特别深入的了解，只需要掌握一些基础的部分，如：变量的定义、结构体的创建、给结构体绑定函数、接口的定义、接口的实现、for循环的写法、结构体对象的初始化等等，以上这些经常出现在标准库代码中。 至于Go语言的一些深入特性，如闭包、管道、Groutine协程等的底层原理，在本系列中无需知晓，只需知道其作用即可。 计算机网络 B站中科大计算机网络教程 《计算机网络自顶向下》 经典书籍，你只需学习书中的应用层和传输层即可，在传输层的结尾你会了解到传统socket的编程方式。 这门课是计算机科学与技术专业或软件工程专业学生的必修专业课，要想知道什么是HTTP，自然离不开计算机网络的学习。 你需要学习有关于传输层的知识，包括TCP等，以及什么是socket。力求对于计算机网络课程有一个大体的概念了解。 go语言的socket编程 B站韩顺平的go语言基础课网络编程部分 在计算机网络课程中，你会了解到什么是socket，以及传统的socket编程方式流程步骤。 但是在go语言中，有着自己的一套socket编程方法，但是大体的思路原理却是一致的，所以你仍需先学习计算机网络，了解传统的socket编程，在此基础上，学习go语言的socket编程将会事半功倍。 注意：我们需要学习的是有关于TCP的socket编程。 3.总结关于上述的三个知识点或者说三部分学习内容，难度不大，不需要花费你太多的精力。 但是却是我们实现Golang的HTTP标准库的基础，所以需要认真学习对待。 在接下来的文章中，我也会将其中一些重要部分单独梳理一遍。 本篇到此结束，感谢你的阅读！","categories":[{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Markdown语法学习，博客记录的开始~","slug":"markdown语法","date":"2022-09-24T15:08:35.025Z","updated":"2022-10-05T14:19:47.371Z","comments":true,"path":"/post/markdown语法.html","link":"","permalink":"http://example.com/post/markdown%E8%AF%AD%E6%B3%95.html","excerpt":"","text":"1.标题一共会有6个等级的标题，用#号表示，#数量越多，越小，一般情况下不要使用第一级标题，从二级标题开始用。 titlel1 我是一级titlel2 我是二级titlel3 我是三级titlel4 我是四级titlel5 我是五级titlel6 我是六级2.段落想要分段，在段尾输入至少两个以上的空格再回车；或者直接空一行再输入。 如：祝爷爷奶奶身体健康 祝我的家人生活幸福 这两句想要分段 就在第一句“祝爷爷奶奶身体健康”结束后空一整行再输入第二句“祝我的家人生活幸福”即可得到： 祝爷爷奶奶身体健康 祝我的家人生活幸福 3.字体3.1字体加粗：如想对“同济大学”加粗，在“同济大学”两侧分别加上两个“*”号，即可实现加粗。 “同济大学” 3.2字体倾斜：如想对“同济大学”倾斜，在“同济大学”两侧分别加上一个“*”号，即可实现倾斜。 “同济大学“ 3.3高亮：如想对“同济大学”高亮，在“同济大学”左边加上”&lt;mark&gt;”，右边加上”&lt;&#x2F;mark&gt;”,即可实现倾斜。 “同济大学“ 4.分隔线当文章段落过多，会影响整体可读性，此时可用分隔线对文章进行切分。 直接在单独的一行中输入三个“*”号。 或者使用多个“-”。 5.删除线在要添加删除线的文本两侧分别加上两个“~”。 文本文本文本 6.无序列表无序列表就是在输出多行文字，每行最前面带一个小点作为前缀。语法为一个“*”跟一个空格，后面输入文字，每行之间不需要空一行。 xxxxxxxxx yyyyyyyyy zzzzzzzzzz 7.有序列表有序列表就是用数字作为前缀。语法为一个数字带一个点跟一个空格，后面输入文字，每行之间不需要空一行。 xxxxxxxxxxxx yyyyyyyyyyyy zzzzzzzzzzzzz 8.列表嵌套在输入完第一个列表行后，想在这个列表行下在嵌套两个子列表行，则在第一个列表行的下一行开始连按四个空格，再逐个输入子列表行。 列表行A 子列表1 子列表2 列表行B 子列表1 子列表2 子列表3 9.区块区块是用来引用一段文本的。 语法为：一个”&gt;”跟一个空格，后面输入需要引用的文本。 如果要分段，则在第二行输入一个单独的”&gt;”，再换到第三行按照语法继续引用。 扬州是个好地方啊。 —-习近平 把扬州建设成为古代文化与现代文明交相辉映的名城。 —-江泽民 10.代码块代码块用来展示不同语言的代码。 语法为：上下分别使用三个点进行包裹，上下各占一行，在顶行的三个点右边写上代码语言的类型(java,go)从而让代码高亮，无需空格。 其中点为esc键下面的那个波浪键，注意一定要用英文的点。 123456public class Hello&#123; public static void main(String[] args)&#123; System.out.print(&quot;Hello,World!!&quot;); &#125;&#125; 1234567package mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Println(&quot;Hello,World!&quot;)&#125; 11.链接 直接插入 直接显示链接的网址，也即直接复制连接过来，点击网址即可跳转。 如 www.baidu.com 有时候无法识别网址，所以在插入链接的时候最好用“&lt;&gt;”包围来插入，这样百分百可识别为网址 文本链接 就是让一段文本具有链接跳转的功能。 语法为：英文下，一对方括号“[]”加上一对圆括号“（）”，在方括号内写文本，在圆括号内写链接网址，点击文本即可跳转,网址需要写全，前缀加上。 如：百度一下 12.图片直接将要插入的图片拖入图床，用markdown格式在vika模式下上传，然后直接粘贴就行了。 文字居中：不能直接按空格让文字居中，而是在文字左侧加”&lt;center&gt;”,右侧加”&lt;&#x2F;center&gt;”。 图片居中：在图片链接结尾的右括号前面加上”#pic_center”。 扮鬼脸的哆啦A梦！ 图1 13.表格 x y z a c e b d f 利用多个”|”，每两个“|”之间写内容。 在表格的第二行中，每两个“|”之间填的是“—”，减号数量不影响显示，这个不会显示出来，只是用来确定格式。 第二行和第一行保持一致，用“—”代替。在“—”的左右两边都可以添加冒号“:”,在左边添就是居左对齐，在右边添就是居右对齐，两边都添就是居中对齐。 x y z a c e b d f 14.转义字符如果我们想输出某些符号，但是在markdown里面有可能被识别成语法，此时需要在前面添上转义字符。 通常用反斜杠”&quot;直接加上符号，无需空格。 反斜杠英文下直接按enter键上面那个，不用按shift。 * 666 这是加了反斜杠的星号。 666 这是没加反斜杠的星号，被识别成无序列表前缀。 # ​","categories":[{"name":"Markdown","slug":"Markdown","permalink":"http://example.com/categories/Markdown/"}],"tags":[{"name":"Markdown语法基础","slug":"Markdown语法基础","permalink":"http://example.com/tags/Markdown%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"}]},{"title":"小戴小戴","slug":"小戴小戴","date":"2021-09-25T06:19:54.000Z","updated":"2023-02-27T13:26:41.313Z","comments":true,"path":"/post/小戴小戴.html","link":"","permalink":"http://example.com/post/%E5%B0%8F%E6%88%B4%E5%B0%8F%E6%88%B4.html","excerpt":"","text":"测试小戴小戴，这里是小徐。（测试）","categories":[],"tags":[]}],"categories":[{"name":"网络模型 golang","slug":"网络模型-golang","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B-golang/"},{"name":"godis","slug":"godis","permalink":"http://example.com/categories/godis/"},{"name":"网络模型","slug":"网络模型","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"},{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"},{"name":"Map","slug":"Map","permalink":"http://example.com/categories/Map/"},{"name":"从零实现HTTP标准库","slug":"从零实现HTTP标准库","permalink":"http://example.com/categories/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%A0%87%E5%87%86%E5%BA%93/"},{"name":"Markdown","slug":"Markdown","permalink":"http://example.com/categories/Markdown/"}],"tags":[{"name":"netpoller epoll","slug":"netpoller-epoll","permalink":"http://example.com/tags/netpoller-epoll/"},{"name":"godis","slug":"godis","permalink":"http://example.com/tags/godis/"},{"name":"netpoller redis","slug":"netpoller-redis","permalink":"http://example.com/tags/netpoller-redis/"},{"name":"跳表","slug":"跳表","permalink":"http://example.com/tags/%E8%B7%B3%E8%A1%A8/"},{"name":"Map","slug":"Map","permalink":"http://example.com/tags/Map/"},{"name":"网络编程","slug":"网络编程","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"基础知识","slug":"基础知识","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"Markdown语法基础","slug":"Markdown语法基础","permalink":"http://example.com/tags/Markdown%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"}]}